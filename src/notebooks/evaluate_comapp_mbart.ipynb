{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T15:38:35.681622192Z",
     "start_time": "2024-01-29T15:38:35.588026593Z"
    }
   },
   "id": "863338ddbf31a6c5"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                example  \\\n0     Doch der theatralische Selbstmord von General ...   \n1     Doch der theatralische Selbstmord von General ...   \n2     Morgens beim Kaffee wird gemeinsam entschieden...   \n3     Morgens beim Kaffee wird gemeinsam entschieden...   \n4     Unter den Einwohnern der großen EU - Länder si...   \n...                                                 ...   \n8503  Protestzüge wälzen sich durch München , Eisner...   \n8504              Und in Sands bewege sich ja einiges .   \n8505              Ulrike beugt sich über die Partitur .   \n8506  Am Anfang gab es viel Widerstand , man holpert...   \n8507  Auf langen Zugfahrten klickt er sich deshalb d...   \n\n                                                    cue    pseudoword  \n0     Doch der theatralische Selbstmord von General ...         am488  \n1     Doch der theatralische Selbstmord von General ...  wenigsten488  \n2     Morgens beim Kaffee wird gemeinsam entschieden...         am488  \n3     Morgens beim Kaffee wird gemeinsam entschieden...  wenigsten488  \n4     Unter den Einwohnern der großen EU - Länder si...         am488  \n...                                                 ...           ...  \n8503                                 Protestzüge wälzen      sich1573  \n8504                                Und in Sands bewege      sich1573  \n8505                                       Ulrike beugt      sich1573  \n8506    Am Anfang gab es viel Widerstand , man holperte      sich1573  \n8507                    Auf langen Zugfahrten klickt er      sich1573  \n\n[8508 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>example</th>\n      <th>cue</th>\n      <th>pseudoword</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Doch der theatralische Selbstmord von General ...</td>\n      <td>Doch der theatralische Selbstmord von General ...</td>\n      <td>am488</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Doch der theatralische Selbstmord von General ...</td>\n      <td>Doch der theatralische Selbstmord von General ...</td>\n      <td>wenigsten488</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Morgens beim Kaffee wird gemeinsam entschieden...</td>\n      <td>Morgens beim Kaffee wird gemeinsam entschieden...</td>\n      <td>am488</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Morgens beim Kaffee wird gemeinsam entschieden...</td>\n      <td>Morgens beim Kaffee wird gemeinsam entschieden...</td>\n      <td>wenigsten488</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Unter den Einwohnern der großen EU - Länder si...</td>\n      <td>Unter den Einwohnern der großen EU - Länder si...</td>\n      <td>am488</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8503</th>\n      <td>Protestzüge wälzen sich durch München , Eisner...</td>\n      <td>Protestzüge wälzen</td>\n      <td>sich1573</td>\n    </tr>\n    <tr>\n      <th>8504</th>\n      <td>Und in Sands bewege sich ja einiges .</td>\n      <td>Und in Sands bewege</td>\n      <td>sich1573</td>\n    </tr>\n    <tr>\n      <th>8505</th>\n      <td>Ulrike beugt sich über die Partitur .</td>\n      <td>Ulrike beugt</td>\n      <td>sich1573</td>\n    </tr>\n    <tr>\n      <th>8506</th>\n      <td>Am Anfang gab es viel Widerstand , man holpert...</td>\n      <td>Am Anfang gab es viel Widerstand , man holperte</td>\n      <td>sich1573</td>\n    </tr>\n    <tr>\n      <th>8507</th>\n      <td>Auf langen Zugfahrten klickt er sich deshalb d...</td>\n      <td>Auf langen Zugfahrten klickt er</td>\n      <td>sich1573</td>\n    </tr>\n  </tbody>\n</table>\n<p>8508 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../../data/pseudowords/CoMaPP_all.json\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "data = [{\"example\": d[\"target1\"], \"cue\": \" \".join(d[\"target1\"].split()[:d[\"query_idx\"]]), \"pseudoword\": d[\"label\"]} for d in data if d[\"target1\"].split()[d[\"query_idx\"]] in d[\"label\"]]\n",
    "df = pd.DataFrame.from_dict(data).drop_duplicates(ignore_index=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T15:38:35.800287048Z",
     "start_time": "2024-01-29T15:38:35.685085484Z"
    }
   },
   "id": "18bb06d46d72aab4"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 example  \\\nindex                                                      \n488    Doch der theatralische Selbstmord von General ...   \n488    Doch der theatralische Selbstmord von General ...   \n488    Morgens beim Kaffee wird gemeinsam entschieden...   \n488    Morgens beim Kaffee wird gemeinsam entschieden...   \n488    Unter den Einwohnern der großen EU - Länder si...   \n...                                                  ...   \n1573   Protestzüge wälzen sich durch München , Eisner...   \n1573               Und in Sands bewege sich ja einiges .   \n1573               Ulrike beugt sich über die Partitur .   \n1573   Am Anfang gab es viel Widerstand , man holpert...   \n1573   Auf langen Zugfahrten klickt er sich deshalb d...   \n\n                                                     cue    pseudoword  \nindex                                                                   \n488    Doch der theatralische Selbstmord von General ...         am488  \n488    Doch der theatralische Selbstmord von General ...  wenigsten488  \n488    Morgens beim Kaffee wird gemeinsam entschieden...         am488  \n488    Morgens beim Kaffee wird gemeinsam entschieden...  wenigsten488  \n488    Unter den Einwohnern der großen EU - Länder si...         am488  \n...                                                  ...           ...  \n1573                                  Protestzüge wälzen      sich1573  \n1573                                 Und in Sands bewege      sich1573  \n1573                                        Ulrike beugt      sich1573  \n1573     Am Anfang gab es viel Widerstand , man holperte      sich1573  \n1573                     Auf langen Zugfahrten klickt er      sich1573  \n\n[8508 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>example</th>\n      <th>cue</th>\n      <th>pseudoword</th>\n    </tr>\n    <tr>\n      <th>index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>488</th>\n      <td>Doch der theatralische Selbstmord von General ...</td>\n      <td>Doch der theatralische Selbstmord von General ...</td>\n      <td>am488</td>\n    </tr>\n    <tr>\n      <th>488</th>\n      <td>Doch der theatralische Selbstmord von General ...</td>\n      <td>Doch der theatralische Selbstmord von General ...</td>\n      <td>wenigsten488</td>\n    </tr>\n    <tr>\n      <th>488</th>\n      <td>Morgens beim Kaffee wird gemeinsam entschieden...</td>\n      <td>Morgens beim Kaffee wird gemeinsam entschieden...</td>\n      <td>am488</td>\n    </tr>\n    <tr>\n      <th>488</th>\n      <td>Morgens beim Kaffee wird gemeinsam entschieden...</td>\n      <td>Morgens beim Kaffee wird gemeinsam entschieden...</td>\n      <td>wenigsten488</td>\n    </tr>\n    <tr>\n      <th>488</th>\n      <td>Unter den Einwohnern der großen EU - Länder si...</td>\n      <td>Unter den Einwohnern der großen EU - Länder si...</td>\n      <td>am488</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1573</th>\n      <td>Protestzüge wälzen sich durch München , Eisner...</td>\n      <td>Protestzüge wälzen</td>\n      <td>sich1573</td>\n    </tr>\n    <tr>\n      <th>1573</th>\n      <td>Und in Sands bewege sich ja einiges .</td>\n      <td>Und in Sands bewege</td>\n      <td>sich1573</td>\n    </tr>\n    <tr>\n      <th>1573</th>\n      <td>Ulrike beugt sich über die Partitur .</td>\n      <td>Ulrike beugt</td>\n      <td>sich1573</td>\n    </tr>\n    <tr>\n      <th>1573</th>\n      <td>Am Anfang gab es viel Widerstand , man holpert...</td>\n      <td>Am Anfang gab es viel Widerstand , man holperte</td>\n      <td>sich1573</td>\n    </tr>\n    <tr>\n      <th>1573</th>\n      <td>Auf langen Zugfahrten klickt er sich deshalb d...</td>\n      <td>Auf langen Zugfahrten klickt er</td>\n      <td>sich1573</td>\n    </tr>\n  </tbody>\n</table>\n<p>8508 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['index'] = df['pseudoword'].str.extract('(\\d+)').astype(int)\n",
    "df.set_index('index', inplace=True)\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T15:38:35.859815797Z",
     "start_time": "2024-01-29T15:38:35.800356056Z"
    }
   },
   "id": "b7e1f6e88f687297"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 example  \\\nindex                                                      \n488    Doch der theatralische Selbstmord von General ...   \n488    Doch der theatralische Selbstmord von General ...   \n488    Morgens beim Kaffee wird gemeinsam entschieden...   \n488    Morgens beim Kaffee wird gemeinsam entschieden...   \n488    Unter den Einwohnern der großen EU - Länder si...   \n...                                                  ...   \n1573   Protestzüge wälzen sich durch München , Eisner...   \n1573               Und in Sands bewege sich ja einiges .   \n1573               Ulrike beugt sich über die Partitur .   \n1573   Am Anfang gab es viel Widerstand , man holpert...   \n1573   Auf langen Zugfahrten klickt er sich deshalb d...   \n\n                                                     cue    pseudoword  \nindex                                                                   \n488    Doch der theatralische Selbstmord von General ...         am488  \n488    Doch der theatralische Selbstmord von General ...  wenigsten488  \n488    Morgens beim Kaffee wird gemeinsam entschieden...         am488  \n488    Morgens beim Kaffee wird gemeinsam entschieden...  wenigsten488  \n488    Unter den Einwohnern der großen EU - Länder si...         am488  \n...                                                  ...           ...  \n1573                                  Protestzüge wälzen      sich1573  \n1573                                 Und in Sands bewege      sich1573  \n1573                                        Ulrike beugt      sich1573  \n1573     Am Anfang gab es viel Widerstand , man holperte      sich1573  \n1573                     Auf langen Zugfahrten klickt er      sich1573  \n\n[8508 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>example</th>\n      <th>cue</th>\n      <th>pseudoword</th>\n    </tr>\n    <tr>\n      <th>index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>488</th>\n      <td>Doch der theatralische Selbstmord von General ...</td>\n      <td>Doch der theatralische Selbstmord von General ...</td>\n      <td>am488</td>\n    </tr>\n    <tr>\n      <th>488</th>\n      <td>Doch der theatralische Selbstmord von General ...</td>\n      <td>Doch der theatralische Selbstmord von General ...</td>\n      <td>wenigsten488</td>\n    </tr>\n    <tr>\n      <th>488</th>\n      <td>Morgens beim Kaffee wird gemeinsam entschieden...</td>\n      <td>Morgens beim Kaffee wird gemeinsam entschieden...</td>\n      <td>am488</td>\n    </tr>\n    <tr>\n      <th>488</th>\n      <td>Morgens beim Kaffee wird gemeinsam entschieden...</td>\n      <td>Morgens beim Kaffee wird gemeinsam entschieden...</td>\n      <td>wenigsten488</td>\n    </tr>\n    <tr>\n      <th>488</th>\n      <td>Unter den Einwohnern der großen EU - Länder si...</td>\n      <td>Unter den Einwohnern der großen EU - Länder si...</td>\n      <td>am488</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1573</th>\n      <td>Protestzüge wälzen sich durch München , Eisner...</td>\n      <td>Protestzüge wälzen</td>\n      <td>sich1573</td>\n    </tr>\n    <tr>\n      <th>1573</th>\n      <td>Und in Sands bewege sich ja einiges .</td>\n      <td>Und in Sands bewege</td>\n      <td>sich1573</td>\n    </tr>\n    <tr>\n      <th>1573</th>\n      <td>Ulrike beugt sich über die Partitur .</td>\n      <td>Ulrike beugt</td>\n      <td>sich1573</td>\n    </tr>\n    <tr>\n      <th>1573</th>\n      <td>Am Anfang gab es viel Widerstand , man holpert...</td>\n      <td>Am Anfang gab es viel Widerstand , man holperte</td>\n      <td>sich1573</td>\n    </tr>\n    <tr>\n      <th>1573</th>\n      <td>Auf langen Zugfahrten klickt er sich deshalb d...</td>\n      <td>Auf langen Zugfahrten klickt er</td>\n      <td>sich1573</td>\n    </tr>\n  </tbody>\n</table>\n<p>8508 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contextleft = pd.read_pickle(\"../../data/pseudowords/contextleft_text.pickle\")\n",
    "\n",
    "def update_cue(row):\n",
    "    output = row[['example', 'cue']]\n",
    "    if row['cue'] == '':  # if the string in cue is empty\n",
    "        # match the index of row with contextleft['construction_id'] and match contextleft['text'] with row['example'] and create matching_entry\n",
    "        matching_entry = contextleft.loc[(contextleft['construction_id'] == row.name) & (contextleft['text'] == row['example']), 'contextleft'].tolist()\n",
    "        if len(matching_entry) > 0:\n",
    "            output = [matching_entry[0] + \" \" + row['example'], matching_entry[0]]\n",
    "    return output\n",
    "\n",
    "# Add the left context if there is no cue up until the pseudoword.\n",
    "#df[[\"example\", \"cue\"]] = df.apply(update_cue, axis=1)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T15:38:35.905973989Z",
     "start_time": "2024-01-29T15:38:35.824150748Z"
    }
   },
   "id": "a898840ef3c9c442"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                   example  \\\nconstruction pseudoword                                                      \n5            Und5        [Und schon gar nicht mit der Mehrwertsteuer .,...   \n             erst5       [Trainer Lucien Favre hatte schon seine beiden...   \n             gar5        [Es hat Afghanistan nicht stabilisiert und sch...   \n             nicht5      [Es hat Afghanistan nicht stabilisiert und sch...   \n             recht5      [Trainer Lucien Favre hatte schon seine beiden...   \n...                                                                    ...   \n1884         Gold1884    [Schweigen ist Silber , reden ist Gold ., Schw...   \n             Silber1884  [Schweigen ist Silber , reden ist Gold ., Schw...   \n             ist1884     [Schweigen ist Silber , reden ist Gold ., Schw...   \n1986         kaum1986    [Die Vorhut vor 20.000 Jahren war für das Ries...   \n1987         sehr1987    [Solche Menschen können sich sehr wohlfühlen o...   \n\n                                                                       cue  \nconstruction pseudoword                                                     \n5            Und5                     [, , , , , , , , , , , , , , , , , ]  \n             erst5       [Trainer Lucien Favre hatte schon seine beiden...  \n             gar5        [Es hat Afghanistan nicht stabilisiert und sch...  \n             nicht5      [Es hat Afghanistan, Dass es in der Familie nu...  \n             recht5      [Trainer Lucien Favre hatte schon seine beiden...  \n...                                                                    ...  \n1884         Gold1884    [Schweigen ist Silber , reden ist, Schweigen i...  \n             Silber1884  [Schweigen ist, Schweigen ist, Angeben ist, Sc...  \n             ist1884     [Schweigen, Schweigen, Angeben, Schweigen, \" Q...  \n1986         kaum1986    [Die Vorhut vor 20.000 Jahren war für das Ries...  \n1987         sehr1987    [Solche Menschen können sich, \" \" Das hat die ...  \n\n[506 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>example</th>\n      <th>cue</th>\n    </tr>\n    <tr>\n      <th>construction</th>\n      <th>pseudoword</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">5</th>\n      <th>Und5</th>\n      <td>[Und schon gar nicht mit der Mehrwertsteuer .,...</td>\n      <td>[, , , , , , , , , , , , , , , , , ]</td>\n    </tr>\n    <tr>\n      <th>erst5</th>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n    </tr>\n    <tr>\n      <th>gar5</th>\n      <td>[Es hat Afghanistan nicht stabilisiert und sch...</td>\n      <td>[Es hat Afghanistan nicht stabilisiert und sch...</td>\n    </tr>\n    <tr>\n      <th>nicht5</th>\n      <td>[Es hat Afghanistan nicht stabilisiert und sch...</td>\n      <td>[Es hat Afghanistan, Dass es in der Familie nu...</td>\n    </tr>\n    <tr>\n      <th>recht5</th>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">1884</th>\n      <th>Gold1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[Schweigen ist Silber , reden ist, Schweigen i...</td>\n    </tr>\n    <tr>\n      <th>Silber1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[Schweigen ist, Schweigen ist, Angeben ist, Sc...</td>\n    </tr>\n    <tr>\n      <th>ist1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[Schweigen, Schweigen, Angeben, Schweigen, \" Q...</td>\n    </tr>\n    <tr>\n      <th>1986</th>\n      <th>kaum1986</th>\n      <td>[Die Vorhut vor 20.000 Jahren war für das Ries...</td>\n      <td>[Die Vorhut vor 20.000 Jahren war für das Ries...</td>\n    </tr>\n    <tr>\n      <th>1987</th>\n      <th>sehr1987</th>\n      <td>[Solche Menschen können sich sehr wohlfühlen o...</td>\n      <td>[Solche Menschen können sich, \" \" Das hat die ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>506 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'construction'}, inplace=True)\n",
    "\n",
    "result_df = df.groupby(['construction', 'pseudoword']).agg({'example': list, 'cue': list})\n",
    "\n",
    "result_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T15:38:35.956992275Z",
     "start_time": "2024-01-29T15:38:35.859847486Z"
    }
   },
   "id": "4a4e3d92707b4c4"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             definition\n677   Bei der Konstruktion \"Additiv_Koordinativkompo...\n563   Bei der \"Gegenüberstellung:V2_V2-Konstruktion\"...\n696   Die \"Konjunktiv:V.conj-I-Konstruktion\" gehört ...\n488   Die \"Superlativ:am_meisten/wenigstenADJ-Konstr...\n674   Die \"Kausaler_Konnektor:weil-Konstruktion\" die...\n...                                                 ...\n875   Bei der Konstruktion (Kxn) \"Kategorisierung_Tr...\n1323  Die meist als Prädikativum verwendete Konstruk...\n85    Die \"Reduplikation_Quantifizierung:N1_über_N1-...\n1792  Bei der Konstruktion (Kxn) \"Prädikation_Negati...\n1573  Die \"Reflexive_Bewegung:NP_VP_REFL_PP-Konstruk...\n\n[211 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>definition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>677</th>\n      <td>Bei der Konstruktion \"Additiv_Koordinativkompo...</td>\n    </tr>\n    <tr>\n      <th>563</th>\n      <td>Bei der \"Gegenüberstellung:V2_V2-Konstruktion\"...</td>\n    </tr>\n    <tr>\n      <th>696</th>\n      <td>Die \"Konjunktiv:V.conj-I-Konstruktion\" gehört ...</td>\n    </tr>\n    <tr>\n      <th>488</th>\n      <td>Die \"Superlativ:am_meisten/wenigstenADJ-Konstr...</td>\n    </tr>\n    <tr>\n      <th>674</th>\n      <td>Die \"Kausaler_Konnektor:weil-Konstruktion\" die...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>875</th>\n      <td>Bei der Konstruktion (Kxn) \"Kategorisierung_Tr...</td>\n    </tr>\n    <tr>\n      <th>1323</th>\n      <td>Die meist als Prädikativum verwendete Konstruk...</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>Die \"Reduplikation_Quantifizierung:N1_über_N1-...</td>\n    </tr>\n    <tr>\n      <th>1792</th>\n      <td>Bei der Konstruktion (Kxn) \"Prädikation_Negati...</td>\n    </tr>\n    <tr>\n      <th>1573</th>\n      <td>Die \"Reflexive_Bewegung:NP_VP_REFL_PP-Konstruk...</td>\n    </tr>\n  </tbody>\n</table>\n<p>211 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../../out/definitions.pickle\", \"rb\") as definitions_file:\n",
    "    definitions = pd.DataFrame.from_dict(pickle.load(definitions_file), orient=\"index\", columns=[\"definition\"])\n",
    "    \n",
    "definitions"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-29T15:38:35.957661342Z",
     "start_time": "2024-01-29T15:38:35.903426189Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                   example  \\\nconstruction pseudoword                                                      \n5            Und5        [Und schon gar nicht mit der Mehrwertsteuer .,...   \n             erst5       [Trainer Lucien Favre hatte schon seine beiden...   \n             gar5        [Es hat Afghanistan nicht stabilisiert und sch...   \n             nicht5      [Es hat Afghanistan nicht stabilisiert und sch...   \n             recht5      [Trainer Lucien Favre hatte schon seine beiden...   \n...                                                                    ...   \n1884         Gold1884    [Schweigen ist Silber , reden ist Gold ., Schw...   \n             Silber1884  [Schweigen ist Silber , reden ist Gold ., Schw...   \n             ist1884     [Schweigen ist Silber , reden ist Gold ., Schw...   \n1986         kaum1986    [Die Vorhut vor 20.000 Jahren war für das Ries...   \n1987         sehr1987    [Solche Menschen können sich sehr wohlfühlen o...   \n\n                                                                       cue  \\\nconstruction pseudoword                                                      \n5            Und5                     [, , , , , , , , , , , , , , , , , ]   \n             erst5       [Trainer Lucien Favre hatte schon seine beiden...   \n             gar5        [Es hat Afghanistan nicht stabilisiert und sch...   \n             nicht5      [Es hat Afghanistan, Dass es in der Familie nu...   \n             recht5      [Trainer Lucien Favre hatte schon seine beiden...   \n...                                                                    ...   \n1884         Gold1884    [Schweigen ist Silber , reden ist, Schweigen i...   \n             Silber1884  [Schweigen ist, Schweigen ist, Angeben ist, Sc...   \n             ist1884     [Schweigen, Schweigen, Angeben, Schweigen, \" Q...   \n1986         kaum1986    [Die Vorhut vor 20.000 Jahren war für das Ries...   \n1987         sehr1987    [Solche Menschen können sich, \" \" Das hat die ...   \n\n                                                                definition  \nconstruction pseudoword                                                     \n5            Und5        Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...  \n             erst5       Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...  \n             gar5        Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...  \n             nicht5      Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...  \n             recht5      Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...  \n...                                                                    ...  \n1884         Gold1884    Die \"Intensivierung_Komparativ:Xist_SilberYist...  \n             Silber1884  Die \"Intensivierung_Komparativ:Xist_SilberYist...  \n             ist1884     Die \"Intensivierung_Komparativ:Xist_SilberYist...  \n1986         kaum1986    Die Konstruktion \"Relativierung:kaumADJ\" gehör...  \n1987         sehr1987    Die Konstruktion \"Intensivierung:sehrV\" gehört...  \n\n[506 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>example</th>\n      <th>cue</th>\n      <th>definition</th>\n    </tr>\n    <tr>\n      <th>construction</th>\n      <th>pseudoword</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">5</th>\n      <th>Und5</th>\n      <td>[Und schon gar nicht mit der Mehrwertsteuer .,...</td>\n      <td>[, , , , , , , , , , , , , , , , , ]</td>\n      <td>Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...</td>\n    </tr>\n    <tr>\n      <th>erst5</th>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...</td>\n    </tr>\n    <tr>\n      <th>gar5</th>\n      <td>[Es hat Afghanistan nicht stabilisiert und sch...</td>\n      <td>[Es hat Afghanistan nicht stabilisiert und sch...</td>\n      <td>Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...</td>\n    </tr>\n    <tr>\n      <th>nicht5</th>\n      <td>[Es hat Afghanistan nicht stabilisiert und sch...</td>\n      <td>[Es hat Afghanistan, Dass es in der Familie nu...</td>\n      <td>Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...</td>\n    </tr>\n    <tr>\n      <th>recht5</th>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">1884</th>\n      <th>Gold1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[Schweigen ist Silber , reden ist, Schweigen i...</td>\n      <td>Die \"Intensivierung_Komparativ:Xist_SilberYist...</td>\n    </tr>\n    <tr>\n      <th>Silber1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[Schweigen ist, Schweigen ist, Angeben ist, Sc...</td>\n      <td>Die \"Intensivierung_Komparativ:Xist_SilberYist...</td>\n    </tr>\n    <tr>\n      <th>ist1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[Schweigen, Schweigen, Angeben, Schweigen, \" Q...</td>\n      <td>Die \"Intensivierung_Komparativ:Xist_SilberYist...</td>\n    </tr>\n    <tr>\n      <th>1986</th>\n      <th>kaum1986</th>\n      <td>[Die Vorhut vor 20.000 Jahren war für das Ries...</td>\n      <td>[Die Vorhut vor 20.000 Jahren war für das Ries...</td>\n      <td>Die Konstruktion \"Relativierung:kaumADJ\" gehör...</td>\n    </tr>\n    <tr>\n      <th>1987</th>\n      <th>sehr1987</th>\n      <td>[Solche Menschen können sich sehr wohlfühlen o...</td>\n      <td>[Solche Menschen können sich, \" \" Das hat die ...</td>\n      <td>Die Konstruktion \"Intensivierung:sehrV\" gehört...</td>\n    </tr>\n  </tbody>\n</table>\n<p>506 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = pd.merge(result_df, definitions, how=\"inner\", left_on=\"construction\", right_index=True)\n",
    "examples"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T15:38:35.958306720Z",
     "start_time": "2024-01-29T15:38:35.903577366Z"
    }
   },
   "id": "238d2238bbdd91d8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Generieren neuer Sätze:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bc899cb800665fa"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.01952364,  0.00048042,  0.05060846, ...,  0.04258203,\n         0.05651806,  0.02429085],\n       [-0.00994319, -0.00676309, -0.00601289, ..., -0.03203335,\n        -0.03284921,  0.00028247],\n       [-0.03243406, -0.00804963, -0.02258722, ...,  0.04839412,\n         0.0025557 ,  0.01301195],\n       ...,\n       [ 0.00162825,  0.01625418,  0.0080498 , ..., -0.01727665,\n         0.01961022, -0.00274661],\n       [ 0.00529211,  0.00459571,  0.01711997, ...,  0.01059076,\n        -0.01628351, -0.0441331 ],\n       [-0.03313114,  0.00591089, -0.00273072, ..., -0.03151482,\n         0.01069049,  0.00970152]], dtype=float32)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudowords = [\n",
    "    np.load(f\"../../data/pseudowords/mbart/pseudowords_comapp_0_69.npy\"),\n",
    "    np.load(f\"../../data/pseudowords/mbart/pseudowords_comapp_69_93.npy\"),\n",
    "    np.load(f\"../../data/pseudowords/mbart/pseudowords_comapp_93_165.npy\"),\n",
    "    np.load(f\"../../data/pseudowords/mbart/pseudowords_comapp_165_176.npy\"),\n",
    "    np.load(f\"../../data/pseudowords/mbart/pseudowords_comapp_176_281.npy\"),\n",
    "    np.load(f\"../../data/pseudowords/mbart/pseudowords_comapp_281_364.npy\"),\n",
    "    np.load(f\"../../data/pseudowords/mbart/pseudowords_comapp_364_437.npy\"),\n",
    "    np.load(f\"../../data/pseudowords/mbart/pseudowords_comapp_437_562.npy\")\n",
    "]\n",
    "pseudowords = np.concatenate(pseudowords)\n",
    "pseudowords"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T15:38:35.958839749Z",
     "start_time": "2024-01-29T15:38:35.903725253Z"
    }
   },
   "id": "c9e6d940aa4aaace"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "            label\norder            \n0         \"\"Was13\n1            \"647\n3           (1597\n4           (1600\n5           (1602\n...           ...\n556     »Raus1316\n557    Ähnlich123\n559    ähnlich123\n560    ähnlich139\n561        über85\n\n[506 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n    </tr>\n    <tr>\n      <th>order</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"\"Was13</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"647</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(1597</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(1600</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>(1602</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>556</th>\n      <td>»Raus1316</td>\n    </tr>\n    <tr>\n      <th>557</th>\n      <td>Ähnlich123</td>\n    </tr>\n    <tr>\n      <th>559</th>\n      <td>ähnlich123</td>\n    </tr>\n    <tr>\n      <th>560</th>\n      <td>ähnlich139</td>\n    </tr>\n    <tr>\n      <th>561</th>\n      <td>über85</td>\n    </tr>\n  </tbody>\n</table>\n<p>506 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_data = []\n",
    "# TODO mBART-Order laden\n",
    "for i in range(0, 8):\n",
    "    csv_data.append(pd.read_csv(f\"../../data/pseudowords/mbart/order_{i}.csv\", sep=\";\", index_col=0, header=None, quotechar=\"|\", names=[\"order\", \"label\"]))\n",
    "csv_data = pd.concat(csv_data)\n",
    "csv_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T15:38:36.010945634Z",
     "start_time": "2024-01-29T15:38:35.947197358Z"
    }
   },
   "id": "621718c51c9db794"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(['\"\"Was13',\n  '\"647',\n  '(1597',\n  '(1600',\n  '(1602',\n  '(1637',\n  '(1641',\n  '(1643',\n  '(379',\n  '(579',\n  '(581',\n  '(584',\n  '(590',\n  '(592',\n  '(600',\n  '(886',\n  '(892',\n  '(900',\n  '(905',\n  '(907',\n  '(909',\n  '(917',\n  '(919',\n  '(921',\n  ')1597',\n  ')1600',\n  ')1637',\n  ')1641',\n  ')1643',\n  ')1792',\n  ')379',\n  ')579',\n  ')581',\n  ')584',\n  ')590',\n  ')592',\n  ')600',\n  ')886',\n  ')892',\n  ')900',\n  ')907',\n  ')909',\n  ')917',\n  ')919',\n  ')921',\n  ')«579',\n  ',1459',\n  ',973',\n  '-128',\n  '-651',\n  '-654',\n  '-875',\n  '-973',\n  ':595',\n  ':875',\n  ':973',\n  'Abstand683',\n  'Allein20',\n  'Aller1630',\n  'Als1315',\n  'Als133',\n  'Als1770',\n  'Am488',\n  'Am492',\n  'Am500',\n  'Amerika605',\n  'genauso122',\n  'genauso98',\n  'geschweige10',\n  'gewesen1459',\n  'gibt605',\n  'gleich100',\n  'gleich675',\n  'gleich676',\n  'gleich98',\n  'gleiche104',\n  'gleichen1777',\n  'gleichkam676',\n  'gleichkommen676',\n  'gleichkommt676',\n  'gleichkäme676',\n  'gleicht132',\n  'gold1554',\n  'habe605',\n  'haben605',\n  'hat605',\n  'hatte605',\n  'heisst1631',\n  'her1351',\n  'her1511',\n  'herunter1574',\n  'heute1459',\n  'hin1351',\n  'hin1511',\n  'hinaus1574',\n  'hindurch1574',\n  'hinunter1574',\n  'hätte1756',\n  'hätten1756',\n  'hättest1756',\n  'im1346',\n  'im1777',\n  'im557',\n  'in1316',\n  'in1777',\n  'in557',\n  'in605',\n  'in858',\n  'ist125',\n  'ist130',\n  'ist1313',\n  'ist1459',\n  'ist1461',\n  'ist1462',\n  'ist1554',\n  'ist1660',\n  'ist1715',\n  'ist1792',\n  'ist1835',\n  'ist1846',\n  'ist1881',\n  'ist1884',\n  'ist875',\n  'ist976',\n  'je111',\n  'jedermanns1329',\n  'jetzt1631',\n  'kam676',\n  'kann1593',\n  'kaum11',\n  'kaum1986',\n  'kein1461',\n  'kein1462',\n  'kein1525',\n  'kein1690',\n  'kein1715',\n  'kein1881',\n  'kein902',\n  'kein949',\n  'keine1461',\n  'keine1525',\n  'keine1715',\n  'keine1835',\n  'keine1881',\n  'keine605',\n  'keine902',\n  'Anstatt320',\n  'Art129',\n  'Arzt1509',\n  'Augenblick1301',\n  'Ausmaß1777',\n  'BRUTAL1503',\n  'Besser1762',\n  'Bis559',\n  'Brutal1503',\n  'Buche1346',\n  'Das1313',\n  'Das1461',\n  'Dass21',\n  'Dasselbe104',\n  'Der1301',\n  'Desto111',\n  'Die1681',\n  'Diese19',\n  'Dieser1301',\n  'Dieser19',\n  'Dieses19',\n  'Entweder1779',\n  'Es1313',\n  'Es605',\n  'Gefühl1301',\n  'Generation1126',\n  'Geschweige10',\n  'Gold1554',\n  'Gold1884',\n  'Hauptsache1033',\n  'Im557',\n  'In557',\n  'In858',\n  'Inbegriff1671',\n  'Ist1660',\n  'Je111',\n  'Jedermanns1329',\n  'Jener1301',\n  'Jetzt1631',\n  'Kein1525',\n  'Kein1715',\n  'Kein1835',\n  'Kein949',\n  'Keine(r1792',\n  'Keine1525',\n  'Keine1715',\n  'Keine1792',\n  'Keine1835',\n  'Keine902',\n  'Keine949',\n  'Keiner1792',\n  'Leben1461',\n  'Leben605',\n  'Lecker1649',\n  'Maß1777',\n  'Maße1777',\n  'Mit683',\n  'Moment1301',\n  'Mords651',\n  'Mutter1681',\n  'Neue875',\n  'Nicht1162',\n  'Nicht902',\n  'Niemand1792',\n  'Ponyhof1462',\n  'Raus1316',\n  'Reden1554',\n  'Riesen654',\n  'Silber1554',\n  'Silber1884',\n  'So1300',\n  'So1760',\n  'So1831',\n  'So22',\n  'So74',\n  'So98',\n  'Solch78',\n  'Solche78',\n  'Sowohl1134',\n  'Statt320',\n  'Tode1347',\n  'Trotz1630',\n  'Umfang1777',\n  'Umso111',\n  'Und11',\n  'Und5',\n  'Von1034',\n  'Von1629',\n  'Von1772',\n  'Was13',\n  'Was16',\n  'Was1846',\n  'Weder12',\n  'keine949',\n  'keiner1792',\n  'kommen1509',\n  'kommen676',\n  'kommt1509',\n  'kommt676',\n  'käme676',\n  'lassen1289',\n  'lecker1649',\n  'ließ1289',\n  'lässt1289',\n  'mag605',\n  'meinem605',\n  'meisten488',\n  'meisten492',\n  'mich1573',\n  'mich1574',\n  'mir1582',\n  'mit1846',\n  'mit683',\n  'mords651',\n  'muss1300',\n  'musste1509',\n  'neue875',\n  'neuen875',\n  'nicht.“1779',\n  'nicht1162',\n  'nicht1690',\n  'nicht1779',\n  'nicht902',\n  'nicht904',\n  'niemand1525',\n  'niemand1792',\n  'noch12',\n  'noch1770',\n  'nämliche104',\n  'ob1315',\n  'ob133',\n  'oder1162',\n  'oder1779',\n  'oder973',\n  'ohne1690',\n  'ohne949',\n  'ohnegleichen618',\n  'par1342',\n  'pur.»1323',\n  'pur1323',\n  'pur«1323',\n  'raus1316',\n  'recht5',\n  'rein1316',\n  'satt1324',\n  'schlechthin1556',\n  'schlechthin»1556',\n  'schon5',\n  'sehr1987',\n  'sei125',\n  'seien1660',\n  'Weil674',\n  'Weil681',\n  'Welch15',\n  'Wenn1291',\n  'Wie14',\n  'Wie1738',\n  'Wo976',\n  'Während320',\n  'Zeit605',\n  'Zeiten605',\n  'ab1574',\n  'aber902',\n  'allen1630',\n  'aller1630',\n  'aller1681',\n  'aller758',\n  'als1134',\n  'als133',\n  'als1762',\n  'als1770',\n  'als97',\n  'am488',\n  'am492',\n  'am500',\n  'an349',\n  'anstatt320',\n  'anstatt882',\n  'artig128',\n  'auch1134',\n  'auch1715',\n  'auch1835',\n  'auf1574',\n  'auf350',\n  'aus1316',\n  'besser1762',\n  'bis1509',\n  'bis559',\n  'bisschen762',\n  'bleibt1660',\n  'brutal1503',\n  'das1301',\n  'das1461',\n  'das875',\n  'dass135',\n  'dasselbe104',\n  'dem1777',\n  'den557',\n  'den671',\n  'denn10',\n  'der1509',\n  'der1681',\n  'der557',\n  'der875',\n  'desto111',\n  'die875',\n  'diese605',\n  'dieses19',\n  'durch1574',\n  'ebenso122',\n  'ebenso98',\n  'ein127',\n  'ein1715',\n  'ein1835',\n  'ein762',\n  'einander1574',\n  'eine129',\n  'eine1715',\n  'eine1835',\n  'eine605',\n  'einem127',\n  'einer127',\n  'entweder1779',\n  'er1004',\n  'er1346',\n  'erst5',\n  'es125',\n  'es1313',\n  'es1346',\n  'es1631',\n  'es605',\n  'euch1574',\n  'excellence1342',\n  'früher1459',\n  'für13',\n  'für1525',\n  'für350',\n  'gab605',\n  'ganz697',\n  'ganz777',\n  'gar5',\n  'gar697',\n  'gar777',\n  'geben605',\n  'gegeben605',\n  'gegen83',\n  'geht1300',\n  'sein1289',\n  'selben1777',\n  'sich1573',\n  'sich1574',\n  'sich1582',\n  'sie1346',\n  'silber1554',\n  'sind130',\n  'sind1459',\n  'sind1554',\n  'sind1660',\n  'sind1881',\n  'sind875',\n  'sind976',\n  'so1134',\n  'so135',\n  'so1760',\n  'so1831',\n  'so74',\n  'so98',\n  'solch78',\n  'soll605',\n  'sondergleichen618',\n  'sondergleichen»618',\n  'sondern902',\n  'sowohl1134',\n  'stand1346',\n  'statt320',\n  'statt882',\n  'steht1346',\n  'um350',\n  'umso111',\n  'und11',\n  'und1140',\n  'und1849',\n  'und5',\n  'und697',\n  'und777',\n  'und904',\n  'uns1574',\n  'uns1582',\n  'unter671',\n  'von1034',\n  'von1035',\n  'von127',\n  'von1629',\n  'von1772',\n  'vor559',\n  'war1313',\n  'war1459',\n  'war1461',\n  'war1462',\n  'war1660',\n  'war1770',\n  'war1846',\n  'war1881',\n  'waren1459',\n  'waren1770',\n  'waren1881',\n  'was1029',\n  'was13',\n  'was1459',\n  'was1846',\n  'weder12',\n  'wegen1629',\n  'wegen1772',\n  'weil674',\n  'weil681',\n  'welch15',\n  'wenig762',\n  'wenigsten488',\n  'wenigsten492',\n  'wenn1291',\n  'wenn136',\n  'wie101',\n  'wie103',\n  'wie125',\n  'wie130',\n  'wie1346',\n  'wie136',\n  'wie1738',\n  'wird1660',\n  'wird605',\n  'wogegen320',\n  'wohingegen320',\n  'wohl11',\n  'wohl1134',\n  'wäre130',\n  'wäre1660',\n  'wäre1756',\n  'wäre1846',\n  'wären1756',\n  'wärest1756',\n  'wärst1756',\n  'würde392',\n  'würden392',\n  'würdest392',\n  'zu1034',\n  'zu1035',\n  'zu1347',\n  'zu1574',\n  'zu320',\n  'zum1313',\n  'zum1630',\n  '«Besser1762',\n  '«Keine949',\n  '«Raus1316',\n  '»Entweder1779',\n  '»Raus1316',\n  'Ähnlich123',\n  'ähnlich123',\n  'ähnlich139',\n  'über85'],\n 506)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbart_tokens = [d[0] for d in csv_data.values]\n",
    "\n",
    "mbart_tokens, len(mbart_tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T15:38:36.011820927Z",
     "start_time": "2024-01-29T15:38:35.947342015Z"
    }
   },
   "id": "d55848226af1aa95"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the vanilla mbart model:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1fd4b9029d49e1e"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "Embedding(250054, 1024, padding_idx=1)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MBartForConditionalGeneration.from_pretrained(\n",
    "    \"facebook/mbart-large-50\", return_dict=True\n",
    ") \n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\n",
    "    \"facebook/mbart-large-50\", src_lang=\"de_DE\", tgt_lang=\"de_DE\"\n",
    ")\n",
    "model.model.encoder.embed_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T15:38:47.132904406Z",
     "start_time": "2024-01-29T15:38:35.947507572Z"
    }
   },
   "id": "e82730a36da5ce9c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add to existing embeddings:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31cb60117910e817"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "Embedding(250560, 1024)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_embeddings = torch.cat((model.model.shared.weight, torch.tensor(pseudowords)), dim=0)\n",
    "model.model.encoder.embed_tokens = torch.nn.Embedding.from_pretrained(combined_embeddings)\n",
    "model.model.encoder.embed_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T15:38:47.133963095Z",
     "start_time": "2024-01-29T15:38:47.091541760Z"
    }
   },
   "id": "de2759094c5daff5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add to existing tokens:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36118990fc6027ce"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 250560. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": "Embedding(250560, 1024)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(mbart_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T15:38:49.589071854Z",
     "start_time": "2024-01-29T15:38:47.101124581Z"
    }
   },
   "id": "5e0c6c41fda55604"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# This part simulates the behavior during training, preventing the Decoder from returning the pseudoword itself.\n",
    "def freeze(model, new_embeds):\n",
    "    # Freeze all the parameters except the word embeddings\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'model.shared' in name:\n",
    "            param.requires_grad = True\n",
    "        else:\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # The \"decoder\" in BERT maps from hidden to output. This is analogous to \"lm_head\" in mBART.\n",
    "    original_weight = model.lm_head.weight\n",
    "    original_bias = model.final_logits_bias\n",
    "    # The vocabulary of the decoder doesn't need the new pseudoword tokens and would be too big:\n",
    "    original_decoder_embed_tokens_weight = model.model.decoder.embed_tokens.weight\n",
    "\n",
    "    # The argument len(tokenizer)-new_embeds should prevent the model from outputting the new tokens:\n",
    "    lm_head = nn.Linear(in_features=1024, out_features=len(tokenizer) - new_embeds, bias=False)\n",
    "    lm_head.weight.requires_grad = False\n",
    "    model.register_buffer(\"final_logits_bias\", torch.zeros((1, model.model.shared.num_embeddings - new_embeds)))\n",
    "    lm_head.weight.data.copy_(original_weight.data[:-new_embeds])\n",
    "    model.final_logits_bias.copy_(original_bias[:, :-new_embeds])\n",
    "    model.lm_head = lm_head\n",
    "    decoder_embed_tokens = nn.Embedding(len(tokenizer) - new_embeds, model.config.d_model, model.config.pad_token_id)\n",
    "    # For decoder, see above:\n",
    "    decoder_embed_tokens.weight.data.copy_(original_decoder_embed_tokens_weight.data[:-new_embeds])\n",
    "    decoder_embed_tokens.requires_grad_(False)\n",
    "    model.model.decoder.embed_tokens = decoder_embed_tokens\n",
    "    model.config.vocab_size -= new_embeds\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T15:38:49.603858383Z",
     "start_time": "2024-01-29T15:38:49.592207622Z"
    }
   },
   "id": "f267906f534bdff3",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "MBartForConditionalGeneration(\n  (model): MBartModel(\n    (shared): Embedding(250560, 1024)\n    (encoder): MBartEncoder(\n      (embed_tokens): Embedding(250560, 1024)\n      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x MBartEncoderLayer(\n          (self_attn): MBartAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): MBartDecoder(\n      (embed_tokens): Embedding(250054, 1024, padding_idx=1)\n      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x MBartDecoderLayer(\n          (self_attn): MBartAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MBartAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=1024, out_features=250054, bias=False)\n)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = freeze(model, len(mbart_tokens))\n",
    "model.to(\"cuda:0\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T15:38:53.197980897Z",
     "start_time": "2024-01-29T15:38:49.595572016Z"
    }
   },
   "id": "29a15c814c4d9e1e",
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "Complete the cues:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b006ebc8aa40484"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/506 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e887e8ce81c642cb82a592924ff4aaac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...:.........................................:....::................................................................................................................:..............................................................:........................:::::::...................................................................:...............................................................:...."
     ]
    }
   ],
   "source": [
    "def complete_cues(row):\n",
    "    try:\n",
    "        output_texts = []\n",
    "        scores = []\n",
    "        for cue, example in zip(row[\"cue\"], row[\"example\"]):\n",
    "            assert row[\"pseudoword\"].iloc[0] in mbart_tokens  # skip pseudoword embeddings that haven't been learned\n",
    "            \n",
    "            input_text = \"</s> \" + cue + \" \" + row[\"pseudoword\"].iloc[0] + \" <mask> </s> de_DE \"\n",
    "            target_length = int(1.5 * len(example))  # allow double the length of the original sentence\n",
    "            \n",
    "            input_ids = tokenizer([input_text], add_special_tokens=False, return_tensors=\"pt\")[\"input_ids\"].to(\"cuda:0\")\n",
    "            outputs = model.generate(input_ids, max_length=target_length, num_return_sequences=1, num_beams=50, output_scores=True, return_dict_in_generate=True)\n",
    "            output_text = tokenizer.batch_decode(outputs.sequences, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "            score = torch.exp(outputs.sequences_scores)\n",
    "            output_texts += output_text\n",
    "            \n",
    "            scores.append(score)\n",
    "        print(\".\", end=\"\")\n",
    "        return pd.Series({\"construction\": row[\"construction\"], \"pseudoword\": row[\"pseudoword\"].iloc[0], \"orig_example\": row[\"example\"], \"generated\": str(output_texts), \"scores\": str([float(score) for score in scores])})\n",
    "    except Exception as e:\n",
    "        print(\":\", end=\"\")\n",
    "        return pd.Series({\"construction\": row[\"construction\"], \"pseudoword\": row[\"pseudoword\"].iloc[0], \"orig_example\": row[\"example\"], \"generated\": str(e), \"scores\": \"[-1.0]\"})\n",
    "\n",
    "examples_reset = examples.reset_index()\n",
    "pseudoword_output_scores = examples_reset[[\"construction\", \"pseudoword\", \"example\", \"cue\", \"pseudoword\"]].progress_apply(complete_cues, axis=1)\n",
    "pseudoword_output_scores"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-29T15:38:53.202374070Z"
    }
   },
   "id": "b7fc546c4aeb79b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "examples = pseudoword_output_scores[[\"pseudoword\", \"generated\", \"scores\"]]\n",
    "\n",
    "examples"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "14e01733b5a4aeba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "examples.to_csv(f\"../../out/comapp/mbart/data_mbart.tsv\", sep=\"\\t\", decimal=\",\")\n",
    "#examples.to_excel(f\"../../out/comapp/mbart/data_mbart.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "93ee2263ebe468ba"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pseudoword_output_scores.to_csv(\"../../out/comapp/mbart/data_mbart_complete.tsv\", sep=\"\\t\", decimal=\",\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a890185b466ac02e",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
