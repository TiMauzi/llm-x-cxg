{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-23T16:14:09.616192400Z",
     "start_time": "2024-01-23T16:14:09.604813100Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertForNextSentencePrediction, BertTokenizer\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['\"\"Was13',\n '\"647',\n '\"Wir-äh-spielen-äh-in-der-äh-Champions-League647',\n '(1597',\n '(1600',\n '(1602',\n '(1624',\n '(1637',\n '(1639',\n '(1641',\n '(1643',\n '(1645',\n '(379',\n '(579',\n '(581',\n '(584',\n '(590',\n '(592',\n '(600',\n '(886',\n '(889',\n '(892',\n '(900',\n '(905',\n '(907',\n '(909',\n '(911',\n '(917',\n '(919',\n '(921',\n '(923',\n ')1597',\n ')1600',\n ')1602',\n ')1624',\n ')1637',\n ')1639',\n ')1641',\n ')1643',\n ')1645',\n ')1792',\n ')379',\n ')579',\n ')581',\n ')584',\n ')590',\n ')592',\n ')600',\n ')886',\n ')889',\n ')892',\n ')900',\n ')905',\n ')907',\n ')909',\n ')911',\n ')917',\n ')919',\n ')921',\n ')923',\n ')«579',\n ',1459',\n ',973',\n '-128',\n '-651',\n '-654',\n '-875',\n '-973',\n ':595',\n ':875',\n ':973',\n 'Abstand683',\n 'Allein20',\n 'Aller1630',\n 'Als1315',\n 'Als133',\n 'Als1770',\n 'Am488',\n 'Am492',\n 'Am500',\n 'Amerika605',\n 'Anstatt320',\n 'Art129',\n 'Arzt1509',\n 'Augenblick1301',\n 'Ausmaß1777',\n 'BRUTAL1503',\n 'Besser1762',\n 'Bis559',\n 'Brutal1503',\n 'Buche1346',\n 'Das1313',\n 'Das1461',\n 'Dass21',\n 'Dasselbe104',\n 'Der1301',\n 'Desto111',\n 'Die1681',\n 'Diese19',\n 'Dieser1301',\n 'Dieser19',\n 'Dieses19',\n 'Entweder1779',\n 'Es1313',\n 'Es605',\n 'Gefühl1301',\n 'Generation1126',\n 'Geschweige10',\n 'Gleiche104',\n 'Gold1554',\n 'Gold1884',\n 'Hauptsache1033',\n 'Im557',\n 'In557',\n 'In858',\n 'Inbegriff1671',\n 'Ist1660',\n 'Je111',\n 'Jedermanns1329',\n 'Jener1301',\n 'Jetzt1631',\n 'Kein1525',\n 'Kein1715',\n 'Kein1835',\n 'Kein949',\n 'Keine(r1792',\n 'Keine1525',\n 'Keine1715',\n 'Keine1792',\n 'Keine1835',\n 'Keine902',\n 'Keine949',\n 'Keiner1792',\n 'Leben1461',\n 'Leben605',\n 'Lecker1649',\n 'Maß1777',\n 'Maße1777',\n 'Mit1029',\n 'Mit683',\n 'Moment1301',\n 'Mords651',\n 'Mutter1681',\n 'Neue875',\n 'Nicht1162',\n 'Nicht902',\n 'Niemand1792',\n 'Ponyhof1462',\n 'Raus1316',\n 'Reden1554',\n 'Riesen654',\n 'Silber1554',\n 'Silber1884',\n 'So1300',\n 'So1760',\n 'So1831',\n 'So22',\n 'So74',\n 'So98',\n 'Solch78',\n 'Solche78',\n 'Sowohl1134',\n 'Statt320',\n 'Tode1347',\n 'Trotz1630',\n 'Umfang1777',\n 'Umso111',\n 'Und11',\n 'Und5',\n 'Von1034',\n 'Von1629',\n 'Von1772',\n 'Warum1029',\n 'Was1029',\n 'Was13',\n 'Was16',\n 'Was1846',\n 'Weder12',\n 'Weil674',\n 'Weil681',\n 'Welch15',\n 'Wem1029',\n 'Wenn1291',\n 'Wer1029',\n 'Wie1029',\n 'Wie14',\n 'Wie1738',\n 'Wo1029',\n 'Wo976',\n 'Während320',\n 'Zeit605',\n 'Zeiten605',\n '[1643',\n ']1643',\n 'ab1574',\n 'aber902',\n 'allen1630',\n 'aller1630',\n 'aller1681',\n 'aller758',\n 'als1134',\n 'als133',\n 'als1762',\n 'als1770',\n 'als97',\n 'am488',\n 'am492',\n 'am500',\n 'an349',\n 'anstatt320',\n 'anstatt882',\n 'artig128',\n 'auch1134',\n 'auch1715',\n 'auch1835',\n 'auf1574',\n 'auf350',\n 'aufhübschen1029',\n 'aus1316',\n 'ausbreiten1029',\n 'auslöste1029',\n 'badete1029',\n 'bedeutet1029',\n 'besser1762',\n 'betreffen1029',\n 'bis1509',\n 'bis559',\n 'bisschen762',\n 'bleibt1660',\n 'braucht1029',\n 'bringt1029',\n 'brutal1503',\n 'darstellen1029',\n 'das104',\n 'das1301',\n 'das1459',\n 'das1461',\n 'das875',\n 'dass135',\n 'dasselbe104',\n 'dem1777',\n 'den557',\n 'den671',\n 'denn10',\n 'der1509',\n 'der1681',\n 'der557',\n 'der875',\n 'desto111',\n 'die1681',\n 'die875',\n 'diese605',\n 'dieses19',\n 'durch1574',\n 'ebenso122',\n 'ebenso98',\n 'ein127',\n 'ein1715',\n 'ein1835',\n 'ein762',\n 'einander1574',\n 'eine129',\n 'eine1715',\n 'eine1835',\n 'eine605',\n 'einem127',\n 'einer127',\n 'entweder1779',\n 'er1004',\n 'er1346',\n 'er99',\n 'erst5',\n 'erzeugt1029',\n 'es125',\n 'es1313',\n 'es1346',\n 'es1631',\n 'es605',\n 'euch1574',\n 'excellence1342',\n 'fahre1029',\n 'früher1459',\n 'für13',\n 'für1525',\n 'für350',\n 'gab605',\n 'ganz697',\n 'ganz777',\n 'gar5',\n 'gar697',\n 'gar777',\n 'geben605',\n 'gegeben605',\n 'gegen83',\n 'gehen1029',\n 'geht1300',\n 'genauso122',\n 'genauso98',\n 'geschweige10',\n 'gewesen1459',\n 'gibt605',\n 'gleich100',\n 'gleich675',\n 'gleich676',\n 'gleich98',\n 'gleiche104',\n 'gleichen1777',\n 'gleichkam676',\n 'gleichkommen676',\n 'gleichkommt676',\n 'gleichkäme676',\n 'gleicht132',\n 'gold1554',\n 'habe605',\n 'haben1029',\n 'haben605',\n 'hat605',\n 'hatte605',\n 'heisst1631',\n 'her1351',\n 'her1511',\n 'herunter1574',\n 'heute1459',\n 'hin1351',\n 'hin1511',\n 'hinaus1574',\n 'hindurch1574',\n 'hinunter1574',\n 'hätte1756',\n 'hätten1756',\n 'hättest1756',\n 'im1346',\n 'im1777',\n 'im557',\n 'in1316',\n 'in1777',\n 'in557',\n 'in605',\n 'in858',\n 'irrte1029',\n 'isst1029',\n 'ist1029',\n 'ist125',\n 'ist130',\n 'ist1313',\n 'ist1459',\n 'ist1461',\n 'ist1462',\n 'ist1554',\n 'ist1660',\n 'ist1715',\n 'ist1792',\n 'ist1835',\n 'ist1846',\n 'ist1881',\n 'ist1884',\n 'ist875',\n 'ist976',\n 'je111',\n 'jedermanns1329',\n 'jetzt1631',\n 'kam676',\n 'kann1593',\n 'kaum11',\n 'kaum1986',\n 'kein1461',\n 'kein1462',\n 'kein1525',\n 'kein1690',\n 'kein1715',\n 'kein1881',\n 'kein902',\n 'kein949',\n 'keine1461',\n 'keine1525',\n 'keine1715',\n 'keine1835',\n 'keine1881',\n 'keine605',\n 'keine902',\n 'keine949',\n 'keiner1792',\n 'kleiden1029',\n 'kommen1509',\n 'kommen676',\n 'kommt1509',\n 'kommt676',\n 'kostet1029',\n 'käme676',\n 'lachen1029',\n 'lassen1029',\n 'lassen1289',\n 'lebte1029',\n 'lecker1649',\n 'ließ1289',\n 'lässt1289',\n 'läuft1029',\n 'macht1029',\n 'machte1029',\n 'mag605',\n 'meinem605',\n 'meisten488',\n 'meisten492',\n 'mich1573',\n 'mich1574',\n 'mir1582',\n 'mit1846',\n 'mit683',\n 'mords651',\n 'muss1300',\n 'musste1509',\n 'müssen1029',\n 'neue875',\n 'neuen875',\n 'nicht.“1779',\n 'nicht1162',\n 'nicht1690',\n 'nicht1779',\n 'nicht5',\n 'nicht902',\n 'nicht904',\n 'niemand1525',\n 'niemand1792',\n 'noch12',\n 'noch1770',\n 'nämliche104',\n 'nützt1029',\n 'ob1315',\n 'ob133',\n 'oder1162',\n 'oder1779',\n 'oder973',\n 'ohne1690',\n 'ohne949',\n 'ohnegleichen618',\n 'par1342',\n 'pur.»1323',\n 'pur1323',\n 'pur«1323',\n 'raus1316',\n 'recht5',\n 'redet1029',\n 'rein1316',\n 'ruiniert1029',\n 'satt1324',\n 'schlechthin1556',\n 'schlechthin»1556',\n 'schon5',\n 'schufen1029',\n 'schützt1029',\n 'sehr1987',\n 'sei125',\n 'seien1660',\n 'sein1289',\n 'selben1777',\n 'sich1573',\n 'sich1574',\n 'sich1582',\n 'sie1346',\n 'silber1554',\n 'sind1029',\n 'sind130',\n 'sind1459',\n 'sind1554',\n 'sind1660',\n 'sind1881',\n 'sind875',\n 'sind976',\n 'so1134',\n 'so135',\n 'so1760',\n 'so1831',\n 'so74',\n 'so98',\n 'solch78',\n 'soll605',\n 'sollten1029',\n 'sondergleichen618',\n 'sondergleichen»618',\n 'sondern902',\n 'sowohl1134',\n 'stand1346',\n 'statt320',\n 'statt882',\n 'steht1346',\n 'um350',\n 'umso111',\n 'und1029',\n 'und11',\n 'und1140',\n 'und1849',\n 'und5',\n 'und697',\n 'und777',\n 'und904',\n 'uns1574',\n 'uns1582',\n 'unter671',\n 'verdient1029',\n 'verändern1029',\n 'von1034',\n 'von1035',\n 'von127',\n 'von1629',\n 'von1772',\n 'vor559',\n 'war1313',\n 'war1459',\n 'war1461',\n 'war1462',\n 'war1660',\n 'war1770',\n 'war1846',\n 'war1881',\n 'waren1459',\n 'waren1770',\n 'waren1881',\n 'was1029',\n 'was13',\n 'was1459',\n 'was1846',\n 'weder12',\n 'wegen1629',\n 'wegen1772',\n 'weil674',\n 'weil681',\n 'welch15',\n 'wem1029',\n 'wenig762',\n 'wenigsten488',\n 'wenigsten492',\n 'wenn1291',\n 'wenn136',\n 'werden1029',\n 'wie101',\n 'wie103',\n 'wie125',\n 'wie130',\n 'wie1346',\n 'wie136',\n 'wie1738',\n 'will1029',\n 'wird1029',\n 'wird1660',\n 'wird605',\n 'wissen1029',\n 'wo1029',\n 'wogegen320',\n 'wohingegen320',\n 'wohl11',\n 'wohl1134',\n 'wollen1029',\n 'wäre130',\n 'wäre1660',\n 'wäre1756']"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudowords = []\n",
    "for i in range(15):\n",
    "    pseudowords.append(np.load(f\"../../data/pseudowords/bsbbert/pseudowords_comapp_bsbbert_{i*37}_{i*37+37}.npy\"))\n",
    "pseudowords = np.concatenate(pseudowords)\n",
    "\n",
    "csv_data = []\n",
    "for i in range(1, 16):\n",
    "    csv_data.append(pd.read_csv(f\"../../data/pseudowords/bsbbert/order_bsbbert_{i}.csv\", sep=\";\", index_col=0, header=None, quotechar=\"|\", names=[\"order\", \"label\"]))\n",
    "csv_data = pd.concat(csv_data)\n",
    "\n",
    "bert_tokens = [d[0] for d in csv_data.values]\n",
    "bert_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T16:14:09.646266500Z",
     "start_time": "2024-01-23T16:14:09.611196Z"
    }
   },
   "id": "c395ff268451a4b2",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForNextSentencePrediction were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 31657. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": "BertForNextSentencePrediction(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(31657, 768)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (cls): BertOnlyNSPHead(\n    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n  )\n)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForNextSentencePrediction.from_pretrained(\"dbmdz/bert-base-german-cased\", return_dict=True)\n",
    "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-german-cased')\n",
    "\n",
    "combined_embeddings = torch.cat((model.bert.embeddings.word_embeddings.weight, torch.tensor(pseudowords)), dim=0)\n",
    "model.bert.embeddings.word_embeddings = torch.nn.Embedding.from_pretrained(combined_embeddings)\n",
    "tokenizer.add_tokens(bert_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.to(\"cuda:0\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T16:14:11.324178600Z",
     "start_time": "2024-01-23T16:14:09.638268500Z"
    }
   },
   "id": "737979872a7f76f1",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(\"../../out/definitions.pickle\", \"rb\") as file:\n",
    "    definitions = pickle.load(file)\n",
    "with open(\"../../out/sentences.pickle\", \"rb\") as file:\n",
    "    sentences = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T16:14:11.324178600Z",
     "start_time": "2024-01-23T16:14:11.317109300Z"
    }
   },
   "id": "eb7917f993cd42d8",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def find_examples(definition, examples):\n",
    "    predictions = {}\n",
    "    tok_examples = [tokenizer.tokenize(\"Zum Beispiel: \" + example) for example in examples]\n",
    "    tok_definition = tokenizer.tokenize(definition)\n",
    "    for num, tok_example in enumerate(tok_examples):\n",
    "        len_prompt = len(tok_definition) + len(tok_example) + 3  # 3 extra tokens for [CLS] and [SEP] (2x)\n",
    "        if len_prompt > 512:\n",
    "            # shorten the definition so that the example fits fully, and add \"...\" (again, 3 additional tokens)\n",
    "            prompt = tokenizer.convert_tokens_to_string(tok_definition[:512-len(tok_example)-3-3]) + \" ...\"\n",
    "        else:\n",
    "            prompt = tokenizer.convert_tokens_to_string(tok_definition)\n",
    "            \n",
    "        inputs = tokenizer(prompt, tokenizer.convert_tokens_to_string(tok_example), return_tensors=\"pt\").to(\"cuda:0\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predictions[num] = logits[0, 0] > logits[0, 1]  # next sentence is not random\n",
    "    res = [examples[num] for num, p in predictions.items() if p]  # return all sentences which have been classified as correct\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T16:14:11.336403400Z",
     "start_time": "2024-01-23T16:14:11.327223600Z"
    }
   },
   "id": "693ad2b73bd9bcb",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d01289699fdc462f94236eb6462aad90"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "55e27ea47bef4f249404c0ae3bf5d942"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69247076d13e4d39a32a7f324603860c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d2f813a23134b84a8c6db03dbf7eea8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12f40654e4a04e03bf88bfa0f96a0ab5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5a3d87c26e648a48b066b5991ba62ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[30], line 23\u001B[0m\n\u001B[0;32m     20\u001B[0m false_sentences \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(random\u001B[38;5;241m.\u001B[39mchoices(others, k\u001B[38;5;241m=\u001B[39mnum_false))\n\u001B[0;32m     21\u001B[0m examples \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(false_sentences \u001B[38;5;241m|\u001B[39m true_sentences)\n\u001B[1;32m---> 23\u001B[0m positive_predicted \u001B[38;5;241m=\u001B[39m find_examples(definition, examples)\n\u001B[0;32m     24\u001B[0m negative_predicted \u001B[38;5;241m=\u001B[39m [ex \u001B[38;5;28;01mfor\u001B[39;00m ex \u001B[38;5;129;01min\u001B[39;00m examples \u001B[38;5;28;01mif\u001B[39;00m ex \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m positive_predicted]\n\u001B[0;32m     26\u001B[0m true_positives \u001B[38;5;241m=\u001B[39m [pr \u001B[38;5;28;01mfor\u001B[39;00m pr \u001B[38;5;129;01min\u001B[39;00m positive_predicted \u001B[38;5;28;01mif\u001B[39;00m pr \u001B[38;5;129;01min\u001B[39;00m true_sentences]\n",
      "Cell \u001B[1;32mIn[29], line 18\u001B[0m, in \u001B[0;36mfind_examples\u001B[1;34m(definition, examples)\u001B[0m\n\u001B[0;32m     16\u001B[0m     logits \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mlogits\n\u001B[0;32m     17\u001B[0m     predictions[num] \u001B[38;5;241m=\u001B[39m logits[\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m>\u001B[39m logits[\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m]  \u001B[38;5;66;03m# next sentence is not random\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m res \u001B[38;5;241m=\u001B[39m [examples[num] \u001B[38;5;28;01mfor\u001B[39;00m num, p \u001B[38;5;129;01min\u001B[39;00m predictions\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m p]  \u001B[38;5;66;03m# return all sentences which have been classified as correct\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
      "Cell \u001B[1;32mIn[29], line 18\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     16\u001B[0m     logits \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mlogits\n\u001B[0;32m     17\u001B[0m     predictions[num] \u001B[38;5;241m=\u001B[39m logits[\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m>\u001B[39m logits[\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m]  \u001B[38;5;66;03m# next sentence is not random\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m res \u001B[38;5;241m=\u001B[39m [examples[num] \u001B[38;5;28;01mfor\u001B[39;00m num, p \u001B[38;5;129;01min\u001B[39;00m predictions\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m p]  \u001B[38;5;66;03m# return all sentences which have been classified as correct\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "random.seed(15)\n",
    "attempts = 15\n",
    "for num_true in range(0, 5):\n",
    "    for num_false in range(0, 5):\n",
    "        if not num_true and not num_false:\n",
    "            continue  # skip (0, 0)\n",
    "        result = []\n",
    "        for key, definition in tqdm(definitions.items()):\n",
    "            others = list(itertools.chain.from_iterable([sentence_list for constr, sentence_list in sentences.items() if int(constr) != int(key)]))  # flatten all other sentences which are not part of the current construction\n",
    "            \n",
    "            for attempt in range(attempts):\n",
    "                try:\n",
    "                    # pick the true positives\n",
    "                    true_sentences = {random.choice(list(sentences[int(key)])) for t in range(num_true)}\n",
    "                except KeyError:\n",
    "                    result.append(pd.Series({\"constr\": key, \"definition\": definition}))\n",
    "                    continue\n",
    "    \n",
    "                # pick random false positives from the other sentences\n",
    "                false_sentences = set(random.choices(others, k=num_false))\n",
    "                examples = list(false_sentences | true_sentences)\n",
    "                \n",
    "                positive_predicted = find_examples(definition, examples)\n",
    "                negative_predicted = [ex for ex in examples if ex not in positive_predicted]\n",
    "                \n",
    "                true_positives = [pr for pr in positive_predicted if pr in true_sentences]\n",
    "                false_positives = [pr for pr in positive_predicted if pr in false_sentences]\n",
    "                false_negatives = [pr for pr in negative_predicted if pr in true_sentences]\n",
    "                true_negatives = [pr for pr in negative_predicted if pr in false_sentences]\n",
    "                \n",
    "                if len(true_positives) + len(false_positives) > 0:\n",
    "                    precision = len(true_positives) / (len(true_positives) + len(false_positives))\n",
    "                else:\n",
    "                    precision = 1.0  # nothing found, so all things found are correct\n",
    "                \n",
    "                if len(true_positives) > 0:\n",
    "                    recall = len(true_positives) / (len(true_positives) + len(false_negatives))\n",
    "                else:\n",
    "                    recall = 1.0  # all found\n",
    "                    \n",
    "                result.append(pd.Series({\n",
    "                    \"constr\": key, \n",
    "                    \"definition\": definition, \n",
    "                    \"examples\": examples, \n",
    "                    \"positive_predicted\": positive_predicted,\n",
    "                    \"negative_predicted\": negative_predicted,\n",
    "                    \"true_positives\": true_positives,\n",
    "                    \"false_positives\": false_positives,\n",
    "                    \"false_negatives\": false_negatives,\n",
    "                    \"true_negatives\": true_negatives,\n",
    "                    \"precision\": precision,\n",
    "                    \"recall\": recall,\n",
    "                    \"f1\": (2 * precision * recall) / (precision + recall),\n",
    "                    \"accuracy\": (len(true_positives) + len(true_negatives)) / (len(true_sentences) + len(false_sentences))\n",
    "                }))\n",
    "                \n",
    "        result = pd.DataFrame(result)\n",
    "        result.to_csv(f\"../../out/comapp/result_{num_true}t_vs_{num_false}f_{attempts}attempts_bsbbert.tsv\", sep=\"\\t\", decimal=\",\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T16:24:36.012348100Z",
     "start_time": "2024-01-23T16:14:11.337405900Z"
    }
   },
   "id": "ecad5aeec67bfd80",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "kelex = csv_data.copy()\n",
    "kelex['constr'] = csv_data['label'].str.extract('(\\d+)').astype(int)\n",
    "#kelex.set_index('constr', inplace=True)\n",
    "kelex = kelex.groupby('constr')['label'].apply(set).to_dict()\n",
    "kelex"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T16:08:15.017653Z",
     "start_time": "2024-01-23T16:08:15.009647400Z"
    }
   },
   "id": "cd5df0ed9a88a378",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO\n",
    "random.seed(15)\n",
    "attempts = 10\n",
    "for num_true in range(2, 8):\n",
    "    result = []\n",
    "    for key, definition in tqdm(definitions.items()):\n",
    "        for attempt in range(attempts):\n",
    "            try:\n",
    "                sentence = random.choice(list(sentences[int(key)]))\n",
    "            except KeyError:\n",
    "                # print(None, None, None)\n",
    "                result.append(pd.Series({\"constr\": key, \"definition\": definition, \"example\": None, \"prediction\": None, \"correct\": None}))\n",
    "                continue\n",
    "            sentence_kelex = []\n",
    "            if kelex.get(key):\n",
    "                for token in sentence.split():\n",
    "                    new_token = token\n",
    "                    # assert kelex.get(key) is not None\n",
    "                    for pseudoword in kelex[key]:\n",
    "                        if token == re.findall(r'\\D+', pseudoword)[0]:\n",
    "                            new_token = pseudoword\n",
    "                            break\n",
    "                    sentence_kelex.append(new_token)\n",
    "                sentence_kelex = \" \".join(sentence_kelex)\n",
    "            else:\n",
    "                continue  # skip constructions without kelex\n",
    "                # sentence_kelex = sentence\n",
    "            others = itertools.chain.from_iterable([sentence_list for constr, sentence_list in sentences.items() if int(constr) != int(key)])\n",
    "            others = random.choices(list(others), k=num_true)\n",
    "            examples = list(set(others) | {sentence_kelex})\n",
    "            positive_predicted = find_examples(definition, examples)\n",
    "            # print(prediction == sentence_kelex, sentence, prediction)\n",
    "            result.append(pd.Series({\"constr\": key, \"definition\": definition, \"example\": sentence, \"example_kelex\": sentence_kelex, \"prediction\": positive_predicted, \"correct\": positive_predicted == sentence_kelex}))\n",
    "    result = pd.DataFrame(result)\n",
    "    result.to_csv(f\"../../out/comapp/result_1_vs_{num_true}_kelex_{attempts}attempts_bsbbert.tsv\", sep=\"\\t\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-23T15:51:04.305253Z"
    }
   },
   "id": "cfdb3dc48dea6759",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "random.seed(15)\n",
    "attempts = 10\n",
    "for num_true in range(2, 8):\n",
    "    result = []\n",
    "    for key, definition in tqdm(definitions.items()):\n",
    "        for attempt in range(attempts):\n",
    "            try:\n",
    "                sentence = random.choice(list(sentences[int(key)]))\n",
    "            except KeyError:\n",
    "                # print(None, None, None)\n",
    "                result.append(pd.Series({\"constr\": key, \"definition\": definition, \"example\": None, \"prediction\": None, \"correct\": None}))\n",
    "                continue\n",
    "            sentence_kelex = []\n",
    "            if kelex.get(key):\n",
    "                for token in sentence.split():\n",
    "                    new_token = token\n",
    "                    # assert kelex.get(key) is not None\n",
    "                    for pseudoword in kelex[key]:\n",
    "                        if token == re.findall(r'\\D+', pseudoword)[0]:\n",
    "                            new_token = pseudoword\n",
    "                            break\n",
    "                    sentence_kelex.append(new_token)\n",
    "                sentence_kelex = \" \".join(sentence_kelex)\n",
    "            else:\n",
    "                # continue  # skip constructions without kelex\n",
    "                sentence_kelex = sentence\n",
    "            others = itertools.chain.from_iterable([sentence_list for constr, sentence_list in sentences.items() if int(constr) != int(key)])\n",
    "            others = random.choices(list(others), k=num_true)\n",
    "            examples = list(set(others) | {sentence_kelex})\n",
    "            positive_predicted = find_examples(definition, examples)\n",
    "            # print(prediction == sentence_kelex, sentence, prediction)\n",
    "            result.append(pd.Series({\"constr\": key, \"definition\": definition, \"example\": sentence, \"example_kelex\": sentence_kelex, \"prediction\": positive_predicted, \"correct\": positive_predicted == sentence_kelex}))\n",
    "    result = pd.DataFrame(result)\n",
    "    result.to_csv(f\"../../out/comapp/result_1_vs_{num_true}_kelex_all_{attempts}attempts_bsbbert.tsv\", sep=\"\\t\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T15:51:04.307255400Z",
     "start_time": "2024-01-23T15:51:04.306254600Z"
    }
   },
   "id": "b6a6959b0d4948b3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-23T15:51:04.307255400Z"
    }
   },
   "id": "e1ae91af86700012"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
