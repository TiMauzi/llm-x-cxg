{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertForNextSentencePrediction, BertTokenizer\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pseudowords = []\n",
    "for i in range(15):\n",
    "    pseudowords.append(np.load(f\"../../data/pseudowords/bsbbert/pseudowords_comapp_bsbbert_{i*37}_{i*37+37}.npy\"))\n",
    "pseudowords = np.concatenate(pseudowords)\n",
    "\n",
    "csv_data = []\n",
    "for i in range(1, 16):\n",
    "    csv_data.append(pd.read_csv(f\"../../data/pseudowords/bsbbert/order_bsbbert_{i}.csv\", sep=\";\", index_col=0, header=None, quotechar=\"|\", names=[\"order\", \"label\"]))\n",
    "csv_data = pd.concat(csv_data)\n",
    "\n",
    "bert_tokens = [d[0] for d in csv_data.values]\n",
    "bert_tokens"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c395ff268451a4b2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = BertForNextSentencePrediction.from_pretrained(\"dbmdz/bert-base-german-cased\", return_dict=True)\n",
    "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-german-cased')\n",
    "\n",
    "combined_embeddings = torch.cat((model.bert.embeddings.word_embeddings.weight, torch.tensor(pseudowords)), dim=0)\n",
    "model.bert.embeddings.word_embeddings = torch.nn.Embedding.from_pretrained(combined_embeddings)\n",
    "tokenizer.add_tokens(bert_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.to(\"cuda:0\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "737979872a7f76f1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(\"../../out/definitions.pickle\", \"rb\") as file:\n",
    "    definitions = pickle.load(file)\n",
    "with open(\"../../out/sentences.pickle\", \"rb\") as file:\n",
    "    sentences = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb7917f993cd42d8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def find_examples(definition, examples, true_examples=0):\n",
    "    predictions = {}\n",
    "    tok_examples = [tokenizer.tokenize(example) for example in examples]\n",
    "    tok_eg = tokenizer.tokenize(\"zum Beispiel:\")\n",
    "    tok_definition = tokenizer.tokenize(definition[:definition.index(\".\")])  # only the first sentence of the definition is used, so BERT has a chance of keeping some of the definition in mind\n",
    "    for num, tok_example in enumerate(tok_examples):\n",
    "        len_prompt = len(tok_definition) + len(tok_eg) + len(tok_example) + 3  # 3 extra tokens for [CLS] and [SEP] (2x)\n",
    "        if len_prompt > 512:\n",
    "            # shorten the definition so that the example fits fully, and add \"...,\" (again, 4 additional tokens)\n",
    "            prompt = tokenizer.convert_tokens_to_string(tok_definition[:512-len(tok_example)-len(tok_eg)-3-4]) + \"..., zum Beispiel:\"\n",
    "        else:\n",
    "            prompt = tokenizer.convert_tokens_to_string(tok_definition) + \", zum Beispiel:\"\n",
    "            \n",
    "        inputs = tokenizer(prompt, tokenizer.convert_tokens_to_string(tok_example), return_tensors=\"pt\").to(\"cuda:0\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        if true_examples == 0:\n",
    "            predictions[num] = logits[0, 0] > logits[0, 1]  # next sentence is not random\n",
    "        else:\n",
    "            predictions[num] = logits[0, 0]  # collect in order to sort later\n",
    "    if true_examples == 0:\n",
    "        res = [examples[num] for num, p in predictions.items() if p]  # return all sentences which have been classified as correct\n",
    "    else:\n",
    "        sorted_idxs = sorted(range(len(examples)), key=lambda i: predictions[i], reverse=True)[:true_examples]\n",
    "        res = [examples[i] for i in sorted_idxs]\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "693ad2b73bd9bcb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_metrics(positive_predicted, negative_predicted, true_sentences, false_sentences, key, definition, examples):\n",
    "    true_positives = [pr for pr in positive_predicted if pr in true_sentences]\n",
    "    false_positives = [pr for pr in positive_predicted if pr in false_sentences]\n",
    "    false_negatives = [pr for pr in negative_predicted if pr in true_sentences]\n",
    "    true_negatives = [pr for pr in negative_predicted if pr in false_sentences]\n",
    "    \n",
    "    if len(true_positives) + len(false_positives) > 0:\n",
    "        precision = len(true_positives) / (len(true_positives) + len(false_positives))\n",
    "    else:\n",
    "        precision = 1.0  # nothing found, so all things found are correct\n",
    "    \n",
    "    if len(true_positives) > 0:\n",
    "        recall = len(true_positives) / (len(true_positives) + len(false_negatives))\n",
    "    else:\n",
    "        recall = 1.0  # all found\n",
    "        \n",
    "    return pd.Series({\n",
    "        \"constr\": key, \n",
    "        \"definition\": definition, \n",
    "        \"examples\": examples, \n",
    "        \"positive_predicted\": positive_predicted,\n",
    "        \"negative_predicted\": negative_predicted,\n",
    "        \"true_positives\": true_positives,\n",
    "        \"false_positives\": false_positives,\n",
    "        \"false_negatives\": false_negatives,\n",
    "        \"true_negatives\": true_negatives,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": (2 * precision * recall) / (precision + recall),\n",
    "        \"accuracy\": (len(true_positives) + len(true_negatives)) / (len(true_sentences) + len(false_sentences))\n",
    "    })"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b56b8577f886471",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "random.seed(15)\n",
    "attempts = 15\n",
    "for num_true in range(0, 6):\n",
    "    for num_false in range(0, 6):\n",
    "        if not num_true and not num_false:\n",
    "            continue  # skip (0, 0)\n",
    "        result = []\n",
    "        for key, definition in tqdm(definitions.items()):\n",
    "            others = list(itertools.chain.from_iterable([sentence_list for constr, sentence_list in sentences.items() if int(constr) != int(key)]))  # flatten all other sentences which are not part of the current construction\n",
    "            \n",
    "            for attempt in range(attempts):\n",
    "                try:\n",
    "                    # pick the true elements of the current construction\n",
    "                    true_sentences = {random.choice(list(sentences[int(key)])) for t in range(num_true)}\n",
    "                except KeyError:\n",
    "                    result.append(pd.Series({\"constr\": key, \"definition\": definition}))\n",
    "                    continue\n",
    "    \n",
    "                # pick random false positives from the other sentences\n",
    "                false_sentences = set(random.choices(others, k=num_false))\n",
    "                examples = list(false_sentences | true_sentences)\n",
    "                \n",
    "                positive_predicted = find_examples(definition, examples)\n",
    "                negative_predicted = [ex for ex in examples if ex not in positive_predicted]\n",
    "                \n",
    "                result.append(get_metrics(positive_predicted, negative_predicted, true_sentences, false_sentences, key, definition, examples))\n",
    "                \n",
    "        result = pd.DataFrame(result)\n",
    "        result.to_csv(f\"../../out/comapp/result_{num_true}t_vs_{num_false}f_{attempts}attempts_bsbbert.tsv\", sep=\"\\t\", decimal=\",\", header=True, index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ecad5aeec67bfd80",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "kelex = csv_data.copy()\n",
    "kelex['constr'] = csv_data['label'].str.extract('(\\d+)').astype(int)\n",
    "#kelex.set_index('constr', inplace=True)\n",
    "kelex = kelex.groupby('constr')['label'].apply(set).to_dict()\n",
    "kelex"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd5df0ed9a88a378",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "random.seed(15)\n",
    "attempts = 15\n",
    "for num_true in range(1, 6):\n",
    "    for num_false in range(0, 6):\n",
    "        if not num_true and not num_false:\n",
    "            continue  # skip (0, 0)\n",
    "        result = []\n",
    "        for key, definition in tqdm(definitions.items()):\n",
    "            others = list(itertools.chain.from_iterable([sentence_list for constr, sentence_list in sentences.items() if int(constr) != int(key)]))\n",
    "            for attempt in range(attempts):\n",
    "                try:\n",
    "                    # pick the true elements of the current construction\n",
    "                    true_sentences = {random.choice(list(sentences[int(key)])) for t in range(num_true)}\n",
    "                except KeyError:\n",
    "                    result.append(pd.Series({\"constr\": key, \"definition\": definition}))\n",
    "                    continue\n",
    "                    \n",
    "                true_sentences_kelex = []\n",
    "                if kelex.get(key):  # if there is a predefined KE-lex in the construction\n",
    "                    # if len(true_sentences) > 0:\n",
    "                        for pseudoword in kelex[key]:  # replace each predefined KE-lex in the sentence one-by-one (if there are multiple)\n",
    "                            cur_true_sentences = []\n",
    "                            for sentence in true_sentences:\n",
    "                                pseudoword_found = False\n",
    "                                sentence_kelex = []\n",
    "                                for token in sentence.split():\n",
    "                                    new_token = token\n",
    "                                    if token == re.findall(r'\\D+', pseudoword)[0]:\n",
    "                                        new_token = pseudoword\n",
    "                                        pseudoword_found = True\n",
    "                                    sentence_kelex.append(new_token)\n",
    "                                if pseudoword_found:  # only add the sentence if it has a replaced pseudoword\n",
    "                                    cur_true_sentences.append(\" \".join(sentence_kelex))\n",
    "                            #if len(cur_true_sentences) > 0:\n",
    "                            true_sentences_kelex.append(set(cur_true_sentences))\n",
    "                else:\n",
    "                    continue  # skip constructions without kelex\n",
    "                \n",
    "                for true_sentences in true_sentences_kelex:\n",
    "                    if len(true_sentences) == num_true:  # watch out that the number of true_sentences is still coherent with the number predefined by num_true (e.g. in case a specific KE-lex wasn't in the sentence)\n",
    "                        # pick random false positives from the other sentences                    \n",
    "                        false_sentences = set(random.choices(others, k=num_false))\n",
    "                        examples = list(false_sentences | true_sentences)\n",
    "                        \n",
    "                        positive_predicted = find_examples(definition, examples)\n",
    "                        negative_predicted = [ex for ex in examples if ex not in positive_predicted]\n",
    "                        \n",
    "                        result.append(get_metrics(positive_predicted, negative_predicted, true_sentences, false_sentences, key, definition, examples))\n",
    "                    \n",
    "        result = pd.DataFrame(result)\n",
    "        result.to_csv(f\"../../out/comapp/result_{num_true}t_vs_{num_false}f_kelex_{attempts}attempts_bsbbert.tsv\", sep=\"\\t\", decimal=\",\", header=True, index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfdb3dc48dea6759",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "random.seed(15)\n",
    "attempts = 15\n",
    "for num_true in range(1, 6):\n",
    "    for num_false in range(1, 6):\n",
    "        if not num_true and not num_false:\n",
    "            continue  # skip (0, 0)\n",
    "        result = []\n",
    "        for key, definition in tqdm(definitions.items()):\n",
    "            others = list(itertools.chain.from_iterable([sentence_list for constr, sentence_list in sentences.items() if int(constr) != int(key)]))  # flatten all other sentences which are not part of the current construction\n",
    "            \n",
    "            for attempt in range(attempts):\n",
    "                try:\n",
    "                    # pick the true elements of the current construction\n",
    "                    true_sentences = {random.choice(list(sentences[int(key)])) for t in range(num_true)}\n",
    "                except KeyError:\n",
    "                    result.append(pd.Series({\"constr\": key, \"definition\": definition}))\n",
    "                    continue\n",
    "    \n",
    "                # pick random false positives from the other sentences\n",
    "                false_sentences = set(random.choices(others, k=num_false))\n",
    "                examples = list(false_sentences | true_sentences)\n",
    "                \n",
    "                positive_predicted = find_examples(definition, examples, num_true)\n",
    "                negative_predicted = [ex for ex in examples if ex not in positive_predicted]\n",
    "                \n",
    "                result.append(get_metrics(positive_predicted, negative_predicted, true_sentences, false_sentences, key, definition, examples))\n",
    "                \n",
    "        result = pd.DataFrame(result)\n",
    "        result.to_csv(f\"../../out/comapp/result_{num_true}t_vs_{num_false}f_{attempts}attempts_bsbbert_2.tsv\", sep=\"\\t\", decimal=\",\", header=True, index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43b177fa6acb3e53",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "random.seed(15)\n",
    "attempts = 15\n",
    "for num_true in range(1, 6):\n",
    "    for num_false in range(1, 6):\n",
    "        result = []\n",
    "        for key, definition in tqdm(definitions.items()):\n",
    "            others = list(itertools.chain.from_iterable([sentence_list for constr, sentence_list in sentences.items() if int(constr) != int(key)]))\n",
    "            for attempt in range(attempts):\n",
    "                try:\n",
    "                    # pick the true elements of the current construction\n",
    "                    true_sentences = {random.choice(list(sentences[int(key)])) for t in range(num_true)}\n",
    "                except KeyError:\n",
    "                    result.append(pd.Series({\"constr\": key, \"definition\": definition}))\n",
    "                    continue\n",
    "                    \n",
    "                true_sentences_kelex = []\n",
    "                if kelex.get(key):  # if there is a predefined KE-lex in the construction\n",
    "                    # if len(true_sentences) > 0:\n",
    "                        for pseudoword in kelex[key]:  # replace each predefined KE-lex in the sentence one-by-one (if there are multiple)\n",
    "                            cur_true_sentences = []\n",
    "                            for sentence in true_sentences:\n",
    "                                pseudoword_found = False\n",
    "                                sentence_kelex = []\n",
    "                                for token in sentence.split():\n",
    "                                    new_token = token\n",
    "                                    if token == re.findall(r'\\D+', pseudoword)[0]:\n",
    "                                        new_token = pseudoword\n",
    "                                        pseudoword_found = True\n",
    "                                    sentence_kelex.append(new_token)\n",
    "                                if pseudoword_found:  # only add the sentence if it has a replaced pseudoword\n",
    "                                    cur_true_sentences.append(\" \".join(sentence_kelex))\n",
    "                            true_sentences_kelex.append(set(cur_true_sentences))\n",
    "                else:\n",
    "                    continue  # skip constructions without kelex\n",
    "                \n",
    "                for true_sentences in true_sentences_kelex:\n",
    "                    if len(true_sentences) == num_true:  # watch out that the number of true_sentences is still coherent with the number predefined by num_true (e.g. in case a specific KE-lex wasn't in the sentence)\n",
    "                        # pick random false positives from the other sentences                    \n",
    "                        false_sentences = set(random.choices(others, k=num_false))\n",
    "                        examples = list(false_sentences | true_sentences)\n",
    "                        \n",
    "                        positive_predicted = find_examples(definition, examples, true_examples=num_true)\n",
    "                        negative_predicted = [ex for ex in examples if ex not in positive_predicted]\n",
    "                        \n",
    "                        result.append(get_metrics(positive_predicted, negative_predicted, true_sentences, false_sentences, key, definition, examples))\n",
    "                        \n",
    "        result = pd.DataFrame(result)\n",
    "        result.to_csv(f\"../../out/comapp/result_{num_true}t_vs_{num_false}f_kelex_{attempts}attempts_bsbbert_2.tsv\", sep=\"\\t\", decimal=\",\", header=True, index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58162688e6c23c1b",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
