{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T17:05:44.196860800Z",
     "start_time": "2024-01-27T17:05:36.474259Z"
    }
   },
   "id": "863338ddbf31a6c5"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 example  \\\n0      Und dann ist da noch das generelle Problem mit...   \n1      Und dann ist da noch das generelle Problem mit...   \n2      Und dann ist da noch das generelle Problem mit...   \n3      Und dann ist da noch das generelle Problem mit...   \n4      Und dann ist da noch das generelle Problem mit...   \n...                                                  ...   \n12128  \" Eine low fee - Schule ist nicht automatisch ...   \n12129  \" Eine low fee - Schule ist nicht automatisch ...   \n12130  Im Gang sieht sie plötzlich Jamie , erkennt ih...   \n12131  An seiner Hand geht ein Mädchen , einen Kopf k...   \n12132  Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n\n                                                     cue    pseudoword  \n0      Und dann ist da noch das generelle Problem mit...  geschweige10  \n1      Und dann ist da noch das generelle Problem mit...        denn10  \n2      Und dann ist da noch das generelle Problem mit...  geschweige10  \n3      Und dann ist da noch das generelle Problem mit...        denn10  \n4      Und dann ist da noch das generelle Problem mit...  geschweige10  \n...                                                  ...           ...  \n12128  \" Eine low fee - Schule ist nicht automatisch ...          er99  \n12129  \" Eine low fee - Schule ist nicht automatisch ...          er99  \n12130  Im Gang sieht sie plötzlich Jamie , erkennt ih...          er99  \n12131  An seiner Hand geht ein Mädchen , einen Kopf k...          er99  \n12132  Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n\n[12133 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>example</th>\n      <th>cue</th>\n      <th>pseudoword</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>geschweige10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>denn10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>geschweige10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>denn10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>geschweige10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12128</th>\n      <td>\" Eine low fee - Schule ist nicht automatisch ...</td>\n      <td>\" Eine low fee - Schule ist nicht automatisch ...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>12129</th>\n      <td>\" Eine low fee - Schule ist nicht automatisch ...</td>\n      <td>\" Eine low fee - Schule ist nicht automatisch ...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>12130</th>\n      <td>Im Gang sieht sie plötzlich Jamie , erkennt ih...</td>\n      <td>Im Gang sieht sie plötzlich Jamie , erkennt ih...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>12131</th>\n      <td>An seiner Hand geht ein Mädchen , einen Kopf k...</td>\n      <td>An seiner Hand geht ein Mädchen , einen Kopf k...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>12132</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n  </tbody>\n</table>\n<p>12133 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../../data/pseudowords/CoMaPP_all.json\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "data = [{\"example\": d[\"target1\"], \"cue\": \" \".join(d[\"target1\"].split()[:d[\"query_idx\"]]), \"pseudoword\": d[\"label\"]} for d in data]\n",
    "df = pd.DataFrame.from_dict(data).drop_duplicates(ignore_index=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T17:05:44.295612Z",
     "start_time": "2024-01-27T17:05:44.081354700Z"
    }
   },
   "id": "18bb06d46d72aab4"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 example  \\\nindex                                                      \n10     Und dann ist da noch das generelle Problem mit...   \n10     Und dann ist da noch das generelle Problem mit...   \n10     Und dann ist da noch das generelle Problem mit...   \n10     Und dann ist da noch das generelle Problem mit...   \n10     Und dann ist da noch das generelle Problem mit...   \n...                                                  ...   \n99     \" Eine low fee - Schule ist nicht automatisch ...   \n99     \" Eine low fee - Schule ist nicht automatisch ...   \n99     Im Gang sieht sie plötzlich Jamie , erkennt ih...   \n99     An seiner Hand geht ein Mädchen , einen Kopf k...   \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n\n                                                     cue    pseudoword  \nindex                                                                   \n10     Und dann ist da noch das generelle Problem mit...  geschweige10  \n10     Und dann ist da noch das generelle Problem mit...        denn10  \n10     Und dann ist da noch das generelle Problem mit...  geschweige10  \n10     Und dann ist da noch das generelle Problem mit...        denn10  \n10     Und dann ist da noch das generelle Problem mit...  geschweige10  \n...                                                  ...           ...  \n99     \" Eine low fee - Schule ist nicht automatisch ...          er99  \n99     \" Eine low fee - Schule ist nicht automatisch ...          er99  \n99     Im Gang sieht sie plötzlich Jamie , erkennt ih...          er99  \n99     An seiner Hand geht ein Mädchen , einen Kopf k...          er99  \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n\n[12133 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>example</th>\n      <th>cue</th>\n      <th>pseudoword</th>\n    </tr>\n    <tr>\n      <th>index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>geschweige10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>denn10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>geschweige10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>denn10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>geschweige10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>\" Eine low fee - Schule ist nicht automatisch ...</td>\n      <td>\" Eine low fee - Schule ist nicht automatisch ...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>\" Eine low fee - Schule ist nicht automatisch ...</td>\n      <td>\" Eine low fee - Schule ist nicht automatisch ...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Im Gang sieht sie plötzlich Jamie , erkennt ih...</td>\n      <td>Im Gang sieht sie plötzlich Jamie , erkennt ih...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>An seiner Hand geht ein Mädchen , einen Kopf k...</td>\n      <td>An seiner Hand geht ein Mädchen , einen Kopf k...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n  </tbody>\n</table>\n<p>12133 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['index'] = df['pseudoword'].str.extract('(\\d+)').astype(int)\n",
    "df.set_index('index', inplace=True)\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T17:05:44.320591200Z",
     "start_time": "2024-01-27T17:05:44.249911500Z"
    }
   },
   "id": "b7e1f6e88f687297"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 example  \\\nindex                                                      \n10     Und dann ist da noch das generelle Problem mit...   \n10     Und dann ist da noch das generelle Problem mit...   \n10     Und dann ist da noch das generelle Problem mit...   \n10     Und dann ist da noch das generelle Problem mit...   \n10     Und dann ist da noch das generelle Problem mit...   \n...                                                  ...   \n99     \" Eine low fee - Schule ist nicht automatisch ...   \n99     \" Eine low fee - Schule ist nicht automatisch ...   \n99     Im Gang sieht sie plötzlich Jamie , erkennt ih...   \n99     An seiner Hand geht ein Mädchen , einen Kopf k...   \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n\n                                                     cue    pseudoword  \nindex                                                                   \n10     Und dann ist da noch das generelle Problem mit...  geschweige10  \n10     Und dann ist da noch das generelle Problem mit...        denn10  \n10     Und dann ist da noch das generelle Problem mit...  geschweige10  \n10     Und dann ist da noch das generelle Problem mit...        denn10  \n10     Und dann ist da noch das generelle Problem mit...  geschweige10  \n...                                                  ...           ...  \n99     \" Eine low fee - Schule ist nicht automatisch ...          er99  \n99     \" Eine low fee - Schule ist nicht automatisch ...          er99  \n99     Im Gang sieht sie plötzlich Jamie , erkennt ih...          er99  \n99     An seiner Hand geht ein Mädchen , einen Kopf k...          er99  \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n\n[12133 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>example</th>\n      <th>cue</th>\n      <th>pseudoword</th>\n    </tr>\n    <tr>\n      <th>index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>geschweige10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>denn10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>geschweige10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>denn10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>geschweige10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>\" Eine low fee - Schule ist nicht automatisch ...</td>\n      <td>\" Eine low fee - Schule ist nicht automatisch ...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>\" Eine low fee - Schule ist nicht automatisch ...</td>\n      <td>\" Eine low fee - Schule ist nicht automatisch ...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Im Gang sieht sie plötzlich Jamie , erkennt ih...</td>\n      <td>Im Gang sieht sie plötzlich Jamie , erkennt ih...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>An seiner Hand geht ein Mädchen , einen Kopf k...</td>\n      <td>An seiner Hand geht ein Mädchen , einen Kopf k...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n  </tbody>\n</table>\n<p>12133 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contextleft = pd.read_pickle(\"../../data/pseudowords/contextleft_text.pickle\")\n",
    "\n",
    "def update_cue(row):\n",
    "    output = row[['example', 'cue']]\n",
    "    if row['cue'] == '':  # if the string in cue is empty\n",
    "        # match the index of row with contextleft['construction_id'] and match contextleft['text'] with row['example'] and create matching_entry\n",
    "        matching_entry = contextleft.loc[(contextleft['construction_id'] == row.name) & (contextleft['text'] == row['example']), 'contextleft'].tolist()\n",
    "        if len(matching_entry) > 0:\n",
    "            output = [matching_entry[0] + \" \" + row['example'], matching_entry[0]]\n",
    "    return output\n",
    "\n",
    "# Add the left context if there is no cue up until the pseudoword.\n",
    "df[[\"example\", \"cue\"]] = df.apply(update_cue, axis=1)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T17:05:49.256776400Z",
     "start_time": "2024-01-27T17:05:44.268772100Z"
    }
   },
   "id": "a898840ef3c9c442"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                   example  \\\nconstruction pseudoword                                                      \n5            Und5        [\"\"Nicht herauskaufen\"\", \"\"nicht erpressen las...   \n             erst5       [Trainer Lucien Favre hatte schon seine beiden...   \n             gar5        [Es hat Afghanistan nicht stabilisiert und sch...   \n             nicht5      [Es hat Afghanistan nicht stabilisiert und sch...   \n             recht5      [Trainer Lucien Favre hatte schon seine beiden...   \n...                                                                    ...   \n1884         Gold1884    [Schweigen ist Silber , reden ist Gold ., Schw...   \n             Silber1884  [Schweigen ist Silber , reden ist Gold ., Schw...   \n             ist1884     [Schweigen ist Silber , reden ist Gold ., Schw...   \n1986         kaum1986    [Die Vorhut vor 20.000 Jahren war für das Ries...   \n1987         sehr1987    [Solche Menschen können sich sehr wohlfühlen o...   \n\n                                                                       cue  \nconstruction pseudoword                                                     \n5            Und5        [\"\"Nicht herauskaufen\"\", \"\"nicht erpressen las...  \n             erst5       [Trainer Lucien Favre hatte schon seine beiden...  \n             gar5        [Es hat Afghanistan nicht stabilisiert, Es hat...  \n             nicht5      [Es, Es hat Afghanistan, Dass, Dass es in der ...  \n             recht5      [Trainer Lucien Favre hatte schon seine beiden...  \n...                                                                    ...  \n1884         Gold1884    [Schweigen ist Silber , reden ist, Schweigen i...  \n             Silber1884  [Schweigen ist, Schweigen ist, Angeben ist, Sc...  \n             ist1884     [Schweigen, Schweigen, Angeben, Schweigen, \" Q...  \n1986         kaum1986    [Die Vorhut vor 20.000 Jahren, Die Vorhut vor ...  \n1987         sehr1987    [Solche Menschen können, Solche Menschen könne...  \n\n[562 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>example</th>\n      <th>cue</th>\n    </tr>\n    <tr>\n      <th>construction</th>\n      <th>pseudoword</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">5</th>\n      <th>Und5</th>\n      <td>[\"\"Nicht herauskaufen\"\", \"\"nicht erpressen las...</td>\n      <td>[\"\"Nicht herauskaufen\"\", \"\"nicht erpressen las...</td>\n    </tr>\n    <tr>\n      <th>erst5</th>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n    </tr>\n    <tr>\n      <th>gar5</th>\n      <td>[Es hat Afghanistan nicht stabilisiert und sch...</td>\n      <td>[Es hat Afghanistan nicht stabilisiert, Es hat...</td>\n    </tr>\n    <tr>\n      <th>nicht5</th>\n      <td>[Es hat Afghanistan nicht stabilisiert und sch...</td>\n      <td>[Es, Es hat Afghanistan, Dass, Dass es in der ...</td>\n    </tr>\n    <tr>\n      <th>recht5</th>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">1884</th>\n      <th>Gold1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[Schweigen ist Silber , reden ist, Schweigen i...</td>\n    </tr>\n    <tr>\n      <th>Silber1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[Schweigen ist, Schweigen ist, Angeben ist, Sc...</td>\n    </tr>\n    <tr>\n      <th>ist1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[Schweigen, Schweigen, Angeben, Schweigen, \" Q...</td>\n    </tr>\n    <tr>\n      <th>1986</th>\n      <th>kaum1986</th>\n      <td>[Die Vorhut vor 20.000 Jahren war für das Ries...</td>\n      <td>[Die Vorhut vor 20.000 Jahren, Die Vorhut vor ...</td>\n    </tr>\n    <tr>\n      <th>1987</th>\n      <th>sehr1987</th>\n      <td>[Solche Menschen können sich sehr wohlfühlen o...</td>\n      <td>[Solche Menschen können, Solche Menschen könne...</td>\n    </tr>\n  </tbody>\n</table>\n<p>562 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'construction'}, inplace=True)\n",
    "\n",
    "result_df = df.groupby(['construction', 'pseudoword']).agg({'example': list, 'cue': list})\n",
    "\n",
    "result_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T17:05:49.307347600Z",
     "start_time": "2024-01-27T17:05:49.251777300Z"
    }
   },
   "id": "4a4e3d92707b4c4"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             definition\n10    Die \"Negation:NEG_XgeschweigedennY-Konstruktio...\n100   Die \"Äquativ_Plural-Konstruktion\" gehört zu de...\n1004  Die \"Superlativ_Klimax:ADJ1_ADJ1-er_NP-Konstru...\n1006  Die \"Superlativ:PRÄP_ADJ-ster_NP-Konstruktion\"...\n101   Die \"Äquativ:ADJwieNP-Konstruktion\" gehört zu ...\n...                                                 ...\n97    Die \"Komparativ:ADJ1-eralsADJ1-Konstruktion\" g...\n973   Bei \"Disjunktion_Doppeltitel:XoderY\" handelt e...\n976   Bei \"Korrelation_Affirmation:WoXist, istY\" han...\n98    Die \"Äquativ:soADJwieXP-Konstruktion\" gehört z...\n99    Die \"Komparativ:ADJ-eralsX-Konstruktion\" gehör...\n\n[211 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>definition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>Die \"Negation:NEG_XgeschweigedennY-Konstruktio...</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>Die \"Äquativ_Plural-Konstruktion\" gehört zu de...</td>\n    </tr>\n    <tr>\n      <th>1004</th>\n      <td>Die \"Superlativ_Klimax:ADJ1_ADJ1-er_NP-Konstru...</td>\n    </tr>\n    <tr>\n      <th>1006</th>\n      <td>Die \"Superlativ:PRÄP_ADJ-ster_NP-Konstruktion\"...</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>Die \"Äquativ:ADJwieNP-Konstruktion\" gehört zu ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>Die \"Komparativ:ADJ1-eralsADJ1-Konstruktion\" g...</td>\n    </tr>\n    <tr>\n      <th>973</th>\n      <td>Bei \"Disjunktion_Doppeltitel:XoderY\" handelt e...</td>\n    </tr>\n    <tr>\n      <th>976</th>\n      <td>Bei \"Korrelation_Affirmation:WoXist, istY\" han...</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>Die \"Äquativ:soADJwieXP-Konstruktion\" gehört z...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Die \"Komparativ:ADJ-eralsX-Konstruktion\" gehör...</td>\n    </tr>\n  </tbody>\n</table>\n<p>211 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../../out/definitions.pickle\", \"rb\") as definitions_file:\n",
    "    definitions = pd.DataFrame.from_dict(pickle.load(definitions_file), orient=\"index\", columns=[\"definition\"])\n",
    "    \n",
    "definitions"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-27T17:05:49.333599Z",
     "start_time": "2024-01-27T17:05:49.290988900Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                   example  \\\nconstruction pseudoword                                                      \n5            Und5        [\"\"Nicht herauskaufen\"\", \"\"nicht erpressen las...   \n             erst5       [Trainer Lucien Favre hatte schon seine beiden...   \n             gar5        [Es hat Afghanistan nicht stabilisiert und sch...   \n             nicht5      [Es hat Afghanistan nicht stabilisiert und sch...   \n             recht5      [Trainer Lucien Favre hatte schon seine beiden...   \n...                                                                    ...   \n1884         Gold1884    [Schweigen ist Silber , reden ist Gold ., Schw...   \n             Silber1884  [Schweigen ist Silber , reden ist Gold ., Schw...   \n             ist1884     [Schweigen ist Silber , reden ist Gold ., Schw...   \n1986         kaum1986    [Die Vorhut vor 20.000 Jahren war für das Ries...   \n1987         sehr1987    [Solche Menschen können sich sehr wohlfühlen o...   \n\n                                                                       cue  \\\nconstruction pseudoword                                                      \n5            Und5        [\"\"Nicht herauskaufen\"\", \"\"nicht erpressen las...   \n             erst5       [Trainer Lucien Favre hatte schon seine beiden...   \n             gar5        [Es hat Afghanistan nicht stabilisiert, Es hat...   \n             nicht5      [Es, Es hat Afghanistan, Dass, Dass es in der ...   \n             recht5      [Trainer Lucien Favre hatte schon seine beiden...   \n...                                                                    ...   \n1884         Gold1884    [Schweigen ist Silber , reden ist, Schweigen i...   \n             Silber1884  [Schweigen ist, Schweigen ist, Angeben ist, Sc...   \n             ist1884     [Schweigen, Schweigen, Angeben, Schweigen, \" Q...   \n1986         kaum1986    [Die Vorhut vor 20.000 Jahren, Die Vorhut vor ...   \n1987         sehr1987    [Solche Menschen können, Solche Menschen könne...   \n\n                                                                definition  \nconstruction pseudoword                                                     \n5            Und5        Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...  \n             erst5       Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...  \n             gar5        Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...  \n             nicht5      Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...  \n             recht5      Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...  \n...                                                                    ...  \n1884         Gold1884    Die \"Intensivierung_Komparativ:Xist_SilberYist...  \n             Silber1884  Die \"Intensivierung_Komparativ:Xist_SilberYist...  \n             ist1884     Die \"Intensivierung_Komparativ:Xist_SilberYist...  \n1986         kaum1986    Die Konstruktion \"Relativierung:kaumADJ\" gehör...  \n1987         sehr1987    Die Konstruktion \"Intensivierung:sehrV\" gehört...  \n\n[562 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>example</th>\n      <th>cue</th>\n      <th>definition</th>\n    </tr>\n    <tr>\n      <th>construction</th>\n      <th>pseudoword</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">5</th>\n      <th>Und5</th>\n      <td>[\"\"Nicht herauskaufen\"\", \"\"nicht erpressen las...</td>\n      <td>[\"\"Nicht herauskaufen\"\", \"\"nicht erpressen las...</td>\n      <td>Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...</td>\n    </tr>\n    <tr>\n      <th>erst5</th>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...</td>\n    </tr>\n    <tr>\n      <th>gar5</th>\n      <td>[Es hat Afghanistan nicht stabilisiert und sch...</td>\n      <td>[Es hat Afghanistan nicht stabilisiert, Es hat...</td>\n      <td>Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...</td>\n    </tr>\n    <tr>\n      <th>nicht5</th>\n      <td>[Es hat Afghanistan nicht stabilisiert und sch...</td>\n      <td>[Es, Es hat Afghanistan, Dass, Dass es in der ...</td>\n      <td>Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...</td>\n    </tr>\n    <tr>\n      <th>recht5</th>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">1884</th>\n      <th>Gold1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[Schweigen ist Silber , reden ist, Schweigen i...</td>\n      <td>Die \"Intensivierung_Komparativ:Xist_SilberYist...</td>\n    </tr>\n    <tr>\n      <th>Silber1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[Schweigen ist, Schweigen ist, Angeben ist, Sc...</td>\n      <td>Die \"Intensivierung_Komparativ:Xist_SilberYist...</td>\n    </tr>\n    <tr>\n      <th>ist1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[Schweigen, Schweigen, Angeben, Schweigen, \" Q...</td>\n      <td>Die \"Intensivierung_Komparativ:Xist_SilberYist...</td>\n    </tr>\n    <tr>\n      <th>1986</th>\n      <th>kaum1986</th>\n      <td>[Die Vorhut vor 20.000 Jahren war für das Ries...</td>\n      <td>[Die Vorhut vor 20.000 Jahren, Die Vorhut vor ...</td>\n      <td>Die Konstruktion \"Relativierung:kaumADJ\" gehör...</td>\n    </tr>\n    <tr>\n      <th>1987</th>\n      <th>sehr1987</th>\n      <td>[Solche Menschen können sich sehr wohlfühlen o...</td>\n      <td>[Solche Menschen können, Solche Menschen könne...</td>\n      <td>Die Konstruktion \"Intensivierung:sehrV\" gehört...</td>\n    </tr>\n  </tbody>\n</table>\n<p>562 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = pd.merge(result_df, definitions, how=\"inner\", left_on=\"construction\", right_index=True)\n",
    "examples"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T17:05:49.378086900Z",
     "start_time": "2024-01-27T17:05:49.299015Z"
    }
   },
   "id": "238d2238bbdd91d8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Generieren neuer Sätze:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bc899cb800665fa"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.01952364,  0.00048042,  0.05060846, ...,  0.04258203,\n         0.05651806,  0.02429085],\n       [-0.00994319, -0.00676309, -0.00601289, ..., -0.03203335,\n        -0.03284921,  0.00028247],\n       [-0.03243406, -0.00804963, -0.02258722, ...,  0.04839412,\n         0.0025557 ,  0.01301195],\n       ...,\n       [ 0.00162825,  0.01625418,  0.0080498 , ..., -0.01727665,\n         0.01961022, -0.00274661],\n       [ 0.00529211,  0.00459571,  0.01711997, ...,  0.01059076,\n        -0.01628351, -0.0441331 ],\n       [-0.03313114,  0.00591089, -0.00273072, ..., -0.03151482,\n         0.01069049,  0.00970152]], dtype=float32)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudowords = [\n",
    "    np.load(f\"../../data/pseudowords/mbart/pseudowords_comapp_0_69.npy\"),\n",
    "    np.load(f\"../../data/pseudowords/mbart/pseudowords_comapp_69_93.npy\"),\n",
    "    np.load(f\"../../data/pseudowords/mbart/pseudowords_comapp_93_165.npy\"),\n",
    "    np.load(f\"../../data/pseudowords/mbart/pseudowords_comapp_165_176.npy\"),\n",
    "    np.load(f\"../../data/pseudowords/mbart/pseudowords_comapp_176_281.npy\"),\n",
    "    np.load(f\"../../data/pseudowords/mbart/pseudowords_comapp_281_364.npy\"),\n",
    "    np.load(f\"../../data/pseudowords/mbart/pseudowords_comapp_364_437.npy\"),\n",
    "    np.load(f\"../../data/pseudowords/mbart/pseudowords_comapp_437_562.npy\")\n",
    "]\n",
    "pseudowords = np.concatenate(pseudowords)\n",
    "pseudowords"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T17:05:49.379087200Z",
     "start_time": "2024-01-27T17:05:49.319019800Z"
    }
   },
   "id": "c9e6d940aa4aaace"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "            label\norder            \n0         \"\"Was13\n1            \"647\n3           (1597\n4           (1600\n5           (1602\n...           ...\n556     »Raus1316\n557    Ähnlich123\n559    ähnlich123\n560    ähnlich139\n561        über85\n\n[506 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n    </tr>\n    <tr>\n      <th>order</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"\"Was13</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"647</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(1597</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(1600</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>(1602</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>556</th>\n      <td>»Raus1316</td>\n    </tr>\n    <tr>\n      <th>557</th>\n      <td>Ähnlich123</td>\n    </tr>\n    <tr>\n      <th>559</th>\n      <td>ähnlich123</td>\n    </tr>\n    <tr>\n      <th>560</th>\n      <td>ähnlich139</td>\n    </tr>\n    <tr>\n      <th>561</th>\n      <td>über85</td>\n    </tr>\n  </tbody>\n</table>\n<p>506 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_data = []\n",
    "# TODO mBART-Order laden\n",
    "for i in range(0, 8):\n",
    "    csv_data.append(pd.read_csv(f\"../../data/pseudowords/mbart/order_{i}.csv\", sep=\";\", index_col=0, header=None, quotechar=\"|\", names=[\"order\", \"label\"]))\n",
    "csv_data = pd.concat(csv_data)\n",
    "csv_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T17:05:49.381087200Z",
     "start_time": "2024-01-27T17:05:49.333599Z"
    }
   },
   "id": "621718c51c9db794"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(['\"\"Was13',\n  '\"647',\n  '(1597',\n  '(1600',\n  '(1602',\n  '(1637',\n  '(1641',\n  '(1643',\n  '(379',\n  '(579',\n  '(581',\n  '(584',\n  '(590',\n  '(592',\n  '(600',\n  '(886',\n  '(892',\n  '(900',\n  '(905',\n  '(907',\n  '(909',\n  '(917',\n  '(919',\n  '(921',\n  ')1597',\n  ')1600',\n  ')1637',\n  ')1641',\n  ')1643',\n  ')1792',\n  ')379',\n  ')579',\n  ')581',\n  ')584',\n  ')590',\n  ')592',\n  ')600',\n  ')886',\n  ')892',\n  ')900',\n  ')907',\n  ')909',\n  ')917',\n  ')919',\n  ')921',\n  ')«579',\n  ',1459',\n  ',973',\n  '-128',\n  '-651',\n  '-654',\n  '-875',\n  '-973',\n  ':595',\n  ':875',\n  ':973',\n  'Abstand683',\n  'Allein20',\n  'Aller1630',\n  'Als1315',\n  'Als133',\n  'Als1770',\n  'Am488',\n  'Am492',\n  'Am500',\n  'Amerika605',\n  'genauso122',\n  'genauso98',\n  'geschweige10',\n  'gewesen1459',\n  'gibt605',\n  'gleich100',\n  'gleich675',\n  'gleich676',\n  'gleich98',\n  'gleiche104',\n  'gleichen1777',\n  'gleichkam676',\n  'gleichkommen676',\n  'gleichkommt676',\n  'gleichkäme676',\n  'gleicht132',\n  'gold1554',\n  'habe605',\n  'haben605',\n  'hat605',\n  'hatte605',\n  'heisst1631',\n  'her1351',\n  'her1511',\n  'herunter1574',\n  'heute1459',\n  'hin1351',\n  'hin1511',\n  'hinaus1574',\n  'hindurch1574',\n  'hinunter1574',\n  'hätte1756',\n  'hätten1756',\n  'hättest1756',\n  'im1346',\n  'im1777',\n  'im557',\n  'in1316',\n  'in1777',\n  'in557',\n  'in605',\n  'in858',\n  'ist125',\n  'ist130',\n  'ist1313',\n  'ist1459',\n  'ist1461',\n  'ist1462',\n  'ist1554',\n  'ist1660',\n  'ist1715',\n  'ist1792',\n  'ist1835',\n  'ist1846',\n  'ist1881',\n  'ist1884',\n  'ist875',\n  'ist976',\n  'je111',\n  'jedermanns1329',\n  'jetzt1631',\n  'kam676',\n  'kann1593',\n  'kaum11',\n  'kaum1986',\n  'kein1461',\n  'kein1462',\n  'kein1525',\n  'kein1690',\n  'kein1715',\n  'kein1881',\n  'kein902',\n  'kein949',\n  'keine1461',\n  'keine1525',\n  'keine1715',\n  'keine1835',\n  'keine1881',\n  'keine605',\n  'keine902',\n  'Anstatt320',\n  'Art129',\n  'Arzt1509',\n  'Augenblick1301',\n  'Ausmaß1777',\n  'BRUTAL1503',\n  'Besser1762',\n  'Bis559',\n  'Brutal1503',\n  'Buche1346',\n  'Das1313',\n  'Das1461',\n  'Dass21',\n  'Dasselbe104',\n  'Der1301',\n  'Desto111',\n  'Die1681',\n  'Diese19',\n  'Dieser1301',\n  'Dieser19',\n  'Dieses19',\n  'Entweder1779',\n  'Es1313',\n  'Es605',\n  'Gefühl1301',\n  'Generation1126',\n  'Geschweige10',\n  'Gold1554',\n  'Gold1884',\n  'Hauptsache1033',\n  'Im557',\n  'In557',\n  'In858',\n  'Inbegriff1671',\n  'Ist1660',\n  'Je111',\n  'Jedermanns1329',\n  'Jener1301',\n  'Jetzt1631',\n  'Kein1525',\n  'Kein1715',\n  'Kein1835',\n  'Kein949',\n  'Keine(r1792',\n  'Keine1525',\n  'Keine1715',\n  'Keine1792',\n  'Keine1835',\n  'Keine902',\n  'Keine949',\n  'Keiner1792',\n  'Leben1461',\n  'Leben605',\n  'Lecker1649',\n  'Maß1777',\n  'Maße1777',\n  'Mit683',\n  'Moment1301',\n  'Mords651',\n  'Mutter1681',\n  'Neue875',\n  'Nicht1162',\n  'Nicht902',\n  'Niemand1792',\n  'Ponyhof1462',\n  'Raus1316',\n  'Reden1554',\n  'Riesen654',\n  'Silber1554',\n  'Silber1884',\n  'So1300',\n  'So1760',\n  'So1831',\n  'So22',\n  'So74',\n  'So98',\n  'Solch78',\n  'Solche78',\n  'Sowohl1134',\n  'Statt320',\n  'Tode1347',\n  'Trotz1630',\n  'Umfang1777',\n  'Umso111',\n  'Und11',\n  'Und5',\n  'Von1034',\n  'Von1629',\n  'Von1772',\n  'Was13',\n  'Was16',\n  'Was1846',\n  'Weder12',\n  'keine949',\n  'keiner1792',\n  'kommen1509',\n  'kommen676',\n  'kommt1509',\n  'kommt676',\n  'käme676',\n  'lassen1289',\n  'lecker1649',\n  'ließ1289',\n  'lässt1289',\n  'mag605',\n  'meinem605',\n  'meisten488',\n  'meisten492',\n  'mich1573',\n  'mich1574',\n  'mir1582',\n  'mit1846',\n  'mit683',\n  'mords651',\n  'muss1300',\n  'musste1509',\n  'neue875',\n  'neuen875',\n  'nicht.“1779',\n  'nicht1162',\n  'nicht1690',\n  'nicht1779',\n  'nicht902',\n  'nicht904',\n  'niemand1525',\n  'niemand1792',\n  'noch12',\n  'noch1770',\n  'nämliche104',\n  'ob1315',\n  'ob133',\n  'oder1162',\n  'oder1779',\n  'oder973',\n  'ohne1690',\n  'ohne949',\n  'ohnegleichen618',\n  'par1342',\n  'pur.»1323',\n  'pur1323',\n  'pur«1323',\n  'raus1316',\n  'recht5',\n  'rein1316',\n  'satt1324',\n  'schlechthin1556',\n  'schlechthin»1556',\n  'schon5',\n  'sehr1987',\n  'sei125',\n  'seien1660',\n  'Weil674',\n  'Weil681',\n  'Welch15',\n  'Wenn1291',\n  'Wie14',\n  'Wie1738',\n  'Wo976',\n  'Während320',\n  'Zeit605',\n  'Zeiten605',\n  'ab1574',\n  'aber902',\n  'allen1630',\n  'aller1630',\n  'aller1681',\n  'aller758',\n  'als1134',\n  'als133',\n  'als1762',\n  'als1770',\n  'als97',\n  'am488',\n  'am492',\n  'am500',\n  'an349',\n  'anstatt320',\n  'anstatt882',\n  'artig128',\n  'auch1134',\n  'auch1715',\n  'auch1835',\n  'auf1574',\n  'auf350',\n  'aus1316',\n  'besser1762',\n  'bis1509',\n  'bis559',\n  'bisschen762',\n  'bleibt1660',\n  'brutal1503',\n  'das1301',\n  'das1461',\n  'das875',\n  'dass135',\n  'dasselbe104',\n  'dem1777',\n  'den557',\n  'den671',\n  'denn10',\n  'der1509',\n  'der1681',\n  'der557',\n  'der875',\n  'desto111',\n  'die875',\n  'diese605',\n  'dieses19',\n  'durch1574',\n  'ebenso122',\n  'ebenso98',\n  'ein127',\n  'ein1715',\n  'ein1835',\n  'ein762',\n  'einander1574',\n  'eine129',\n  'eine1715',\n  'eine1835',\n  'eine605',\n  'einem127',\n  'einer127',\n  'entweder1779',\n  'er1004',\n  'er1346',\n  'erst5',\n  'es125',\n  'es1313',\n  'es1346',\n  'es1631',\n  'es605',\n  'euch1574',\n  'excellence1342',\n  'früher1459',\n  'für13',\n  'für1525',\n  'für350',\n  'gab605',\n  'ganz697',\n  'ganz777',\n  'gar5',\n  'gar697',\n  'gar777',\n  'geben605',\n  'gegeben605',\n  'gegen83',\n  'geht1300',\n  'sein1289',\n  'selben1777',\n  'sich1573',\n  'sich1574',\n  'sich1582',\n  'sie1346',\n  'silber1554',\n  'sind130',\n  'sind1459',\n  'sind1554',\n  'sind1660',\n  'sind1881',\n  'sind875',\n  'sind976',\n  'so1134',\n  'so135',\n  'so1760',\n  'so1831',\n  'so74',\n  'so98',\n  'solch78',\n  'soll605',\n  'sondergleichen618',\n  'sondergleichen»618',\n  'sondern902',\n  'sowohl1134',\n  'stand1346',\n  'statt320',\n  'statt882',\n  'steht1346',\n  'um350',\n  'umso111',\n  'und11',\n  'und1140',\n  'und1849',\n  'und5',\n  'und697',\n  'und777',\n  'und904',\n  'uns1574',\n  'uns1582',\n  'unter671',\n  'von1034',\n  'von1035',\n  'von127',\n  'von1629',\n  'von1772',\n  'vor559',\n  'war1313',\n  'war1459',\n  'war1461',\n  'war1462',\n  'war1660',\n  'war1770',\n  'war1846',\n  'war1881',\n  'waren1459',\n  'waren1770',\n  'waren1881',\n  'was1029',\n  'was13',\n  'was1459',\n  'was1846',\n  'weder12',\n  'wegen1629',\n  'wegen1772',\n  'weil674',\n  'weil681',\n  'welch15',\n  'wenig762',\n  'wenigsten488',\n  'wenigsten492',\n  'wenn1291',\n  'wenn136',\n  'wie101',\n  'wie103',\n  'wie125',\n  'wie130',\n  'wie1346',\n  'wie136',\n  'wie1738',\n  'wird1660',\n  'wird605',\n  'wogegen320',\n  'wohingegen320',\n  'wohl11',\n  'wohl1134',\n  'wäre130',\n  'wäre1660',\n  'wäre1756',\n  'wäre1846',\n  'wären1756',\n  'wärest1756',\n  'wärst1756',\n  'würde392',\n  'würden392',\n  'würdest392',\n  'zu1034',\n  'zu1035',\n  'zu1347',\n  'zu1574',\n  'zu320',\n  'zum1313',\n  'zum1630',\n  '«Besser1762',\n  '«Keine949',\n  '«Raus1316',\n  '»Entweder1779',\n  '»Raus1316',\n  'Ähnlich123',\n  'ähnlich123',\n  'ähnlich139',\n  'über85'],\n 506)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbart_tokens = [d[0] for d in csv_data.values]\n",
    "\n",
    "mbart_tokens, len(mbart_tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T17:05:49.417102700Z",
     "start_time": "2024-01-27T17:05:49.356749400Z"
    }
   },
   "id": "d55848226af1aa95"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the vanilla mbart model:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1fd4b9029d49e1e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Embedding(250054, 1024, padding_idx=1)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MBartForConditionalGeneration.from_pretrained(\n",
    "    \"facebook/mbart-large-50\", return_dict=True\n",
    ") \n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\n",
    "    \"facebook/mbart-large-50\", src_lang=\"de_DE\", tgt_lang=\"de_DE\"\n",
    ")\n",
    "model.model.encoder.embed_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T17:06:07.525915800Z",
     "start_time": "2024-01-27T17:05:49.365645400Z"
    }
   },
   "id": "e82730a36da5ce9c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add to existing embeddings:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31cb60117910e817"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "Embedding(250560, 1024)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_embeddings = torch.cat((model.model.encoder.embed_tokens.weight, torch.tensor(pseudowords)), dim=0)\n",
    "model.model.encoder.embed_tokens = torch.nn.Embedding.from_pretrained(combined_embeddings)\n",
    "model.model.encoder.embed_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T17:06:07.662873900Z",
     "start_time": "2024-01-27T17:06:07.505863800Z"
    }
   },
   "id": "de2759094c5daff5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add to existing tokens:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36118990fc6027ce"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 250560. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": "Embedding(250560, 1024)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(mbart_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T17:06:10.454005600Z",
     "start_time": "2024-01-27T17:06:07.664237800Z"
    }
   },
   "id": "5e0c6c41fda55604"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "MBartForConditionalGeneration(\n  (model): MBartModel(\n    (shared): Embedding(250560, 1024)\n    (encoder): MBartEncoder(\n      (embed_tokens): Embedding(250560, 1024)\n      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x MBartEncoderLayer(\n          (self_attn): MBartAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): MBartDecoder(\n      (embed_tokens): Embedding(250560, 1024)\n      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x MBartDecoderLayer(\n          (self_attn): MBartAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MBartAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=1024, out_features=250560, bias=False)\n)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda:0\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T17:06:13.397542400Z",
     "start_time": "2024-01-27T17:06:10.449778200Z"
    }
   },
   "id": "29a15c814c4d9e1e",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "Complete the cues:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b006ebc8aa40484"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/562 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ddedbd635fac43749eea724c86f157aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...:.........................................:....::.............................................................................................."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 25\u001B[0m\n\u001B[0;32m     22\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m pd\u001B[38;5;241m.\u001B[39mSeries({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconstruction\u001B[39m\u001B[38;5;124m\"\u001B[39m: row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconstruction\u001B[39m\u001B[38;5;124m\"\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpseudoword\u001B[39m\u001B[38;5;124m\"\u001B[39m: row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpseudoword\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124morig_example\u001B[39m\u001B[38;5;124m\"\u001B[39m: row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexample\u001B[39m\u001B[38;5;124m\"\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerated\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mstr\u001B[39m(e), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscores\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[-1.0]\u001B[39m\u001B[38;5;124m\"\u001B[39m})\n\u001B[0;32m     24\u001B[0m examples_reset \u001B[38;5;241m=\u001B[39m examples\u001B[38;5;241m.\u001B[39mreset_index()\n\u001B[1;32m---> 25\u001B[0m pseudoword_output_scores \u001B[38;5;241m=\u001B[39m examples_reset[[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconstruction\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpseudoword\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexample\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcue\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpseudoword\u001B[39m\u001B[38;5;124m\"\u001B[39m]]\u001B[38;5;241m.\u001B[39mprogress_apply(complete_cues, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     26\u001B[0m pseudoword_output_scores\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\tqdm\\std.py:805\u001B[0m, in \u001B[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001B[1;34m(df, func, *args, **kwargs)\u001B[0m\n\u001B[0;32m    802\u001B[0m \u001B[38;5;66;03m# Apply the provided function (in **kwargs)\u001B[39;00m\n\u001B[0;32m    803\u001B[0m \u001B[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001B[39;00m\n\u001B[0;32m    804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(df, df_function)(wrapper, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    806\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    807\u001B[0m     t\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\pandas\\core\\frame.py:9423\u001B[0m, in \u001B[0;36mDataFrame.apply\u001B[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001B[0m\n\u001B[0;32m   9412\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapply\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m frame_apply\n\u001B[0;32m   9414\u001B[0m op \u001B[38;5;241m=\u001B[39m frame_apply(\n\u001B[0;32m   9415\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   9416\u001B[0m     func\u001B[38;5;241m=\u001B[39mfunc,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   9421\u001B[0m     kwargs\u001B[38;5;241m=\u001B[39mkwargs,\n\u001B[0;32m   9422\u001B[0m )\n\u001B[1;32m-> 9423\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m op\u001B[38;5;241m.\u001B[39mapply()\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapply\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\pandas\\core\\apply.py:678\u001B[0m, in \u001B[0;36mFrameApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    675\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw:\n\u001B[0;32m    676\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_raw()\n\u001B[1;32m--> 678\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_standard()\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\pandas\\core\\apply.py:798\u001B[0m, in \u001B[0;36mFrameApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    797\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_standard\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 798\u001B[0m     results, res_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_series_generator()\n\u001B[0;32m    800\u001B[0m     \u001B[38;5;66;03m# wrap results\u001B[39;00m\n\u001B[0;32m    801\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwrap_results(results, res_index)\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\pandas\\core\\apply.py:814\u001B[0m, in \u001B[0;36mFrameApply.apply_series_generator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    811\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m option_context(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode.chained_assignment\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    812\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(series_gen):\n\u001B[0;32m    813\u001B[0m         \u001B[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001B[39;00m\n\u001B[1;32m--> 814\u001B[0m         results[i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf(v)\n\u001B[0;32m    815\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(results[i], ABCSeries):\n\u001B[0;32m    816\u001B[0m             \u001B[38;5;66;03m# If we have a view on v, we need to make a copy because\u001B[39;00m\n\u001B[0;32m    817\u001B[0m             \u001B[38;5;66;03m#  series_generator will swap out the underlying data\u001B[39;00m\n\u001B[0;32m    818\u001B[0m             results[i] \u001B[38;5;241m=\u001B[39m results[i]\u001B[38;5;241m.\u001B[39mcopy(deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\tqdm\\std.py:800\u001B[0m, in \u001B[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    794\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    795\u001B[0m     \u001B[38;5;66;03m# update tbar correctly\u001B[39;00m\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001B[39;00m\n\u001B[0;32m    797\u001B[0m     \u001B[38;5;66;03m# on the first column/row to decide whether it can\u001B[39;00m\n\u001B[0;32m    798\u001B[0m     \u001B[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001B[39;00m\n\u001B[0;32m    799\u001B[0m     t\u001B[38;5;241m.\u001B[39mupdate(n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m t\u001B[38;5;241m.\u001B[39mtotal \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mn \u001B[38;5;241m<\u001B[39m t\u001B[38;5;241m.\u001B[39mtotal \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m--> 800\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "Cell \u001B[1;32mIn[15], line 12\u001B[0m, in \u001B[0;36mcomplete_cues\u001B[1;34m(row)\u001B[0m\n\u001B[0;32m      9\u001B[0m target_length \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;241m1.5\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(example))  \u001B[38;5;66;03m# allow double the length of the original sentence\u001B[39;00m\n\u001B[0;32m     11\u001B[0m outputs \u001B[38;5;241m=\u001B[39m tokenizer(input_text, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 12\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mgenerate(outputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda:0\u001B[39m\u001B[38;5;124m\"\u001B[39m), max_length\u001B[38;5;241m=\u001B[39mtarget_length, num_return_sequences\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, num_beams\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, output_scores\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, return_dict_in_generate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     13\u001B[0m output_text \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mbatch_decode(outputs\u001B[38;5;241m.\u001B[39msequences, skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     14\u001B[0m score \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mexp(outputs\u001B[38;5;241m.\u001B[39msequences_scores)\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\transformers\\generation\\utils.py:1681\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[0;32m   1674\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[0;32m   1675\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[0;32m   1676\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_beams,\n\u001B[0;32m   1677\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[0;32m   1678\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[0;32m   1679\u001B[0m     )\n\u001B[0;32m   1680\u001B[0m     \u001B[38;5;66;03m# 13. run beam search\u001B[39;00m\n\u001B[1;32m-> 1681\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbeam_search(\n\u001B[0;32m   1682\u001B[0m         input_ids,\n\u001B[0;32m   1683\u001B[0m         beam_scorer,\n\u001B[0;32m   1684\u001B[0m         logits_processor\u001B[38;5;241m=\u001B[39mlogits_processor,\n\u001B[0;32m   1685\u001B[0m         stopping_criteria\u001B[38;5;241m=\u001B[39mstopping_criteria,\n\u001B[0;32m   1686\u001B[0m         pad_token_id\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mpad_token_id,\n\u001B[0;32m   1687\u001B[0m         eos_token_id\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39meos_token_id,\n\u001B[0;32m   1688\u001B[0m         output_scores\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39moutput_scores,\n\u001B[0;32m   1689\u001B[0m         return_dict_in_generate\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mreturn_dict_in_generate,\n\u001B[0;32m   1690\u001B[0m         synced_gpus\u001B[38;5;241m=\u001B[39msynced_gpus,\n\u001B[0;32m   1691\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[0;32m   1692\u001B[0m     )\n\u001B[0;32m   1694\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;241m==\u001B[39m GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SAMPLE:\n\u001B[0;32m   1695\u001B[0m     \u001B[38;5;66;03m# 11. prepare logits warper\u001B[39;00m\n\u001B[0;32m   1696\u001B[0m     logits_warper \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_logits_warper(generation_config)\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\transformers\\generation\\utils.py:3020\u001B[0m, in \u001B[0;36mGenerationMixin.beam_search\u001B[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001B[0m\n\u001B[0;32m   3016\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m   3018\u001B[0m model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_inputs_for_generation(input_ids, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs)\n\u001B[1;32m-> 3020\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m(\n\u001B[0;32m   3021\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_inputs,\n\u001B[0;32m   3022\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m   3023\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[0;32m   3024\u001B[0m     output_hidden_states\u001B[38;5;241m=\u001B[39moutput_hidden_states,\n\u001B[0;32m   3025\u001B[0m )\n\u001B[0;32m   3027\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m synced_gpus \u001B[38;5;129;01mand\u001B[39;00m this_peer_finished:\n\u001B[0;32m   3028\u001B[0m     cur_len \u001B[38;5;241m=\u001B[39m cur_len \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\transformers\\models\\mbart\\modeling_mbart.py:1357\u001B[0m, in \u001B[0;36mMBartForConditionalGeneration.forward\u001B[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1354\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m decoder_input_ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m decoder_inputs_embeds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1355\u001B[0m         decoder_input_ids \u001B[38;5;241m=\u001B[39m shift_tokens_right(labels, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mpad_token_id)\n\u001B[1;32m-> 1357\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(\n\u001B[0;32m   1358\u001B[0m     input_ids,\n\u001B[0;32m   1359\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[0;32m   1360\u001B[0m     decoder_input_ids\u001B[38;5;241m=\u001B[39mdecoder_input_ids,\n\u001B[0;32m   1361\u001B[0m     encoder_outputs\u001B[38;5;241m=\u001B[39mencoder_outputs,\n\u001B[0;32m   1362\u001B[0m     decoder_attention_mask\u001B[38;5;241m=\u001B[39mdecoder_attention_mask,\n\u001B[0;32m   1363\u001B[0m     head_mask\u001B[38;5;241m=\u001B[39mhead_mask,\n\u001B[0;32m   1364\u001B[0m     decoder_head_mask\u001B[38;5;241m=\u001B[39mdecoder_head_mask,\n\u001B[0;32m   1365\u001B[0m     cross_attn_head_mask\u001B[38;5;241m=\u001B[39mcross_attn_head_mask,\n\u001B[0;32m   1366\u001B[0m     past_key_values\u001B[38;5;241m=\u001B[39mpast_key_values,\n\u001B[0;32m   1367\u001B[0m     inputs_embeds\u001B[38;5;241m=\u001B[39minputs_embeds,\n\u001B[0;32m   1368\u001B[0m     decoder_inputs_embeds\u001B[38;5;241m=\u001B[39mdecoder_inputs_embeds,\n\u001B[0;32m   1369\u001B[0m     use_cache\u001B[38;5;241m=\u001B[39muse_cache,\n\u001B[0;32m   1370\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[0;32m   1371\u001B[0m     output_hidden_states\u001B[38;5;241m=\u001B[39moutput_hidden_states,\n\u001B[0;32m   1372\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[0;32m   1373\u001B[0m )\n\u001B[0;32m   1374\u001B[0m lm_logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlm_head(outputs[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinal_logits_bias\n\u001B[0;32m   1376\u001B[0m masked_lm_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\transformers\\models\\mbart\\modeling_mbart.py:1243\u001B[0m, in \u001B[0;36mMBartModel.forward\u001B[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1236\u001B[0m     encoder_outputs \u001B[38;5;241m=\u001B[39m BaseModelOutput(\n\u001B[0;32m   1237\u001B[0m         last_hidden_state\u001B[38;5;241m=\u001B[39mencoder_outputs[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m   1238\u001B[0m         hidden_states\u001B[38;5;241m=\u001B[39mencoder_outputs[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(encoder_outputs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1239\u001B[0m         attentions\u001B[38;5;241m=\u001B[39mencoder_outputs[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(encoder_outputs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1240\u001B[0m     )\n\u001B[0;32m   1242\u001B[0m \u001B[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001B[39;00m\n\u001B[1;32m-> 1243\u001B[0m decoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder(\n\u001B[0;32m   1244\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39mdecoder_input_ids,\n\u001B[0;32m   1245\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mdecoder_attention_mask,\n\u001B[0;32m   1246\u001B[0m     encoder_hidden_states\u001B[38;5;241m=\u001B[39mencoder_outputs[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m   1247\u001B[0m     encoder_attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[0;32m   1248\u001B[0m     head_mask\u001B[38;5;241m=\u001B[39mdecoder_head_mask,\n\u001B[0;32m   1249\u001B[0m     cross_attn_head_mask\u001B[38;5;241m=\u001B[39mcross_attn_head_mask,\n\u001B[0;32m   1250\u001B[0m     past_key_values\u001B[38;5;241m=\u001B[39mpast_key_values,\n\u001B[0;32m   1251\u001B[0m     inputs_embeds\u001B[38;5;241m=\u001B[39mdecoder_inputs_embeds,\n\u001B[0;32m   1252\u001B[0m     use_cache\u001B[38;5;241m=\u001B[39muse_cache,\n\u001B[0;32m   1253\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[0;32m   1254\u001B[0m     output_hidden_states\u001B[38;5;241m=\u001B[39moutput_hidden_states,\n\u001B[0;32m   1255\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[0;32m   1256\u001B[0m )\n\u001B[0;32m   1258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_dict:\n\u001B[0;32m   1259\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m decoder_outputs \u001B[38;5;241m+\u001B[39m encoder_outputs\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\transformers\\models\\mbart\\modeling_mbart.py:1108\u001B[0m, in \u001B[0;36mMBartDecoder.forward\u001B[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1097\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[0;32m   1098\u001B[0m         create_custom_forward(decoder_layer),\n\u001B[0;32m   1099\u001B[0m         hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1105\u001B[0m         \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1106\u001B[0m     )\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1108\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m decoder_layer(\n\u001B[0;32m   1109\u001B[0m         hidden_states,\n\u001B[0;32m   1110\u001B[0m         attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[0;32m   1111\u001B[0m         encoder_hidden_states\u001B[38;5;241m=\u001B[39mencoder_hidden_states,\n\u001B[0;32m   1112\u001B[0m         encoder_attention_mask\u001B[38;5;241m=\u001B[39mencoder_attention_mask,\n\u001B[0;32m   1113\u001B[0m         layer_head_mask\u001B[38;5;241m=\u001B[39m(head_mask[idx] \u001B[38;5;28;01mif\u001B[39;00m head_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m   1114\u001B[0m         cross_attn_layer_head_mask\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1115\u001B[0m             cross_attn_head_mask[idx] \u001B[38;5;28;01mif\u001B[39;00m cross_attn_head_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1116\u001B[0m         ),\n\u001B[0;32m   1117\u001B[0m         past_key_value\u001B[38;5;241m=\u001B[39mpast_key_value,\n\u001B[0;32m   1118\u001B[0m         output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[0;32m   1119\u001B[0m         use_cache\u001B[38;5;241m=\u001B[39muse_cache,\n\u001B[0;32m   1120\u001B[0m     )\n\u001B[0;32m   1121\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1123\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\transformers\\models\\mbart\\modeling_mbart.py:439\u001B[0m, in \u001B[0;36mMBartDecoderLayer.forward\u001B[1;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001B[0m\n\u001B[0;32m    437\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m encoder_hidden_states \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    438\u001B[0m     residual \u001B[38;5;241m=\u001B[39m hidden_states\n\u001B[1;32m--> 439\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder_attn_layer_norm(hidden_states)\n\u001B[0;32m    441\u001B[0m     \u001B[38;5;66;03m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001B[39;00m\n\u001B[0;32m    442\u001B[0m     cross_attn_past_key_value \u001B[38;5;241m=\u001B[39m past_key_value[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m:] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:196\u001B[0m, in \u001B[0;36mLayerNorm.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    195\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 196\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mlayer_norm(\n\u001B[0;32m    197\u001B[0m         \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnormalized_shape, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meps)\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\torch\\nn\\functional.py:2543\u001B[0m, in \u001B[0;36mlayer_norm\u001B[1;34m(input, normalized_shape, weight, bias, eps)\u001B[0m\n\u001B[0;32m   2539\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_variadic(\u001B[38;5;28minput\u001B[39m, weight, bias):\n\u001B[0;32m   2540\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m   2541\u001B[0m         layer_norm, (\u001B[38;5;28minput\u001B[39m, weight, bias), \u001B[38;5;28minput\u001B[39m, normalized_shape, weight\u001B[38;5;241m=\u001B[39mweight, bias\u001B[38;5;241m=\u001B[39mbias, eps\u001B[38;5;241m=\u001B[39meps\n\u001B[0;32m   2542\u001B[0m     )\n\u001B[1;32m-> 2543\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mlayer_norm(\u001B[38;5;28minput\u001B[39m, normalized_shape, weight, bias, eps, torch\u001B[38;5;241m.\u001B[39mbackends\u001B[38;5;241m.\u001B[39mcudnn\u001B[38;5;241m.\u001B[39menabled)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def complete_cues(row):\n",
    "    try:\n",
    "        output_texts = []\n",
    "        scores = []\n",
    "        for cue, example in zip(row[\"cue\"], row[\"example\"]):\n",
    "            assert row[\"pseudoword\"].iloc[0] in mbart_tokens  # skip pseudoword embeddings that haven't been learned\n",
    "            \n",
    "            input_text = cue + \" \" + row[\"pseudoword\"].iloc[0] + \" <mask>\"\n",
    "            target_length = int(1.5 * len(example))  # allow double the length of the original sentence\n",
    "            \n",
    "            outputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "            outputs = model.generate(outputs[\"input_ids\"].to(\"cuda:0\"), max_length=target_length, num_return_sequences=1, num_beams=10, output_scores=True, return_dict_in_generate=True)\n",
    "            output_text = tokenizer.batch_decode(outputs.sequences, skip_special_tokens=True)\n",
    "            score = torch.exp(outputs.sequences_scores)\n",
    "            output_texts += output_text\n",
    "            \n",
    "            scores.append(score)\n",
    "        print(\".\", end=\"\")\n",
    "        return pd.Series({\"construction\": row[\"construction\"], \"pseudoword\": row[\"pseudoword\"].iloc[0], \"orig_example\": row[\"example\"], \"generated\": str(output_texts), \"scores\": str([float(score) for score in scores])})\n",
    "    except Exception as e:\n",
    "        print(\":\", end=\"\")\n",
    "        return pd.Series({\"construction\": row[\"construction\"], \"pseudoword\": row[\"pseudoword\"].iloc[0], \"orig_example\": row[\"example\"], \"generated\": str(e), \"scores\": \"[-1.0]\"})\n",
    "\n",
    "examples_reset = examples.reset_index()\n",
    "pseudoword_output_scores = examples_reset[[\"construction\", \"pseudoword\", \"example\", \"cue\", \"pseudoword\"]].progress_apply(complete_cues, axis=1)\n",
    "pseudoword_output_scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T17:51:01.066952700Z",
     "start_time": "2024-01-27T17:06:13.395540700Z"
    }
   },
   "id": "b7fc546c4aeb79b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "examples = pseudoword_output_scores[[\"pseudoword\", \"generated\", \"scores\"]]\n",
    "\n",
    "examples"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-27T17:51:01.059958700Z"
    }
   },
   "id": "14e01733b5a4aeba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Anzahl neuer Sätze"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a64a06083f0ccd35"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "examples.to_csv(f\"../../out/comapp/mbart/data_mbart.tsv\", sep=\"\\t\", decimal=\",\")\n",
    "examples.to_excel(f\"../../out/comapp/mbart/data_mbart.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-27T17:51:01.060956500Z"
    }
   },
   "id": "93ee2263ebe468ba"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pseudoword_output_scores.to_csv(\"../../out/comapp/mbart/data_mbart_complete.tsv\", sep=\"\\t\", decimal=\",\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-27T17:51:01.061953200Z"
    }
   },
   "id": "a890185b466ac02e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
