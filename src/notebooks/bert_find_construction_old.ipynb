{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-22T23:18:40.894594630Z",
     "start_time": "2024-01-22T23:18:34.207715836Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9374/2916255755.py:7: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertForNextSentencePrediction, BertTokenizer\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['\"\"Was13',\n '\"647',\n '\"Wir-äh-spielen-äh-in-der-äh-Champions-League647',\n '(1597',\n '(1600',\n '(1602',\n '(1624',\n '(1637',\n '(1639',\n '(1641',\n '(1643',\n '(1645',\n '(379',\n '(579',\n '(581',\n '(584',\n '(590',\n '(592',\n '(600',\n '(886',\n '(889',\n '(892',\n '(900',\n '(905',\n '(907',\n '(909',\n '(911',\n '(917',\n '(919',\n '(921',\n '(923',\n ')1597',\n ')1600',\n ')1602',\n ')1624',\n ')1637',\n ')1639',\n ')1641',\n ')1643',\n ')1645',\n ')1792',\n ')379',\n ')579',\n ')581',\n ')584',\n ')590',\n ')592',\n ')600',\n ')886',\n ')889',\n ')892',\n ')900',\n ')905',\n ')907',\n ')909',\n ')911',\n ')917',\n ')919',\n ')921',\n ')923',\n ')«579',\n ',1459',\n ',973',\n '-128',\n '-651',\n '-654',\n '-875',\n '-973',\n ':595',\n ':875',\n ':973',\n 'Abstand683',\n 'Allein20',\n 'Aller1630',\n 'Als1315',\n 'Als133',\n 'Als1770',\n 'Am488',\n 'Am492',\n 'Am500',\n 'Amerika605',\n 'Anstatt320',\n 'Art129',\n 'Arzt1509',\n 'Augenblick1301',\n 'Ausmaß1777',\n 'BRUTAL1503',\n 'Besser1762',\n 'Bis559',\n 'Brutal1503',\n 'Buche1346',\n 'Das1313',\n 'Das1461',\n 'Dass21',\n 'Dasselbe104',\n 'Der1301',\n 'Desto111',\n 'Die1681',\n 'Diese19',\n 'Dieser1301',\n 'Dieser19',\n 'Dieses19',\n 'Entweder1779',\n 'Es1313',\n 'Es605',\n 'Gefühl1301',\n 'Generation1126',\n 'Geschweige10',\n 'Gleiche104',\n 'Gold1554',\n 'Gold1884',\n 'Hauptsache1033',\n 'Im557',\n 'In557',\n 'In858',\n 'Inbegriff1671',\n 'Ist1660',\n 'Je111',\n 'Jedermanns1329',\n 'Jener1301',\n 'Jetzt1631',\n 'Kein1525',\n 'Kein1715',\n 'Kein1835',\n 'Kein949',\n 'Keine(r1792',\n 'Keine1525',\n 'Keine1715',\n 'Keine1792',\n 'Keine1835',\n 'Keine902',\n 'Keine949',\n 'Keiner1792',\n 'Leben1461',\n 'Leben605',\n 'Lecker1649',\n 'Maß1777',\n 'Maße1777',\n 'Mit1029',\n 'Mit683',\n 'Moment1301',\n 'Mords651',\n 'Mutter1681',\n 'Neue875',\n 'Nicht1162',\n 'Nicht902',\n 'Niemand1792',\n 'Ponyhof1462',\n 'Raus1316',\n 'Reden1554',\n 'Riesen654',\n 'Silber1554',\n 'Silber1884',\n 'So1300',\n 'So1760',\n 'So1831',\n 'So22',\n 'So74',\n 'So98',\n 'Solch78',\n 'Solche78',\n 'Sowohl1134',\n 'Statt320',\n 'Tode1347',\n 'Trotz1630',\n 'Umfang1777',\n 'Umso111',\n 'Und11',\n 'Und5',\n 'Von1034',\n 'Von1629',\n 'Von1772',\n 'Warum1029',\n 'Was1029',\n 'Was13',\n 'Was16',\n 'Was1846',\n 'Weder12',\n 'Weil674',\n 'Weil681',\n 'Welch15',\n 'Wem1029',\n 'Wenn1291',\n 'Wer1029',\n 'Wie1029',\n 'Wie14',\n 'Wie1738',\n 'Wo1029',\n 'Wo976',\n 'Während320',\n 'Zeit605',\n 'Zeiten605',\n '[1643',\n ']1643',\n 'ab1574',\n 'aber902',\n 'allen1630',\n 'aller1630',\n 'aller1681',\n 'aller758',\n 'als1134',\n 'als133',\n 'als1762',\n 'als1770',\n 'als97',\n 'am488',\n 'am492',\n 'am500',\n 'an349',\n 'anstatt320',\n 'anstatt882',\n 'artig128',\n 'auch1134',\n 'auch1715',\n 'auch1835',\n 'auf1574',\n 'auf350',\n 'aufhübschen1029',\n 'aus1316',\n 'ausbreiten1029',\n 'auslöste1029',\n 'badete1029',\n 'bedeutet1029',\n 'besser1762',\n 'betreffen1029',\n 'bis1509',\n 'bis559',\n 'bisschen762',\n 'bleibt1660',\n 'braucht1029',\n 'bringt1029',\n 'brutal1503',\n 'darstellen1029',\n 'das104',\n 'das1301',\n 'das1459',\n 'das1461',\n 'das875',\n 'dass135',\n 'dasselbe104',\n 'dem1777',\n 'den557',\n 'den671',\n 'denn10',\n 'der1509',\n 'der1681',\n 'der557',\n 'der875',\n 'desto111',\n 'die1681',\n 'die875',\n 'diese605',\n 'dieses19',\n 'durch1574',\n 'ebenso122',\n 'ebenso98',\n 'ein127',\n 'ein1715',\n 'ein1835',\n 'ein762',\n 'einander1574',\n 'eine129',\n 'eine1715',\n 'eine1835',\n 'eine605',\n 'einem127',\n 'einer127',\n 'entweder1779',\n 'er1004',\n 'er1346',\n 'er99',\n 'erst5',\n 'erzeugt1029',\n 'es125',\n 'es1313',\n 'es1346',\n 'es1631',\n 'es605',\n 'euch1574',\n 'excellence1342',\n 'fahre1029',\n 'früher1459',\n 'für13',\n 'für1525',\n 'für350',\n 'gab605',\n 'ganz697',\n 'ganz777',\n 'gar5',\n 'gar697',\n 'gar777',\n 'geben605',\n 'gegeben605',\n 'gegen83',\n 'gehen1029',\n 'geht1300',\n 'genauso122',\n 'genauso98',\n 'geschweige10',\n 'gewesen1459',\n 'gibt605',\n 'gleich100',\n 'gleich675',\n 'gleich676',\n 'gleich98',\n 'gleiche104',\n 'gleichen1777',\n 'gleichkam676',\n 'gleichkommen676',\n 'gleichkommt676',\n 'gleichkäme676',\n 'gleicht132',\n 'gold1554',\n 'habe605',\n 'haben1029',\n 'haben605',\n 'hat605',\n 'hatte605',\n 'heisst1631',\n 'her1351',\n 'her1511',\n 'herunter1574',\n 'heute1459',\n 'hin1351',\n 'hin1511',\n 'hinaus1574',\n 'hindurch1574',\n 'hinunter1574',\n 'hätte1756',\n 'hätten1756',\n 'hättest1756',\n 'im1346',\n 'im1777',\n 'im557',\n 'in1316',\n 'in1777',\n 'in557',\n 'in605',\n 'in858',\n 'irrte1029',\n 'isst1029',\n 'ist1029',\n 'ist125',\n 'ist130',\n 'ist1313',\n 'ist1459',\n 'ist1461',\n 'ist1462',\n 'ist1554',\n 'ist1660',\n 'ist1715',\n 'ist1792',\n 'ist1835',\n 'ist1846',\n 'ist1881',\n 'ist1884',\n 'ist875',\n 'ist976',\n 'je111',\n 'jedermanns1329',\n 'jetzt1631',\n 'kam676',\n 'kann1593',\n 'kaum11',\n 'kaum1986',\n 'kein1461',\n 'kein1462',\n 'kein1525',\n 'kein1690',\n 'kein1715',\n 'kein1881',\n 'kein902',\n 'kein949',\n 'keine1461',\n 'keine1525',\n 'keine1715',\n 'keine1835',\n 'keine1881',\n 'keine605',\n 'keine902',\n 'keine949',\n 'keiner1792',\n 'kleiden1029',\n 'kommen1509',\n 'kommen676',\n 'kommt1509',\n 'kommt676',\n 'kostet1029',\n 'käme676',\n 'lachen1029',\n 'lassen1029',\n 'lassen1289',\n 'lebte1029',\n 'lecker1649',\n 'ließ1289',\n 'lässt1289',\n 'läuft1029',\n 'macht1029',\n 'machte1029',\n 'mag605',\n 'meinem605',\n 'meisten488',\n 'meisten492',\n 'mich1573',\n 'mich1574',\n 'mir1582',\n 'mit1846',\n 'mit683',\n 'mords651',\n 'muss1300',\n 'musste1509',\n 'müssen1029',\n 'neue875',\n 'neuen875',\n 'nicht.“1779',\n 'nicht1162',\n 'nicht1690',\n 'nicht1779',\n 'nicht5',\n 'nicht902',\n 'nicht904',\n 'niemand1525',\n 'niemand1792',\n 'noch12',\n 'noch1770',\n 'nämliche104',\n 'nützt1029',\n 'ob1315',\n 'ob133',\n 'oder1162',\n 'oder1779',\n 'oder973',\n 'ohne1690',\n 'ohne949',\n 'ohnegleichen618',\n 'par1342',\n 'pur.»1323',\n 'pur1323',\n 'pur«1323',\n 'raus1316',\n 'recht5',\n 'redet1029',\n 'rein1316',\n 'ruiniert1029',\n 'satt1324',\n 'schlechthin1556',\n 'schlechthin»1556',\n 'schon5',\n 'schufen1029',\n 'schützt1029',\n 'sehr1987',\n 'sei125',\n 'seien1660',\n 'sein1289',\n 'selben1777',\n 'sich1573',\n 'sich1574',\n 'sich1582',\n 'sie1346',\n 'silber1554',\n 'sind1029',\n 'sind130',\n 'sind1459',\n 'sind1554',\n 'sind1660',\n 'sind1881',\n 'sind875',\n 'sind976',\n 'so1134',\n 'so135',\n 'so1760',\n 'so1831',\n 'so74',\n 'so98',\n 'solch78',\n 'soll605',\n 'sollten1029',\n 'sondergleichen618',\n 'sondergleichen»618',\n 'sondern902',\n 'sowohl1134',\n 'stand1346',\n 'statt320',\n 'statt882',\n 'steht1346',\n 'um350',\n 'umso111',\n 'und1029',\n 'und11',\n 'und1140',\n 'und1849',\n 'und5',\n 'und697',\n 'und777',\n 'und904',\n 'uns1574',\n 'uns1582',\n 'unter671',\n 'verdient1029',\n 'verändern1029',\n 'von1034',\n 'von1035',\n 'von127',\n 'von1629',\n 'von1772',\n 'vor559',\n 'war1313',\n 'war1459',\n 'war1461',\n 'war1462',\n 'war1660',\n 'war1770',\n 'war1846',\n 'war1881',\n 'waren1459',\n 'waren1770',\n 'waren1881',\n 'was1029',\n 'was13',\n 'was1459',\n 'was1846',\n 'weder12',\n 'wegen1629',\n 'wegen1772',\n 'weil674',\n 'weil681',\n 'welch15',\n 'wem1029',\n 'wenig762',\n 'wenigsten488',\n 'wenigsten492',\n 'wenn1291',\n 'wenn136',\n 'werden1029',\n 'wie101',\n 'wie103',\n 'wie125',\n 'wie130',\n 'wie1346',\n 'wie136',\n 'wie1738',\n 'will1029',\n 'wird1029',\n 'wird1660',\n 'wird605',\n 'wissen1029',\n 'wo1029',\n 'wogegen320',\n 'wohingegen320',\n 'wohl11',\n 'wohl1134',\n 'wollen1029',\n 'wäre130',\n 'wäre1660',\n 'wäre1756']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudowords = []\n",
    "for i in range(15):\n",
    "    pseudowords.append(np.load(f\"../../data/pseudowords/bsbbert/pseudowords_comapp_bsbbert_{i*37}_{i*37+37}.npy\"))\n",
    "pseudowords = np.concatenate(pseudowords)\n",
    "\n",
    "csv_data = []\n",
    "for i in range(1, 16):\n",
    "    csv_data.append(pd.read_csv(f\"../../data/pseudowords/bsbbert/order_bsbbert_{i}.csv\", sep=\";\", index_col=0, header=None, quotechar=\"|\", names=[\"order\", \"label\"]))\n",
    "csv_data = pd.concat(csv_data)\n",
    "\n",
    "bert_tokens = [d[0] for d in csv_data.values]\n",
    "bert_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T23:18:40.932559478Z",
     "start_time": "2024-01-22T23:18:37.170672159Z"
    }
   },
   "id": "c395ff268451a4b2",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForNextSentencePrediction were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "BertForNextSentencePrediction(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(31657, 768)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (cls): BertOnlyNSPHead(\n    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n  )\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForNextSentencePrediction.from_pretrained(\"dbmdz/bert-base-german-cased\", return_dict=True)\n",
    "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-german-cased')\n",
    "\n",
    "combined_embeddings = torch.cat((model.bert.embeddings.word_embeddings.weight, torch.tensor(pseudowords)), dim=0)\n",
    "model.bert.embeddings.word_embeddings = torch.nn.Embedding.from_pretrained(combined_embeddings)\n",
    "tokenizer.add_tokens(bert_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.to(\"cuda:0\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T23:18:40.935363280Z",
     "start_time": "2024-01-22T23:18:37.215107333Z"
    }
   },
   "id": "737979872a7f76f1",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(\"../../out/definitions.pickle\", \"rb\") as file:\n",
    "    definitions = pickle.load(file)\n",
    "with open(\"../../out/sentences.pickle\", \"rb\") as file:\n",
    "    sentences = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T23:18:40.955995448Z",
     "start_time": "2024-01-22T23:18:38.810825894Z"
    }
   },
   "id": "eb7917f993cd42d8",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def find_examples(definition, examples):\n",
    "    predictions = {}\n",
    "    for num, example in enumerate(examples):\n",
    "        len_prompt = len(definition) + len(\" Zum Beispiel: \") + len(example)\n",
    "        if len_prompt > 512:\n",
    "            prompt = definition[:512-len_prompt+len(definition)-1] + \"… Zum Beispiel: \"\n",
    "            if len(prompt) > 512:\n",
    "                prompt = prompt[:511] + \"…\"\n",
    "        else:\n",
    "            prompt = definition + \" Zum Beispiel: \"  # TODO Deutsch\n",
    "        \n",
    "        inputs = tokenizer(prompt, example, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predictions[num] = logits[0, 0]  # probability that the next sentence makes sense\n",
    "    res = max(predictions, key=predictions.get)\n",
    "    return examples[res]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T23:18:40.957068265Z",
     "start_time": "2024-01-22T23:18:38.828205699Z"
    }
   },
   "id": "693ad2b73bd9bcb",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3973073a41b04712ad34bf2c09f0d86b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b9873d1c4237491bbb451e9f5523c4f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "22339ed7a2b84b84b9eb56ff14a8de18"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cf2a5cead7464372b47b529bf732b1b0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "905b7abd84d5434aaf185a345cb29223"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cdc492a18f6c49d58b493ad10f6d452e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(15)\n",
    "attempts = 10\n",
    "for false_positives in range(2, 8):\n",
    "    result = []\n",
    "    for key, definition in tqdm(definitions.items()):\n",
    "        for attempt in range(attempts):\n",
    "            try:\n",
    "                sentence = random.choice(list(sentences[int(key)]))\n",
    "            except KeyError:\n",
    "                #print(None, None, None)\n",
    "                result.append(pd.Series({\"constr\": key, \"definition\": definition, \"example\": None, \"prediction\": None, \"correct\": None}))\n",
    "                continue\n",
    "            others = itertools.chain.from_iterable([sentence_list for constr, sentence_list in sentences.items() if int(constr) != int(key)])\n",
    "            others = random.choices(list(others), k=false_positives)\n",
    "            examples = list(set(others) | {sentence})\n",
    "            prediction = find_examples(definition, examples)\n",
    "            #print(prediction == sentence, sentence, prediction)\n",
    "            result.append(pd.Series({\"constr\": key, \"definition\": definition, \"example\": sentence, \"prediction\": prediction, \"correct\": prediction == sentence}))\n",
    "    result = pd.DataFrame(result)\n",
    "    result.to_csv(f\"../../out/comapp/result_1_vs_{false_positives}_{attempts}attempts_bsbbert.tsv\", sep=\"\\t\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T23:30:16.256838716Z",
     "start_time": "2024-01-22T23:18:38.839777103Z"
    }
   },
   "id": "ecad5aeec67bfd80",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{5: {'Und5', 'erst5', 'gar5', 'nicht5', 'recht5', 'schon5', 'und5'},\n 10: {'Geschweige10', 'denn10', 'geschweige10'},\n 11: {'Und11', 'kaum11', 'und11', 'wohl11'},\n 12: {'Weder12', 'noch12', 'weder12'},\n 13: {'\"\"Was13', 'Was13', 'für13', 'was13'},\n 14: {'Wie14'},\n 15: {'Welch15', 'welch15'},\n 16: {'Was16'},\n 19: {'Diese19', 'Dieser19', 'Dieses19', 'dieses19'},\n 20: {'Allein20'},\n 21: {'Dass21'},\n 22: {'So22'},\n 74: {'So74', 'so74'},\n 78: {'Solch78', 'Solche78', 'solch78'},\n 83: {'gegen83'},\n 97: {'als97'},\n 98: {'So98', 'ebenso98', 'genauso98', 'gleich98', 'so98'},\n 99: {'er99'},\n 100: {'gleich100'},\n 101: {'wie101'},\n 103: {'wie103'},\n 104: {'Dasselbe104',\n  'Gleiche104',\n  'das104',\n  'dasselbe104',\n  'gleiche104',\n  'nämliche104'},\n 111: {'Desto111', 'Je111', 'Umso111', 'desto111', 'je111', 'umso111'},\n 122: {'ebenso122', 'genauso122'},\n 125: {'es125', 'ist125', 'sei125', 'wie125'},\n 127: {'ein127', 'einem127', 'einer127', 'von127'},\n 128: {'-128', 'artig128'},\n 129: {'Art129', 'eine129'},\n 130: {'ist130', 'sind130', 'wie130', 'wäre130'},\n 132: {'gleicht132'},\n 133: {'Als133', 'als133', 'ob133'},\n 135: {'dass135', 'so135'},\n 136: {'wenn136', 'wie136'},\n 320: {'Anstatt320',\n  'Statt320',\n  'Während320',\n  'anstatt320',\n  'statt320',\n  'wogegen320',\n  'wohingegen320'},\n 349: {'an349'},\n 350: {'auf350', 'für350', 'um350'},\n 379: {'(379', ')379'},\n 488: {'Am488', 'am488', 'meisten488', 'wenigsten488'},\n 492: {'Am492', 'am492', 'meisten492', 'wenigsten492'},\n 500: {'Am500', 'am500'},\n 557: {'Im557', 'In557', 'den557', 'der557', 'im557', 'in557'},\n 559: {'Bis559', 'bis559', 'vor559'},\n 579: {'(579', ')579', ')«579'},\n 581: {'(581', ')581'},\n 584: {'(584', ')584'},\n 590: {'(590', ')590'},\n 592: {'(592', ')592'},\n 595: {':595'},\n 600: {'(600', ')600'},\n 605: {'Amerika605',\n  'Es605',\n  'Leben605',\n  'Zeit605',\n  'Zeiten605',\n  'diese605',\n  'eine605',\n  'es605',\n  'gab605',\n  'geben605',\n  'gegeben605',\n  'gibt605',\n  'habe605',\n  'haben605',\n  'hat605',\n  'hatte605',\n  'in605',\n  'keine605',\n  'mag605',\n  'meinem605',\n  'soll605',\n  'wird605'},\n 618: {'ohnegleichen618', 'sondergleichen618', 'sondergleichen»618'},\n 647: {'\"647', '\"Wir-äh-spielen-äh-in-der-äh-Champions-League647'},\n 651: {'-651', 'Mords651', 'mords651'},\n 654: {'-654', 'Riesen654'},\n 671: {'den671', 'unter671'},\n 674: {'Weil674', 'weil674'},\n 675: {'gleich675'},\n 676: {'gleich676',\n  'gleichkam676',\n  'gleichkommen676',\n  'gleichkommt676',\n  'gleichkäme676',\n  'kam676',\n  'kommen676',\n  'kommt676',\n  'käme676'},\n 681: {'Weil681', 'weil681'},\n 683: {'Abstand683', 'Mit683', 'mit683'},\n 697: {'ganz697', 'gar697', 'und697'},\n 758: {'aller758'},\n 762: {'bisschen762', 'ein762', 'wenig762'},\n 777: {'ganz777', 'gar777', 'und777'},\n 858: {'In858', 'in858'},\n 875: {'-875',\n  ':875',\n  'Neue875',\n  'das875',\n  'der875',\n  'die875',\n  'ist875',\n  'neue875',\n  'neuen875',\n  'sind875'},\n 882: {'anstatt882', 'statt882'},\n 886: {'(886', ')886'},\n 889: {'(889', ')889'},\n 892: {'(892', ')892'},\n 900: {'(900', ')900'},\n 902: {'Keine902',\n  'Nicht902',\n  'aber902',\n  'kein902',\n  'keine902',\n  'nicht902',\n  'sondern902'},\n 904: {'nicht904', 'und904'},\n 905: {'(905', ')905'},\n 907: {'(907', ')907'},\n 909: {'(909', ')909'},\n 911: {'(911', ')911'},\n 917: {'(917', ')917'},\n 919: {'(919', ')919'},\n 921: {'(921', ')921'},\n 923: {'(923', ')923'},\n 949: {'Kein949', 'Keine949', 'kein949', 'keine949', 'ohne949'},\n 973: {',973', '-973', ':973', 'oder973'},\n 976: {'Wo976', 'ist976', 'sind976'},\n 1004: {'er1004'},\n 1029: {'Mit1029',\n  'Warum1029',\n  'Was1029',\n  'Wem1029',\n  'Wer1029',\n  'Wie1029',\n  'Wo1029',\n  'aufhübschen1029',\n  'ausbreiten1029',\n  'auslöste1029',\n  'badete1029',\n  'bedeutet1029',\n  'betreffen1029',\n  'braucht1029',\n  'bringt1029',\n  'darstellen1029',\n  'erzeugt1029',\n  'fahre1029',\n  'gehen1029',\n  'haben1029',\n  'irrte1029',\n  'isst1029',\n  'ist1029',\n  'kleiden1029',\n  'kostet1029',\n  'lachen1029',\n  'lassen1029',\n  'lebte1029',\n  'läuft1029',\n  'macht1029',\n  'machte1029',\n  'müssen1029',\n  'nützt1029',\n  'redet1029',\n  'ruiniert1029',\n  'schufen1029',\n  'schützt1029',\n  'sind1029',\n  'sollten1029',\n  'und1029',\n  'verdient1029',\n  'verändern1029',\n  'was1029',\n  'wem1029',\n  'werden1029',\n  'will1029',\n  'wird1029',\n  'wissen1029',\n  'wo1029',\n  'wollen1029'},\n 1033: {'Hauptsache1033'},\n 1034: {'Von1034', 'von1034'},\n 1035: {'von1035'},\n 1126: {'Generation1126'},\n 1134: {'Sowohl1134',\n  'als1134',\n  'auch1134',\n  'so1134',\n  'sowohl1134',\n  'wohl1134'},\n 1140: {'und1140'},\n 1162: {'Nicht1162', 'nicht1162', 'oder1162'},\n 1289: {'lassen1289', 'ließ1289', 'lässt1289', 'sein1289'},\n 1291: {'Wenn1291', 'wenn1291'},\n 1300: {'So1300', 'geht1300', 'muss1300'},\n 1301: {'Augenblick1301',\n  'Der1301',\n  'Dieser1301',\n  'Gefühl1301',\n  'Jener1301',\n  'Moment1301',\n  'das1301'},\n 1313: {'Das1313', 'Es1313', 'es1313', 'ist1313', 'war1313'},\n 1315: {'Als1315', 'ob1315'},\n 1316: {'Raus1316', 'aus1316', 'in1316', 'raus1316', 'rein1316'},\n 1323: {'pur.»1323', 'pur1323', 'pur«1323'},\n 1324: {'satt1324'},\n 1329: {'Jedermanns1329', 'jedermanns1329'},\n 1342: {'excellence1342', 'par1342'},\n 1346: {'Buche1346',\n  'er1346',\n  'es1346',\n  'im1346',\n  'sie1346',\n  'stand1346',\n  'steht1346',\n  'wie1346'},\n 1347: {'Tode1347'},\n 1351: {'her1351', 'hin1351'},\n 1459: {',1459',\n  'das1459',\n  'früher1459',\n  'gewesen1459',\n  'heute1459',\n  'ist1459',\n  'sind1459',\n  'war1459',\n  'waren1459',\n  'was1459'},\n 1461: {'Das1461',\n  'Leben1461',\n  'das1461',\n  'ist1461',\n  'kein1461',\n  'keine1461',\n  'war1461'},\n 1462: {'Ponyhof1462', 'ist1462', 'kein1462', 'war1462'},\n 1503: {'BRUTAL1503', 'Brutal1503', 'brutal1503'},\n 1509: {'Arzt1509',\n  'bis1509',\n  'der1509',\n  'kommen1509',\n  'kommt1509',\n  'musste1509'},\n 1511: {'her1511', 'hin1511'},\n 1525: {'Kein1525',\n  'Keine1525',\n  'für1525',\n  'kein1525',\n  'keine1525',\n  'niemand1525'},\n 1554: {'Gold1554',\n  'Reden1554',\n  'Silber1554',\n  'gold1554',\n  'ist1554',\n  'silber1554',\n  'sind1554'},\n 1556: {'schlechthin1556', 'schlechthin»1556'},\n 1573: {'mich1573', 'sich1573'},\n 1574: {'ab1574',\n  'auf1574',\n  'durch1574',\n  'einander1574',\n  'euch1574',\n  'herunter1574',\n  'hinaus1574',\n  'hindurch1574',\n  'hinunter1574',\n  'mich1574',\n  'sich1574',\n  'uns1574'},\n 1582: {'mir1582', 'sich1582', 'uns1582'},\n 1593: {'kann1593'},\n 1597: {'(1597', ')1597'},\n 1600: {'(1600', ')1600'},\n 1602: {'(1602', ')1602'},\n 1624: {'(1624', ')1624'},\n 1629: {'Von1629', 'von1629', 'wegen1629'},\n 1630: {'Aller1630', 'Trotz1630', 'allen1630', 'aller1630'},\n 1631: {'Jetzt1631', 'es1631', 'heisst1631', 'jetzt1631'},\n 1637: {'(1637', ')1637'},\n 1639: {'(1639', ')1639'},\n 1641: {'(1641', ')1641'},\n 1643: {'(1643', ')1643', '[1643', ']1643'},\n 1645: {'(1645', ')1645'},\n 1649: {'Lecker1649', 'lecker1649'},\n 1660: {'Ist1660',\n  'bleibt1660',\n  'ist1660',\n  'seien1660',\n  'sind1660',\n  'war1660',\n  'wird1660',\n  'wäre1660'},\n 1671: {'Inbegriff1671'},\n 1681: {'Die1681', 'Mutter1681', 'aller1681', 'der1681', 'die1681'},\n 1690: {'kein1690', 'nicht1690', 'ohne1690'},\n 1715: {'Kein1715',\n  'Keine1715',\n  'auch1715',\n  'ein1715',\n  'eine1715',\n  'ist1715',\n  'kein1715',\n  'keine1715'},\n 1738: {'Wie1738', 'wie1738'},\n 1756: {'hätte1756', 'hätten1756', 'hättest1756', 'wäre1756'},\n 1760: {'So1760', 'so1760'},\n 1762: {'Besser1762', 'als1762', 'besser1762'},\n 1770: {'Als1770', 'als1770', 'noch1770', 'war1770', 'waren1770'},\n 1772: {'Von1772', 'von1772', 'wegen1772'},\n 1777: {'Ausmaß1777',\n  'Maß1777',\n  'Maße1777',\n  'Umfang1777',\n  'dem1777',\n  'gleichen1777',\n  'im1777',\n  'in1777',\n  'selben1777'},\n 1779: {'Entweder1779',\n  'entweder1779',\n  'nicht.“1779',\n  'nicht1779',\n  'oder1779'},\n 1792: {')1792',\n  'Keine(r1792',\n  'Keine1792',\n  'Keiner1792',\n  'Niemand1792',\n  'ist1792',\n  'keiner1792',\n  'niemand1792'},\n 1831: {'So1831', 'so1831'},\n 1835: {'Kein1835',\n  'Keine1835',\n  'auch1835',\n  'ein1835',\n  'eine1835',\n  'ist1835',\n  'keine1835'},\n 1846: {'Was1846', 'ist1846', 'mit1846', 'war1846', 'was1846'},\n 1849: {'und1849'},\n 1881: {'ist1881',\n  'kein1881',\n  'keine1881',\n  'sind1881',\n  'war1881',\n  'waren1881'},\n 1884: {'Gold1884', 'Silber1884', 'ist1884'},\n 1986: {'kaum1986'},\n 1987: {'sehr1987'}}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kelex = csv_data.copy()\n",
    "kelex['constr'] = csv_data['label'].str.extract('(\\d+)').astype(int)\n",
    "#kelex.set_index('constr', inplace=True)\n",
    "kelex = kelex.groupby('constr')['label'].apply(set).to_dict()\n",
    "kelex"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T23:30:16.309072583Z",
     "start_time": "2024-01-22T23:30:16.260778203Z"
    }
   },
   "id": "cd5df0ed9a88a378",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a40685d9d0646b29fa6758cf486ca5c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5555844678f74963bcd0ca15009d8369"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a874469ca3c747ae8da302d0167cfcb2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4382420bf1bf415e8855fcfbeeac5a4a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f57f32c05d1a419ba3b7c50b2ebbb8c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04053d4ec9e7422c91f4f909f71359c2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(15)\n",
    "attempts = 10\n",
    "for false_positives in range(2, 8):\n",
    "    result = []\n",
    "    for key, definition in tqdm(definitions.items()):\n",
    "        for attempt in range(attempts):\n",
    "            try:\n",
    "                sentence = random.choice(list(sentences[int(key)]))\n",
    "            except KeyError:\n",
    "                # print(None, None, None)\n",
    "                result.append(pd.Series({\"constr\": key, \"definition\": definition, \"example\": None, \"prediction\": None, \"correct\": None}))\n",
    "                continue\n",
    "            sentence_kelex = []\n",
    "            if kelex.get(key):\n",
    "                for token in sentence.split():\n",
    "                    new_token = token\n",
    "                    # assert kelex.get(key) is not None\n",
    "                    for pseudoword in kelex[key]:\n",
    "                        if token == re.findall(r'\\D+', pseudoword)[0]:\n",
    "                            new_token = pseudoword\n",
    "                            break\n",
    "                    sentence_kelex.append(new_token)\n",
    "                sentence_kelex = \" \".join(sentence_kelex)\n",
    "            else:\n",
    "                continue  # skip constructions without kelex\n",
    "                # sentence_kelex = sentence\n",
    "            others = itertools.chain.from_iterable([sentence_list for constr, sentence_list in sentences.items() if int(constr) != int(key)])\n",
    "            others = random.choices(list(others), k=false_positives)\n",
    "            examples = list(set(others) | {sentence_kelex})\n",
    "            prediction = find_examples(definition, examples)\n",
    "            # print(prediction == sentence_kelex, sentence, prediction)\n",
    "            result.append(pd.Series({\"constr\": key, \"definition\": definition, \"example\": sentence, \"example_kelex\": sentence_kelex, \"prediction\": prediction, \"correct\": prediction == sentence_kelex}))\n",
    "    result = pd.DataFrame(result)\n",
    "    result.to_csv(f\"../../out/comapp/result_1_vs_{false_positives}_kelex_{attempts}attempts_bsbbert.tsv\", sep=\"\\t\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T23:38:44.528203281Z",
     "start_time": "2024-01-22T23:30:16.307110042Z"
    }
   },
   "id": "cfdb3dc48dea6759",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33a9472441434af3a279f3eb19a017ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d745200994a0496b94be94dbefd4fa8a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "429ffd24ed9e4194831aa31a9cb96c9f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae0511640faa47518bcb7a439fa5bab2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3edc201266e64692b7dfb2954af78229"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/211 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4c41c56ecbf4905b3802c9ba9ed15fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(15)\n",
    "attempts = 10\n",
    "for false_positives in range(2, 8):\n",
    "    result = []\n",
    "    for key, definition in tqdm(definitions.items()):\n",
    "        for attempt in range(attempts):\n",
    "            try:\n",
    "                sentence = random.choice(list(sentences[int(key)]))\n",
    "            except KeyError:\n",
    "                # print(None, None, None)\n",
    "                result.append(pd.Series({\"constr\": key, \"definition\": definition, \"example\": None, \"prediction\": None, \"correct\": None}))\n",
    "                continue\n",
    "            sentence_kelex = []\n",
    "            if kelex.get(key):\n",
    "                for token in sentence.split():\n",
    "                    new_token = token\n",
    "                    # assert kelex.get(key) is not None\n",
    "                    for pseudoword in kelex[key]:\n",
    "                        if token == re.findall(r'\\D+', pseudoword)[0]:\n",
    "                            new_token = pseudoword\n",
    "                            break\n",
    "                    sentence_kelex.append(new_token)\n",
    "                sentence_kelex = \" \".join(sentence_kelex)\n",
    "            else:\n",
    "                # continue  # skip constructions without kelex\n",
    "                sentence_kelex = sentence\n",
    "            others = itertools.chain.from_iterable([sentence_list for constr, sentence_list in sentences.items() if int(constr) != int(key)])\n",
    "            others = random.choices(list(others), k=false_positives)\n",
    "            examples = list(set(others) | {sentence_kelex})\n",
    "            prediction = find_examples(definition, examples)\n",
    "            # print(prediction == sentence_kelex, sentence, prediction)\n",
    "            result.append(pd.Series({\"constr\": key, \"definition\": definition, \"example\": sentence, \"example_kelex\": sentence_kelex, \"prediction\": prediction, \"correct\": prediction == sentence_kelex}))\n",
    "    result = pd.DataFrame(result)\n",
    "    result.to_csv(f\"../../out/comapp/result_1_vs_{false_positives}_kelex_all_{attempts}attempts_bsbbert.tsv\", sep=\"\\t\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-22T23:38:44.536992875Z"
    }
   },
   "id": "b6a6959b0d4948b3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e1ae91af86700012"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
