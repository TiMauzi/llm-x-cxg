{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This notebook explores adding pseudoword embeddings as new embeddings to a BERT model:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "839603333987fa39"
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "import torch\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:21:07.798919Z",
     "start_time": "2023-10-17T18:21:07.759734400Z"
    }
   },
   "id": "1885ffc884adae38"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the pseudoword embeddings:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a5f4b6ca3447959"
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.6139378 , -0.09849278,  0.38503495, ...,  0.5829185 ,\n        -0.03312979, -0.32081214],\n       [ 0.7645389 , -0.9078201 , -0.83330715, ...,  0.29633465,\n         0.2754484 ,  0.01427615],\n       [-0.04470551, -0.13107753, -0.6122573 , ...,  0.9067127 ,\n         0.5997687 , -0.05785817],\n       ...,\n       [-0.41056955, -0.25118613, -0.1638469 , ..., -0.26522723,\n         1.182461  ,  0.3514442 ],\n       [ 0.188755  , -0.4069652 ,  0.12774336, ..., -0.12126191,\n        -0.5085608 ,  0.632808  ],\n       [-0.34621328,  0.5956651 , -0.95337975, ...,  0.05335583,\n        -1.1837399 ,  0.24092862]], dtype=float32)"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudowords = np.load(\"../out/pseudowords-avg.npy\")\n",
    "pseudowords"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:21:07.799921300Z",
     "start_time": "2023-10-17T18:21:07.762754800Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the new token names:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3be05fa9ba7ff46a"
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "data": {
      "text/plain": "['in1',\n 'in2',\n 'for1',\n 'for2',\n 'for3',\n 'started1',\n 'started2',\n 'had1',\n 'had4',\n 'had5',\n 'about1',\n 'about2',\n 'with1',\n 'with2',\n 'with3',\n 'on1',\n 'on2',\n 'run1',\n 'run2']"
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "with open(\"./pseudowords/MaPP_all.txt\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "new_tokens = [d[\"query\"].split()[d[\"query_idx\"]] for d in data]\n",
    "token_counts = {}\n",
    "bert_tokens = []\n",
    "\n",
    "with open(\"./pseudowords/MaPP_Dataset.csv\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    labels = {row[0]: row[2] + row[5] for row in csv_reader}\n",
    "\n",
    "bert_tokens = []\n",
    "\n",
    "for d in data:\n",
    "    try:\n",
    "        label = labels[d[\"target1\"]]\n",
    "    except KeyError:\n",
    "        label = labels[d[\"target1\"].strip()]\n",
    "    if label not in bert_tokens:\n",
    "        bert_tokens.append(label)\n",
    "bert_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:21:07.810945400Z",
     "start_time": "2023-10-17T18:21:07.769609700Z"
    }
   },
   "id": "fa2bfb45eab801eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the vanilla BERT model:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a823993f6cd12d1"
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "Embedding(28996, 768, padding_idx=0)"
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained('bert-base-cased', return_dict=True)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model.bert.embeddings.word_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:21:09.543441700Z",
     "start_time": "2023-10-17T18:21:07.776511600Z"
    }
   },
   "id": "36b0ec25d2a7b96d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add to existing embeddings:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c998c44f7fe5a64c"
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "data": {
      "text/plain": "Embedding(29015, 768)"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_embeddings = torch.cat((model.bert.embeddings.word_embeddings.weight, torch.tensor(pseudowords)), dim=0)\n",
    "model.bert.embeddings.word_embeddings = torch.nn.Embedding.from_pretrained(combined_embeddings)\n",
    "model.bert.embeddings.word_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:21:09.552518800Z",
     "start_time": "2023-10-17T18:21:09.524534100Z"
    }
   },
   "id": "f75d926b56c56aa5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add to existing tokens:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7660671b4583a798"
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 29015. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": "Embedding(29015, 768)"
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(bert_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:21:09.589360500Z",
     "start_time": "2023-10-17T18:21:09.546952500Z"
    }
   },
   "id": "3e2a95a395a524aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Try it with an example:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6d3af6077a3d297"
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "data": {
      "text/plain": "['[CLS]',\n 'The',\n 'lecture',\n 'will',\n 'be',\n 'just',\n 'about1',\n 'a',\n '[MASK]',\n '.',\n '[SEP]']"
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text = tokenizer.tokenize(\"[CLS] The lecture will be just about1 a [MASK]. [SEP]\")\n",
    "masked_index = tokenized_text.index(\"[MASK]\")\n",
    "tokenized_text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:23:09.300982100Z",
     "start_time": "2023-10-17T18:23:09.248992800Z"
    }
   },
   "id": "c22ec3fb15b6e0bb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert the tokens to indices:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b06b6272dae022f5"
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[  101,  1109, 10309,  1209,  1129,  1198, 29006,   170,   103,   119,\n           102]])"
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "input_ids = torch.tensor([input_ids])\n",
    "input_ids"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:23:09.332434600Z",
     "start_time": "2023-10-17T18:23:09.255135600Z"
    }
   },
   "id": "640da514d8412154"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predict the token:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db0a38b7d71e3727"
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [
    {
     "data": {
      "text/plain": "'run2'"
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    predictions = outputs.logits\n",
    "\n",
    "predicted_token_id = torch.argmax(predictions[0, masked_index]).item()\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_token_id])[0]\n",
    "\n",
    "predicted_token"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:23:09.403255Z",
     "start_time": "2023-10-17T18:23:09.260948Z"
    }
   },
   "id": "e04734b9262be065"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predict the top 100 tokens:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a71ff18c4d51f4c1"
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run2 tensor(50.2523)\n",
      "started2 tensor(46.4366)\n",
      "had4 tensor(40.3415)\n",
      "run1 tensor(34.4864)\n",
      "had1 tensor(33.7096)\n",
      "about2 tensor(33.7002)\n",
      "had5 tensor(25.1552)\n",
      "for2 tensor(12.1103)\n",
      "minute tensor(10.4596)\n",
      "lecture tensor(9.8213)\n",
      "moment tensor(9.7789)\n",
      "day tensor(9.5306)\n",
      "bit tensor(9.5272)\n",
      "little tensor(9.4727)\n",
      "show tensor(9.3757)\n",
      "preview tensor(8.8964)\n",
      "game tensor(8.8520)\n",
      "start tensor(8.8175)\n",
      "second tensor(8.8044)\n",
      "demonstration tensor(8.7517)\n",
      "touch tensor(8.6196)\n",
      "surprise tensor(8.4973)\n",
      "performance tensor(8.4794)\n",
      "week tensor(8.4368)\n",
      "conference tensor(8.3706)\n",
      "presentation tensor(8.2188)\n",
      "meeting tensor(8.2018)\n",
      "joke tensor(8.1999)\n",
      "thing tensor(8.1657)\n",
      "concert tensor(8.1434)\n",
      "test tensor(8.1418)\n",
      "distraction tensor(8.0433)\n",
      "rehearsal tensor(7.9748)\n",
      "dream tensor(7.9736)\n",
      "visit tensor(7.9571)\n",
      "date tensor(7.7271)\n",
      "while tensor(7.6887)\n",
      "scratch tensor(7.6475)\n",
      "few tensor(7.6338)\n",
      "walk tensor(7.6190)\n",
      "break tensor(7.5936)\n",
      "thought tensor(7.5277)\n",
      "movie tensor(7.5129)\n",
      "coincidence tensor(7.4856)\n",
      "story tensor(7.4786)\n",
      "shock tensor(7.4044)\n",
      "glance tensor(7.3418)\n",
      "match tensor(7.3398)\n",
      "speech tensor(7.3146)\n",
      "beginning tensor(7.2592)\n",
      "diversion tensor(7.2497)\n",
      "weekend tensor(7.1669)\n",
      "nightmare tensor(7.1573)\n",
      "blur tensor(7.1369)\n",
      "first tensor(7.1053)\n",
      "night tensor(7.0505)\n",
      "statement tensor(7.0462)\n",
      "lesson tensor(7.0161)\n",
      "reminder tensor(6.9833)\n",
      "kiss tensor(6.9631)\n",
      "text tensor(6.9194)\n",
      "session tensor(6.9148)\n",
      "function tensor(6.8444)\n",
      "peek tensor(6.8133)\n",
      "seminar tensor(6.7940)\n",
      "gig tensor(6.7887)\n",
      "suggestion tensor(6.7692)\n",
      "talk tensor(6.7347)\n",
      "month tensor(6.7244)\n",
      "job tensor(6.7196)\n",
      "memory tensor(6.6935)\n",
      "whisper tensor(6.6749)\n",
      "reading tensor(6.6653)\n",
      "warning tensor(6.6262)\n",
      "call tensor(6.6156)\n",
      "look tensor(6.6013)\n",
      "hobby tensor(6.5831)\n",
      "chat tensor(6.5769)\n",
      "crawl tensor(6.5644)\n",
      "guess tensor(6.5607)\n",
      "fantasy tensor(6.5166)\n",
      "project tensor(6.4673)\n",
      "celebration tensor(6.4479)\n",
      "rumor tensor(6.4459)\n",
      "trick tensor(6.4151)\n",
      "sermon tensor(6.4068)\n",
      "shot tensor(6.4059)\n",
      "record tensor(6.3992)\n",
      "handful tensor(6.3987)\n",
      "dance tensor(6.3865)\n",
      "change tensor(6.3675)\n",
      "vacation tensor(6.3433)\n",
      "play tensor(6.3319)\n",
      "class tensor(6.3276)\n",
      "question tensor(6.3067)\n",
      "buzz tensor(6.3058)\n",
      "premiere tensor(6.3052)\n",
      "discussion tensor(6.2937)\n",
      "stroke tensor(6.2760)\n",
      "meal tensor(6.2624)\n"
     ]
    }
   ],
   "source": [
    "top_k = 100\n",
    "predicted_token_ids = torch.topk(predictions[0, masked_index], top_k).indices\n",
    "predicted_token_probs = torch.topk(predictions[0, masked_index], top_k).values\n",
    "\n",
    "# Convert the predicted token IDs back to tokens\n",
    "predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_token_ids)\n",
    "\n",
    "# Print the top 5 predictions and their probabilities\n",
    "for token, prob in zip(predicted_tokens, predicted_token_probs):\n",
    "    print(token, prob)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:23:09.404262900Z",
     "start_time": "2023-10-17T18:23:09.336874900Z"
    }
   },
   "id": "412b1529163d9372"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predict the most probable word that is not part of the new embeddings:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6f8c075142cc733"
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minute\n"
     ]
    }
   ],
   "source": [
    "predicted_token_ids = torch.argmax(predictions[0, masked_index])\n",
    "vocab_size = len(tokenizer)\n",
    "# Find the highest predicted token with an ID lower than 28997\n",
    "for i in range(vocab_size):\n",
    "    if predicted_token_ids < 28996:  # if no [PAD]: <= 28996\n",
    "        break\n",
    "    predicted_token_ids = torch.argsort(predictions[0, masked_index], descending=True)[i]\n",
    "\n",
    "# Convert the predicted token ID back to a token\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_token_ids])[0]\n",
    "\n",
    "print(predicted_token)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:23:09.404262900Z",
     "start_time": "2023-10-17T18:23:09.358214500Z"
    }
   },
   "id": "aa8ec7e84884477f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predict the top 5 words that are not part of the new embeddings:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23bd77356979b3e"
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minute 10.4595947265625\n",
      "lecture 9.821345329284668\n",
      "moment 9.778871536254883\n",
      "day 9.530567169189453\n",
      "bit 9.527246475219727\n"
     ]
    }
   ],
   "source": [
    "# Get the predicted token IDs and their probabilities\n",
    "predicted_token_probs = predictions[0, masked_index]\n",
    "vocab_size = len(tokenizer)\n",
    "# Create a list to store the top 5 predictions and their probabilities\n",
    "top_5_predictions = []\n",
    "\n",
    "# Find the top 5 predicted tokens with IDs lower than 28997\n",
    "for i in range(vocab_size):\n",
    "    if len(top_5_predictions) >= 5 or i >= vocab_size:\n",
    "        break\n",
    "    token_id = torch.argsort(predicted_token_probs, descending=True)[i].item()\n",
    "    if token_id < 28996:  # if no [PAD]: <= 28996\n",
    "        predicted_token = tokenizer.convert_ids_to_tokens([token_id])[0]\n",
    "        top_5_predictions.append((predicted_token, predicted_token_probs[token_id].item()))\n",
    "\n",
    "# Print the top 5 predictions and their probabilities\n",
    "for token, prob in top_5_predictions:\n",
    "    print(token, prob)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:23:09.485489600Z",
     "start_time": "2023-10-17T18:23:09.404262900Z"
    }
   },
   "id": "e18dc0c71658a1b4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
