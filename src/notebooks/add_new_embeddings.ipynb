{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This notebook explores adding pseudoword embeddings as new embeddings to a BERT model:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "839603333987fa39"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "import torch\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T12:09:25.633085Z",
     "start_time": "2023-12-30T12:09:25.594390200Z"
    }
   },
   "id": "1885ffc884adae38"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the pseudoword embeddings:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a5f4b6ca3447959"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.6139378 , -0.09849278,  0.38503495, ...,  0.5829185 ,\n        -0.03312979, -0.32081214],\n       [ 0.7645389 , -0.9078201 , -0.83330715, ...,  0.29633465,\n         0.2754484 ,  0.01427615],\n       [-0.04470551, -0.13107753, -0.6122573 , ...,  0.9067127 ,\n         0.5997687 , -0.05785817],\n       ...,\n       [-0.41056955, -0.25118613, -0.1638469 , ..., -0.26522723,\n         1.182461  ,  0.3514442 ],\n       [ 0.188755  , -0.4069652 ,  0.12774336, ..., -0.12126191,\n        -0.5085608 ,  0.632808  ],\n       [-0.34621328,  0.5956651 , -0.95337975, ...,  0.05335583,\n        -1.1837399 ,  0.24092862]], dtype=float32)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudowords = np.load(\"../../out/pseudowords-avg.npy\")\n",
    "pseudowords"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T12:09:25.659157300Z",
     "start_time": "2023-12-30T12:09:25.636457400Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the new token names:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3be05fa9ba7ff46a"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "['in1',\n 'in2',\n 'for1',\n 'for2',\n 'for3',\n 'started1',\n 'started2',\n 'had1',\n 'had4',\n 'had5',\n 'about1',\n 'about2',\n 'with1',\n 'with2',\n 'with3',\n 'on1',\n 'on2',\n 'run1',\n 'run2']"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "with open(\"../../data/pseudowords/MaPP_all.txt\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "new_tokens = [d[\"query\"].split()[d[\"query_idx\"]] for d in data]\n",
    "token_counts = {}\n",
    "bert_tokens = []\n",
    "\n",
    "with open(\"../../data/pseudowords/MaPP_Dataset.csv\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    labels = {row[0]: row[2] + row[5] for row in csv_reader}\n",
    "\n",
    "bert_tokens = []\n",
    "\n",
    "for d in data:\n",
    "    try:\n",
    "        label = labels[d[\"target1\"]]\n",
    "    except KeyError:\n",
    "        label = labels[d[\"target1\"].strip()]\n",
    "    if label not in bert_tokens:\n",
    "        bert_tokens.append(label)\n",
    "bert_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T12:09:25.660263800Z",
     "start_time": "2023-12-30T12:09:25.644587400Z"
    }
   },
   "id": "fa2bfb45eab801eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the vanilla BERT model:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a823993f6cd12d1"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "Embedding(28996, 768, padding_idx=0)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained('bert-base-cased', return_dict=True)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model.bert.embeddings.word_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T12:09:27.850818200Z",
     "start_time": "2023-12-30T12:09:25.652300800Z"
    }
   },
   "id": "36b0ec25d2a7b96d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add to existing embeddings:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c998c44f7fe5a64c"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "Embedding(29015, 768)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_embeddings = torch.cat((model.bert.embeddings.word_embeddings.weight, torch.tensor(pseudowords)), dim=0)\n",
    "model.bert.embeddings.word_embeddings = torch.nn.Embedding.from_pretrained(combined_embeddings)\n",
    "model.bert.embeddings.word_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T12:09:27.860553700Z",
     "start_time": "2023-12-30T12:09:27.848263Z"
    }
   },
   "id": "f75d926b56c56aa5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add to existing tokens:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7660671b4583a798"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 29015. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": "Embedding(29015, 768)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(bert_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T12:09:27.869944500Z",
     "start_time": "2023-12-30T12:09:27.859395400Z"
    }
   },
   "id": "3e2a95a395a524aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Try it with an example:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6d3af6077a3d297"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "['The', '[MASK]', '[PAD]']"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text = tokenizer.tokenize(\"The [MASK]\")\n",
    "masked_index = tokenized_text.index(\"[MASK]\")\n",
    "tokenized_text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T12:10:25.764261900Z",
     "start_time": "2023-12-30T12:10:25.762098100Z"
    }
   },
   "id": "c22ec3fb15b6e0bb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert the tokens to indices:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b06b6272dae022f5"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1109,  103,    0]])"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "input_ids = torch.tensor([input_ids])\n",
    "input_ids"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T12:10:27.546508400Z",
     "start_time": "2023-12-30T12:10:27.541843800Z"
    }
   },
   "id": "640da514d8412154"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predict the token:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db0a38b7d71e3727"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "data": {
      "text/plain": "'for2'"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    predictions = outputs.logits\n",
    "\n",
    "predicted_token_id = torch.argmax(predictions[0, masked_index]).item()\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_token_id])[0]\n",
    "\n",
    "predicted_token"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T12:10:29.726118900Z",
     "start_time": "2023-12-30T12:10:29.673589400Z"
    }
   },
   "id": "e04734b9262be065"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predict the top 100 tokens:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a71ff18c4d51f4c1"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for2 tensor(60.4169)\n",
      "in1 tensor(42.1652)\n",
      "for3 tensor(27.5228)\n",
      "with2 tensor(26.8077)\n",
      "about2 tensor(26.3791)\n",
      "on1 tensor(24.1114)\n",
      ". tensor(20.7530)\n",
      ", tensor(13.6920)\n",
      "had1 tensor(11.8560)\n",
      "in2 tensor(10.7599)\n",
      "; tensor(10.3517)\n",
      "had4 tensor(10.2989)\n",
      "? tensor(9.3468)\n",
      "... tensor(8.9554)\n",
      ") tensor(8.0753)\n",
      "of tensor(7.8683)\n",
      "one tensor(7.8091)\n",
      ": tensor(7.7398)\n",
      "with1 tensor(7.7063)\n",
      "\" tensor(7.5942)\n",
      "with3 tensor(7.1962)\n",
      "and tensor(7.1646)\n",
      "have tensor(7.1489)\n",
      "for tensor(6.8958)\n",
      "- tensor(6.8416)\n",
      "( tensor(6.6311)\n",
      "to tensor(6.6089)\n",
      "however tensor(6.4687)\n",
      "or tensor(6.4409)\n",
      "has tensor(6.2858)\n",
      "he tensor(6.1440)\n",
      "10 tensor(6.0997)\n",
      "was tensor(6.0678)\n",
      "had tensor(6.0156)\n",
      "direction tensor(6.0082)\n",
      "she tensor(5.8671)\n",
      "with tensor(5.8534)\n",
      "once tensor(5.7480)\n",
      "! tensor(5.6943)\n",
      "center tensor(5.6774)\n",
      "which tensor(5.6481)\n",
      "but tensor(5.6247)\n",
      "hundred tensor(5.6120)\n",
      "being tensor(5.5830)\n",
      "instead tensor(5.5702)\n",
      "calling tensor(5.5174)\n",
      "50 tensor(5.4752)\n",
      "called tensor(5.4552)\n",
      "small tensor(5.4548)\n",
      "is tensor(5.4308)\n",
      "having tensor(5.3784)\n",
      "order tensor(5.3433)\n",
      "more tensor(5.2630)\n",
      "M tensor(5.2523)\n",
      "40 tensor(5.0536)\n",
      "1 tensor(4.9694)\n",
      "two tensor(4.9466)\n",
      "centre tensor(4.8576)\n",
      "on tensor(4.8356)\n",
      "place tensor(4.8162)\n",
      "that tensor(4.8066)\n",
      "left tensor(4.7993)\n",
      "than tensor(4.7940)\n",
      "call tensor(4.7741)\n",
      "9 tensor(4.7561)\n",
      "38 tensor(4.7530)\n",
      "only tensor(4.7056)\n",
      "company tensor(4.6789)\n",
      "Marshall tensor(4.6688)\n",
      "after tensor(4.6636)\n",
      "in tensor(4.6548)\n",
      "show tensor(4.6216)\n",
      "12 tensor(4.6158)\n",
      "large tensor(4.5841)\n",
      "thousand tensor(4.5778)\n",
      "it tensor(4.5772)\n",
      "each tensor(4.5484)\n",
      "100 tensor(4.4579)\n",
      "finally tensor(4.4545)\n",
      "reason tensor(4.4535)\n",
      "ones tensor(4.4359)\n",
      "= tensor(4.4331)\n",
      "force tensor(4.4303)\n",
      "work tensor(4.4269)\n",
      "later tensor(4.4036)\n",
      "where tensor(4.4017)\n",
      "again tensor(4.4015)\n",
      "beginning tensor(4.3604)\n",
      "York tensor(4.3561)\n",
      "site tensor(4.3266)\n",
      "about1 tensor(4.3161)\n",
      "also tensor(4.3075)\n",
      "rate tensor(4.2907)\n",
      "square tensor(4.2768)\n",
      "David tensor(4.2687)\n",
      "for1 tensor(4.2370)\n",
      "##4 tensor(4.2335)\n",
      "around tensor(4.2329)\n",
      "000 tensor(4.2254)\n",
      "last tensor(4.2198)\n"
     ]
    }
   ],
   "source": [
    "top_k = 100\n",
    "predicted_token_ids = torch.topk(predictions[0, masked_index], top_k).indices\n",
    "predicted_token_probs = torch.topk(predictions[0, masked_index], top_k).values\n",
    "\n",
    "# Convert the predicted token IDs back to tokens\n",
    "predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_token_ids)\n",
    "\n",
    "# Print the top 5 predictions and their probabilities\n",
    "for token, prob in zip(predicted_tokens, predicted_token_probs):\n",
    "    print(token, prob)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T12:10:31.437521Z",
     "start_time": "2023-12-30T12:10:31.413634400Z"
    }
   },
   "id": "412b1529163d9372"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predict the most probable word that is not part of the new embeddings:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6f8c075142cc733"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "predicted_token_ids = torch.argmax(predictions[0, masked_index])\n",
    "vocab_size = len(tokenizer)\n",
    "# Find the highest predicted token with an ID lower than 28997\n",
    "for i in range(vocab_size):\n",
    "    if predicted_token_ids < 28996:  # if no [PAD]: <= 28996\n",
    "        break\n",
    "    predicted_token_ids = torch.argsort(predictions[0, masked_index], descending=True)[i]\n",
    "\n",
    "# Convert the predicted token ID back to a token\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_token_ids])[0]\n",
    "\n",
    "print(predicted_token)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T12:10:33.484480800Z",
     "start_time": "2023-12-30T12:10:33.452933700Z"
    }
   },
   "id": "aa8ec7e84884477f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predict the top 5 words that are not part of the new embeddings:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23bd77356979b3e"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". 21.43332862854004\n",
      ", 13.855920791625977\n",
      "; 10.54966926574707\n",
      "? 9.460063934326172\n",
      "... 9.084609031677246\n"
     ]
    }
   ],
   "source": [
    "# Get the predicted token IDs and their probabilities\n",
    "predicted_token_probs = predictions[0, masked_index]\n",
    "vocab_size = len(tokenizer)\n",
    "# Create a list to store the top 5 predictions and their probabilities\n",
    "top_5_predictions = []\n",
    "\n",
    "# Find the top 5 predicted tokens with IDs lower than 28997\n",
    "for i in range(vocab_size):\n",
    "    if len(top_5_predictions) >= 5 or i >= vocab_size:\n",
    "        break\n",
    "    token_id = torch.argsort(predicted_token_probs, descending=True)[i].item()\n",
    "    if token_id < 28996:  # if no [PAD]: <= 28996\n",
    "        predicted_token = tokenizer.convert_ids_to_tokens([token_id])[0]\n",
    "        top_5_predictions.append((predicted_token, predicted_token_probs[token_id].item()))\n",
    "\n",
    "# Print the top 5 predictions and their probabilities\n",
    "for token, prob in top_5_predictions:\n",
    "    print(token, prob)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T12:10:15.508999300Z",
     "start_time": "2023-12-30T12:10:15.455672800Z"
    }
   },
   "id": "e18dc0c71658a1b4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "985532b6f321c2ed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
