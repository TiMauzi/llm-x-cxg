{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import os\n",
    "from io import open\n",
    "\n",
    "import spacy\n",
    "from conllu import parse_incr, TokenList\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Zuerst werden die UD-HDT-Daten geladen, sodass diese später gefiltert werden können:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfc4cec27eff6850"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ud_hdt_sentences = {}\n",
    "all_ud_hdt_sentences = []\n",
    "filepath = \"../../libs/UD_German-HDT\"\n",
    "for filename in tqdm(list(os.listdir(\"../../libs/UD_German-HDT\"))):\n",
    "    cur_sentences = []\n",
    "    if filename.endswith('.conllu'):\n",
    "        data_file = open(os.path.join(filepath, filename), \"r\", encoding=\"utf-8\")\n",
    "        for token_list in parse_incr(data_file):\n",
    "            cur_sentences.append(token_list)\n",
    "        ud_hdt_sentences[filename] = cur_sentences\n",
    "        all_ud_hdt_sentences += cur_sentences\n",
    "        \n",
    "ud_hdt_sentences"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91e0abe2e05fb3d0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nun werden die Beispieldaten benötigt. Hierzu werden die Beispielsätze aus dem Konstruktikon verwendet, die nach Konstruktionen sortiert werden."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3991e0edfa6b341b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"../../data/pseudowords/CoMaPP_Dataset.csv\", \"r\") as csv_file:\n",
    "    data = [row for row in csv.DictReader(csv_file)]\n",
    "\n",
    "# Group the dataset into a list of lists where the label of the dictionaries is identical:\n",
    "data.sort(key=lambda x: x[\"label\"])  # Grouping doesn't work without sorting first!\n",
    "data = [list(group) for _, group in itertools.groupby(data, key=lambda x: x[\"label\"])]\n",
    "\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf22b9baa6667871"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "example_sentences = {}\n",
    "kees = {}\n",
    "for group in tqdm(data):\n",
    "    example_sentences[group[0][\"label\"]] = set()\n",
    "    kees[group[0][\"label\"]] = set()\n",
    "    for example in group:\n",
    "        if len(eval(example[\"pos_tags\"])) > 0:\n",
    "            # Wenn POS-Tags annotiert sind\n",
    "            example_sentences[group[0][\"label\"]].add((example[\"text\"], tuple(eval(example[\"pos_tags\"]))))\n",
    "        else:\n",
    "            # Sonst nimm Spacy-POS-Tags\n",
    "            example_sentences[group[0][\"label\"]].add((example[\"text\"], tuple(token.pos_ for token in nlp(example[\"text\"]))))\n",
    "        kees[group[0][\"label\"]].add(example[\"ambiguous_word\"].lower())\n",
    "    \n",
    "example_sentences"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1e07531cb8c185d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nun können wir alle Korpussätze aus UD-HDT herausfiltern, die POS-Tag-Sequenzen enthalten, die in den Konstruktionen im Konstruktikon definiert sind."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83163a31340a129f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "matches = {}\n",
    "for constr, group in tqdm(example_sentences.items()):\n",
    "    matches[constr] = []\n",
    "    for _, ex_pos in group:\n",
    "        for corpus_sentence in ud_hdt_sentences[\"de_hdt-ud-test.conllu\"]:  # in all_ud_hdt_sentences\n",
    "            # Vergleiche ex_pos VS. tuple(token[\"upos\"] for token in corpus_sentence)\n",
    "            joined_ex_pos = ' '.join(ex_pos)\n",
    "            joined_corpus_pos = ' '.join([token[\"upos\"] for token in corpus_sentence])\n",
    "            if (joined_ex_pos in joined_corpus_pos and \n",
    "                    any([kee in [token[\"form\"].lower() for token in corpus_sentence] for kee in kees[constr]])):\n",
    "                matches[constr].append(corpus_sentence)\n",
    "                # print(\".\", end=\"\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a0967c7b3ddd63e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "matches"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1b939cc22001f36"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"../../out/matches_upos.txt\", \"w\") as file:\n",
    "    for key, match in matches.items(): \n",
    "        file.write(key + \":\\n\")\n",
    "        for m in match:\n",
    "            file.write(\"\\t\" + m.metadata[\"text\"] + \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac7d3fcb2995f121"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Äquivalenter Test mit XPOS:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d06fe4ad9ba6adae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "example_sentences = {}\n",
    "kees = {}\n",
    "for group in tqdm(data):\n",
    "    example_sentences[group[0][\"label\"]] = set()\n",
    "    kees[group[0][\"label\"]] = set()\n",
    "    for example in group:\n",
    "        if len(eval(example[\"xpos_tags\"])) > 0:\n",
    "            # Wenn POS-Tags annotiert sind\n",
    "            example_sentences[group[0][\"label\"]].add((example[\"text\"], tuple(eval(example[\"xpos_tags\"]))))\n",
    "        else:\n",
    "            # Sonst nimm Spacy-POS-Tags\n",
    "            example_sentences[group[0][\"label\"]].add((example[\"text\"], tuple(token.tag_ for token in nlp(example[\"text\"]))))\n",
    "        kees[group[0][\"label\"]].add(example[\"ambiguous_word\"].lower())\n",
    "    \n",
    "example_sentences"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54562ffda65ec869"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "matches = {}\n",
    "for constr, group in tqdm(example_sentences.items()):\n",
    "    matches[constr] = []\n",
    "    for _, ex_tag in group:\n",
    "        for corpus_sentence in ud_hdt_sentences[\"de_hdt-ud-test.conllu\"]:  # in all_ud_hdt_sentences\n",
    "            # Vergleiche ex_tag VS. tuple(token[\"xpos\"] for token in corpus_sentence)\n",
    "            joined_ex_tag = ' '.join(ex_tag)\n",
    "            joined_corpus_tag = ' '.join([str(token[\"xpos\"]) for token in corpus_sentence])\n",
    "            if (joined_ex_tag in joined_corpus_tag and\n",
    "                    any([kee in [token[\"form\"].lower() for token in corpus_sentence] for kee in kees[constr]])):\n",
    "                matches[constr].append(corpus_sentence)\n",
    "                # print(\".\", end=\"\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f7c70f548880ea2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "matches"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a4ccdc7a7356588"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"../../out/matches_xpos.txt\", \"w\") as file:\n",
    "    for key, match in matches.items(): \n",
    "        file.write(key + \":\\n\")\n",
    "        for m in match:\n",
    "            file.write(\"\\t\" + m.metadata[\"text\"] + \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "699732598de2ee6b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Äquivalenter Test mit DEPs:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f4145a311538b93"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "example_sentences = {}\n",
    "kees = {}\n",
    "for group in tqdm(data):\n",
    "    example_sentences[group[0][\"label\"]] = set()\n",
    "    kees[group[0][\"label\"]] = set()\n",
    "    for example in group:\n",
    "        if len(eval(example[\"dep_rels\"])) > 0:\n",
    "            # Wenn Dep-Rels annotiert sind\n",
    "            example_sentences[group[0][\"label\"]].add((example[\"text\"], tuple(ex.upper() for ex in eval(example[\"dep_rels\"]))))\n",
    "        else:\n",
    "            # Sonst nimm Spacy-Dep-Rels\n",
    "            example_sentences[group[0][\"label\"]].add((example[\"text\"], tuple(str(token.dep_).upper() for token in nlp(example[\"text\"]))))\n",
    "        kees[group[0][\"label\"]].add(example[\"ambiguous_word\"].lower())\n",
    "    \n",
    "example_sentences"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88e808c27493b381"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "matches = {}\n",
    "for constr, group in tqdm(example_sentences.items()):\n",
    "    matches[constr] = []\n",
    "    for _, ex_dep in group:\n",
    "        for corpus_sentence in ud_hdt_sentences[\"de_hdt-ud-test.conllu\"]:  # in all_ud_hdt_sentences\n",
    "            # Vergleiche ex_tag VS. tuple(token[\"xpos\"] for token in corpus_sentence)\n",
    "            joined_ex_dep = ' '.join(ex_dep)\n",
    "            joined_corpus_dep = ' '.join([str(token[\"deprel\"]).upper() for token in corpus_sentence])\n",
    "            if (joined_ex_dep in joined_corpus_dep and\n",
    "                    any([kee in [token[\"form\"].lower() for token in corpus_sentence] for kee in kees[constr]])):\n",
    "                matches[constr].append(corpus_sentence)\n",
    "                # print(\".\", end=\"\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b0d5fa47cfa3c23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "matches"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b01a98f8d25733db"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"../../out/matches_dep.txt\", \"w\") as file:\n",
    "    for key, match in matches.items(): \n",
    "        file.write(key + \":\\n\")\n",
    "        for m in match:\n",
    "            file.write(\"\\t\" + m.metadata[\"text\"] + \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d3016a95cda24d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "doc = nlp(\"Dies ist ein Beispielsatz.\")\n",
    "#displacy.render(doc, style=\"dep\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6716a125272c6b6b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pass"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d79e8545068026a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
