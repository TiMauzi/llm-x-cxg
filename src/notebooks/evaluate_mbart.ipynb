{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "863338ddbf31a6c5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"../../data/pseudowords/CoMaPP_all.json\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "# d+1 since we are not replacing the ke-lex this time!\n",
    "data = [{\"example\": d[\"target1\"], \"cue\": \" \".join(d[\"target1\"].split()[:d[\"query_idx\"]+1]), \"pseudoword\": d[\"label\"]} for d in data]\n",
    "df = pd.DataFrame.from_dict(data).drop_duplicates(ignore_index=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18bb06d46d72aab4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['index'] = df['pseudoword'].str.extract('(\\d+)').astype(int)\n",
    "df.set_index('index', inplace=True)\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7e1f6e88f687297"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "contextleft = pd.read_pickle(\"../../data/pseudowords/contextleft_text.pickle\")\n",
    "\n",
    "def update_cue(row):\n",
    "    output = row[['example', 'cue']]\n",
    "    if len(row['cue'].split()) == 1:  # if the string in cue is empty (except for the kelex)\n",
    "        # match the index of row with contextleft['construction_id'] and match contextleft['text'] with row['example'] and create matching_entry\n",
    "        matching_entry = contextleft.loc[(contextleft['construction_id'] == row.name) & (contextleft['text'] == row['example']), 'contextleft'].tolist()\n",
    "        if len(matching_entry) > 0:\n",
    "            # Add the left context to the example and to the cue:\n",
    "            output = [matching_entry[0] + \" \" + row['example'], matching_entry[0] + \" \" + row['cue']]\n",
    "    return output\n",
    "\n",
    "# Add the left context if there is no cue up until the pseudoword.\n",
    "df[[\"example\", \"cue\"]] = df.apply(update_cue, axis=1)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a898840ef3c9c442"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'construction'}, inplace=True)\n",
    "\n",
    "result_df = df.groupby(['construction', 'pseudoword']).agg({'example': list, 'cue': list})\n",
    "\n",
    "result_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a4e3d92707b4c4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"../../out/definitions.pickle\", \"rb\") as definitions_file:\n",
    "    definitions = pd.DataFrame.from_dict(pickle.load(definitions_file), orient=\"index\", columns=[\"definition\"])\n",
    "    \n",
    "definitions"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "examples = pd.merge(result_df, definitions, how=\"inner\", left_on=\"construction\", right_index=True)\n",
    "examples"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "238d2238bbdd91d8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Generieren neuer Sätze:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bc899cb800665fa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the vanilla mbart model:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1fd4b9029d49e1e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = MBartForConditionalGeneration.from_pretrained(\n",
    "    \"facebook/mbart-large-50\", return_dict=True\n",
    ") \n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\n",
    "    \"facebook/mbart-large-50\", src_lang=\"de_DE\", tgt_lang=\"de_DE\"\n",
    ")\n",
    "model.to(\"cuda:0\")\n",
    "model.model.encoder.embed_tokens"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e82730a36da5ce9c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Complete the cues:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b006ebc8aa40484"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def complete_cues(row):\n",
    "    try:\n",
    "        output_texts = []\n",
    "        scores = []\n",
    "        for cue, example in zip(row[\"cue\"], row[\"example\"]):\n",
    "            input_text = cue + \" <mask>\"\n",
    "            \n",
    "            # print(tokenizer.tokenize(input_text))\n",
    "            \n",
    "            target_length = int(1.5 * len(example))  # allow double the length of the original sentence\n",
    "            \n",
    "            outputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "            outputs = model.generate(outputs[\"input_ids\"].to(\"cuda:0\"), max_length=target_length, num_return_sequences=1, num_beams=10, output_scores=True, return_dict_in_generate=True)\n",
    "            output_text = tokenizer.batch_decode(outputs.sequences, skip_special_tokens=True)\n",
    "            score = torch.exp(outputs.sequences_scores)\n",
    "            output_texts += output_text\n",
    "            \n",
    "            scores.append(score)\n",
    "        #print(row[\"pseudoword\"], str(output_texts), str([float(score) for score in scores]))\n",
    "        print(\".\", end=\"\")\n",
    "        return pd.Series({\"construction\": row[\"construction\"], \"pseudoword\": row[\"pseudoword\"].iloc[0], \"orig_example\": row[\"example\"], \"generated\": str(output_texts), \"scores\": str([float(score) for score in scores])})\n",
    "    except Exception as e:\n",
    "        print(\":\", end=\"\")\n",
    "        return pd.Series({\"construction\": row[\"construction\"], \"pseudoword\": row[\"pseudoword\"].iloc[0], \"orig_example\": row[\"example\"], \"generated\": str(e), \"scores\": \"[-1.0]\"})\n",
    "\n",
    "examples_reset = examples.reset_index()\n",
    "pseudoword_output_scores = examples_reset[[\"construction\", \"pseudoword\", \"example\", \"cue\", \"pseudoword\"]].progress_apply(complete_cues, axis=1)\n",
    "pseudoword_output_scores"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7fc546c4aeb79b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "examples = pseudoword_output_scores[[\"pseudoword\", \"generated\", \"score\"]]\n",
    "\n",
    "examples"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14e01733b5a4aeba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Anzahl neuer Sätze"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a64a06083f0ccd35"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "examples.to_csv(f\"../../out/comapp/mbart/data_mbart_vanilla.tsv\", sep=\"\\t\", decimal=\",\")\n",
    "examples.to_excel(f\"../../out/comapp/mbart/data_mbart_vanilla.xlsx\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93ee2263ebe468ba"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pseudoword_output_scores.to_csv(\"../../out/comapp/mbart/data_mbart_vanilla_complete.tsv\", sep=\"\\t\", decimal=\",\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a890185b466ac02e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
