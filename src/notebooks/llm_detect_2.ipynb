{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLytI65hYIQD",
        "outputId": "b10347df-b139-4df2-e0a2-75cfa0e9b5b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 30 00:57:16 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P0    29W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkHXdgjjg82h",
        "outputId": "6f92eb94-dce5-45ba-f553-293a22df017a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.33.2 in /usr/local/lib/python3.10/dist-packages (4.33.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.2) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.2) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.33.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.33.2) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.33.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.33.2) (2023.7.22)\n",
            "Requirement already satisfied: optimum==1.13.2 in /usr/local/lib/python3.10/dist-packages (1.13.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from optimum==1.13.2) (15.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum==1.13.2) (1.12)\n",
            "Requirement already satisfied: transformers[sentencepiece]>=4.26.0 in /usr/local/lib/python3.10/dist-packages (from optimum==1.13.2) (4.33.2)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from optimum==1.13.2) (2.1.0+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from optimum==1.13.2) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optimum==1.13.2) (1.23.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from optimum==1.13.2) (0.19.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from optimum==1.13.2) (2.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum==1.13.2) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum==1.13.2) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum==1.13.2) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum==1.13.2) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum==1.13.2) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum==1.13.2) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum==1.13.2) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum==1.13.2) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum==1.13.2) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.26.0->optimum==1.13.2) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.26.0->optimum==1.13.2) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.26.0->optimum==1.13.2) (0.4.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.26.0->optimum==1.13.2) (0.1.99)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.26.0->optimum==1.13.2) (3.20.3)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->optimum==1.13.2) (10.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum==1.13.2) (9.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->optimum==1.13.2) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum==1.13.2) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->optimum==1.13.2) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->optimum==1.13.2) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->optimum==1.13.2) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->optimum==1.13.2) (3.8.6)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum==1.13.2) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum==1.13.2) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum==1.13.2) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum==1.13.2) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum==1.13.2) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum==1.13.2) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum==1.13.2) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum==1.13.2) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum==1.13.2) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum==1.13.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum==1.13.2) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->optimum==1.13.2) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum==1.13.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum==1.13.2) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->optimum==1.13.2) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://huggingface.github.io/autogptq-index/whl/cu118/\n",
            "Requirement already satisfied: auto-gptq in /usr/local/lib/python3.10/dist-packages (0.5.1+cu118)\n",
            "Requirement already satisfied: accelerate>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.24.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.15.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.1.99)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.23.5)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.0.1)\n",
            "Requirement already satisfied: gekko in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.0.6)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.1.0+cu118)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.4.0)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (4.33.2)\n",
            "Requirement already satisfied: peft>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->auto-gptq) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->auto-gptq) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->auto-gptq) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->auto-gptq) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (0.13.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (9.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.8.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge->auto-gptq) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install transformers==4.33.2\n",
        "!pip3 install optimum==1.13.2\n",
        "!pip3 install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s4gw-wd1g9sK"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "O00St_JBhAJs"
      },
      "outputs": [],
      "source": [
        "model_name_or_path = 'TheBloke/Llama-2-13B-German-Assistant-v4-GPTQ'  # \"TheBloke/Llama-2-13B-chat-GPTQ\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
        "                                             device_map='auto',\n",
        "                                             trust_remote_code=False,\n",
        "                                             revision=\"gptq-4bit-32g-actorder_True\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "H76qqrTyWJq6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "c092fdb4-d854-439b-995e-63d6ad1c5515"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Die \"Negation:NEG_XgeschweigedennY-Konstruktion\" korreliert zwei Propositionen, die jeweils einen Punkt auf einem pragmatisch definiertem Maßstab markieren. Die erste Proposition ist pragmatisch stärker als die zweite Proposition; so zieht, pragmatisch betrachtet, die Wahrheit der ersten Proposition automatisch die Wahrheit der zweiten Proposition nach sich. Einfacher ausgedrückt: Ist die erste Proposition wahr, so muss die zweite Proposition ebenfalls wahr sein. Die erste Proposition ist darüber hinaus auch informativer als die zweite Proposition, da die erstgenannte pragmatisch betrachtet die letztgenannte einschließt, während diese wiederum die diskursrelevantere der beiden Propositionen ist. Die Konstruktion umfasst das konstruktionsevozierende Element (KEE) \"geschweige_denn\", die internen Kern-Konstruktionselemente (Kern-KE) \"Erstes_Konjunkt\" und \"Zweites_Konjunkt\" sowie die externen Kern-KE \"Negator\" und \"Fokuskontext\". Das \"Erste_Konjunkt\" geht dem \"KEE\" voraus, auf welches das \"Zweite_Konjunkt\" folgt. Der informationsstrukturelle Fokus liegt auf dem \"Ersten_Konjunkt\", das die Basis für den entstehenden Kontrast zwischen den zwei Propositionen bildet. Das \"Erste_Konjunkt\" und das \"Zweite_Konjunkt\" bilden jeweils einen Teil der beiden Propositionen ab, wobei das \"Erste_Konjunkt\" meist zusätzlih vom \"Negator\" negiert wird. Der \"Fokuskontext\" indiziert in der Regel den Rest der Proposition. Werden beide Konjunkte im Wechsel mit dem \"Fokuskontext\" kombiniert, können die einander gegenübergestellten Propositionen vollständig wiederhergestellt (oder: vervollständigt) werden. Im Gegensatz zum \"Ersten_Konjunkt\" und \"Zweiten_Konjunkt\" muss der \"Fokuskontext\" nicht zwangsläufig realisiert werden – wird der \"Fokuskontext\" nicht realisiert, drücken die beiden Konjunkte jeweils vollständige Propositionen aus. \" Die zwei gegenübergestellten Propositionen sind hier die beiden Aussagen, dass die meisten von ihnen zuvor noch nie einen Computer a) gesehen und b) bedient haben. Die Verwendung der \"Negation:NEG_XgeschweigedennY-Konstruktion\" erfordert die Einstufung von Sehen und Bedienen auf einer \\'pragmatischen Skala\\', was dazu führt, dass die Aussage Die meisten von ihnen haben zuvor noch nie einen Computer bedient als \\'größere\\' Behauptung betrachtet werden muss als Die meisten von ihnen haben zuvor noch nie einen Computer gesehen. Mit anderen Worten: Wenn die meisten von ihnen einen Computer zuvor noch nie gesehen haben, dann haben sie ihn ganz sicher auch nicht bedient bzw. wenn sie einen Computer noch nie gesehen haben, können sie diesen auch nicht bedient haben. Proposition a) schließt Proposition b) somit aus. Unter dem Aspekt der Negation wird die erste Proposition Die meisten von ihnen haben zuvor noch nie einen Computer gesehen damit zur stärkeren der beiden kontrastierten Propositionen.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"definitions.pickle\", \"rb\") as file:\n",
        "    definitions = pickle.load(file)\n",
        "with open(\"sentences.pickle\", \"rb\") as file:\n",
        "    sentences = pickle.load(file)\n",
        "\n",
        "definitions[\"10\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "C4cDctccfqqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e4d0407-25ad-4857-8026-917b7dc0cbad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\"\"Es ist mehr als klar , dass das ganze Unternehmen keine drei Euro wert ist - geschweige denn die drei Euro je Aktie , die Flowers verlangt \"\" , sagte ein Börsianer .',\n",
              " '\"\"Ich kann mich kaum noch bücken , ich kann meine Laptoptasche nicht mehr tragen , geschweige denn meine Tochter .\"\"',\n",
              " 'Abermillionen rings um die Welt , die das Spektakel auf dem Schirm beobachtet haben , kennen nicht einmal die Namen der Staatschefs von China , Indien oder den europäischen Ländern , geschweige denn , dass sie ihre Amtseinführung bestaunen würden .',\n",
              " 'Bei ihnen ist es bereits schwer vorstellbar , dass sie Geiseln nehmen , geschweige denn diese ermorden , und schon gar keine Frauen oder sogar Kinder .\"\"',\n",
              " 'Bis heute sind viele dieser Untaten , dieser Massaker an der »Heimatfront« , kaum aufgeklärt , geschweige denn im öffentlichen Gedächtnis präsent .',\n",
              " 'Bush selbst hat wahrscheinlich kaum einmal den Namen Johann Strauss gehört , geschweige denn eine Seite von Leo gelesen , doch wurde seine Politik durch dessen Denken geprägt .',\n",
              " 'Da merkt kein Mensch , dass wir alle das gleiche Kleidungsstück anhaben , geschweige denn , dass es Jumpsuit heißt . \"\"',\n",
              " 'Da musst du dann die juristischen Begriffe benutzen , du musst dich damit abfinden , dass dein Mandant nicht versteht , worum es geht , geschweige denn das Publikum .',\n",
              " 'Dennoch hat Hamas es nicht geschafft , ihre militärischen Kapazitäten auszubauen , geschweige denn eine zivile Infrastruktur in ihrem Einflussgebiet zu etablieren .',\n",
              " 'Der Gutachter selbst hat die Tiere allerdings nie im Labor besucht , geschweige denn untersucht .',\n",
              " 'Deren Ergebnisse zogen kaum Diskussionen , geschweige denn Taten nach sich .',\n",
              " 'Die Beschäftigung mit dem Kontinent sei einfach zu deprimierend , er sehe sich nicht in der Lage , die Krise des Kontinents zu erklären , geschweige denn Lösungswege vorzuschlagen .',\n",
              " 'Die Flüsse , die Chinas Städte durchströmen , sind oftmals fließende Kloaken , deren Wasser nicht einmal zur Bewässerung von Feldern taugt , geschweige denn als Trinkwasser .',\n",
              " 'Die Geschichte zeigt , dass die Nieder- und Querschläge eines Jumbobankrotts nicht voraussehbar sind – geschweige denn kontrollierbar .',\n",
              " 'Die meisten von ihnen haben zuvor noch nie einen Computer gesehen , geschweige denn bedient .',\n",
              " 'Dies lässt sich damit begründen , dass vor und neben Alexander – soweit wir wissen – kein Grieche auf die Idee gekommen ist , geschweige denn versucht hat , nach Indien zu ziehen .',\n",
              " 'Ein Bündnis mit Politikern , die Maas selbst für kaum politik- , geschweige denn regierungsfähig hält ?',\n",
              " 'Eine ausführliche Begründung , geschweige denn eine rechtliche Handhabe gibt es nicht .',\n",
              " 'Es gibt keine repräsentativen Meinungsumfragen , es gibt keine Nachwahlbefragungen , und es gibt keine entsprechenden Computerprogramme – geschweige denn das dafür nötige Know-how von Meinungsforschern .',\n",
              " 'Es ist schon peinlich , dass statt Deutschland jetzt ein Staat , den bis Dienstag kaum jemand kannte , geschweige denn auf der Weltkarte fand , 17 Uiguren aus dem amerikanischen Militärgefängnis eine neue Heimat bieten will .',\n",
              " 'Es sei schwer verständlich , wie Finanzmarkthändler bei AIG überhaupt Sonderzahlungen verdient haben könnten , geschweige denn von 165 Millionen Dollar .',\n",
              " 'Genauso wichtig ist , zu sehen , dass die gewürfelten Augenzahlen signifikanten Einfluss auf das Geschehen auf dem Bildschirm haben ; so wie wir manche Sachen im Leben nicht bestimmen geschweige denn vorhersehen können .',\n",
              " 'Geschweige denn , dass sie die Argumentation einfach kippten .',\n",
              " 'Geschweige denn die monatlichen Ausgaben .',\n",
              " 'Geschweige denn ihre Aktivitäten bei Twitter , Facebook und ähnlichen Angeboten .',\n",
              " 'Gewiss , Jimmy bildet sich ein , dass sich die drei Entkommenen einmal im Jahr bei seinem Nachbarn treffen , und kurz lässt Tony sich von der Marotte seines Onkels anstecken , aber eine gegenseitige Stimulation der beiden Erzählebenen , geschweige denn ein Zopf , wird nicht daraus .',\n",
              " 'Hilfsorganisationen warnen seit Langem : Sie befürchten , dass die reichen Länder wegen der tiefen Krise ihre zugesagte Entwicklungshilfe nicht einhalten – geschweige denn noch etwas mehr drauflegen , um , wie FAO-Generaldirektor Jacques Diouf verlangt , \"\"den Hunger in der Welt völlig und rasch auszurotten\"\" .',\n",
              " 'Ihre Forderungen seien noch nicht einmal bei den Frauen der städtischen Mittelschichten angekommen , geschweige denn in den ländlichen Gebieten .',\n",
              " 'Keine Spur einer Entrüstung , geschweige denn die Nachfrage , wie es Schulze nun gehe .',\n",
              " 'Man habe keine Zunahme der Petitionen feststellen können , geschweige denn , dass sich breitere Bevölkerungsschichten an ihnen beteiligten als zuvor .',\n",
              " 'Noch aber hat keiner der Bundesstaaten eine solche Regelung eingeführt – geschweige denn , dass es ein entsprechendes Bundesgesetz gibt .',\n",
              " 'Noch die größten Experten wissen nicht zu sagen , was in sechs Monaten sein wird , geschweige denn in sechs Jahren .',\n",
              " 'Noch nie wurde gewagt , das Kommende , das Unklare zu planen , da man noch nicht einmal weiß , geschweige denn versteht , was ist .',\n",
              " 'Noch weiß niemand genau , wie sich aus den iPS gezielt einzelne Körperzellen züchten lassen , geschweige denn ganze Muskeln oder Organe .',\n",
              " 'Oder man geht ins Studio , wo man Songs aufnimmt , die man in der Realität nie spielen geschweige denn komponieren würde .',\n",
              " 'Ohne den Staat könnte ein Großteil der Banken schlicht nicht überleben , geschweige denn die Wirtschaft angemessen mit Geld versorgen .',\n",
              " 'Plötzlich konnte Quelle keine Rechnung mehr bezahlen , geschweige denn den Hauptkatalog für den Herbst und Winter finanzieren .',\n",
              " 'Reicher , geschweige denn glücklicher , wird ein Volk dadurch nicht – ebenso wenig , wie es durch die Heirat des Geistlichen ärmer wird .',\n",
              " 'Sein Betrieb , eine kleine Klitsche für chemische Reinigungsmittel , bietet ihm keine Krankenkasse als Teil des Gehaltspaketes an , und die acht Dollar , die er pro Stunde verdient , reichen kaum zum Leben , geschweige denn für eine Prämienzahlung .',\n",
              " 'Sie könne nicht inmitten 20.000 fremder Leute trauern , geschweige denn eine Rede halten .',\n",
              " 'Solange kein Polizist daneben steht , ist das Band kein Hindernis , geschweige denn eine Mauer .',\n",
              " 'Solange zwischen den beiden Palästinenser-Gebilden latenter Bürgerkrieg herrscht , ist ein Zweistaaten-Model selbst in der Logik nicht auf der Agenda , geschweige denn in der Praxis .',\n",
              " 'Und dann ist da noch das generelle Problem mit Hamas , dass nicht jeder Sprecher und Führer , der redet , auch etwas zu sagen , geschweige denn das letzte Wort hat .',\n",
              " 'Und viele Künstler kreisten derart um sich selbst , dass sich ein Blick in die Tradition der Kunst , geschweige denn über die deutsch-deutsche Grenze geradezu verbot .',\n",
              " 'Viele stellen in Indien auch eine grundsätzliche Frage : Biowissenschaften , Nanotechnologie , gar Mondraketen – ist das wirklich das , was ein Land braucht , in dem hunderte Millionen Menschen hungern , kein fließendes Wasser , geschweige denn Strom haben ?',\n",
              " 'Von einer zusätzlich die Existenz bedrohenden Kapitalnot war öffentlich noch nicht die Rede , geschweige denn davon , dass der Staat diese Kapitalnot beheben müsste .',\n",
              " 'Weil Funktionäre , Politiker , Ärzte sowie Trainer und Sportler nicht sehen , hören , geschweige denn reden wollen .',\n",
              " '»Ohne Europa sind viele Fragen nicht mehr seriös in Angriff zu nehmen , geschweige denn zu lösen« , meint der grüne Bundesparteisekretär Lothar Lockl .'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "sentences[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tap32gHBHoA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232,
          "referenced_widgets": [
            "66bfceea93a442b58252269f7c5ee5a8",
            "6b7ad871964f4a6c9416bf94ec33c82e",
            "3c9ed48e98314d9380bcb4004c4f54fa",
            "51141b6efb55487b81cb2f18879eaeab",
            "7bd3186bf23b4ec7a7d9aede81872e4e",
            "7ece653dacb644c1ad5eb9f321574258",
            "1c50e2aafcdf4d9ea7b32a4377c13359",
            "4f831815d6874c77b2bd2b8e248109d9",
            "1ee0a2c83fa34912bcb28d9515e8f6e1",
            "6279e720f5af4c14976bcaad9ab95baa",
            "e39ebe5b13a0466fb841e8bed6878361"
          ]
        },
        "outputId": "3b085983-8ac2-47b1-db28-139c45995747"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/211 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66bfceea93a442b58252269f7c5ee5a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 98 97 \n",
            "(\"['»Ohne Europa sind viele Fragen nicht mehr seriös in Angriff zu nehmen , geschweige denn zu lösen« , meint der grüne Bundesparteisekretär Lothar Lockl .', 'Bis heute sind viele dieser Untaten , dieser Massaker an der »Heimatfront« , kaum aufgeklärt , geschweige denn im öffentlichen Gedächtnis präsent .', 'Plötzlich konnte Quelle keine Rechnung mehr bezahlen , geschweige denn den Hauptkatalog für den Herbst und Winter finanzieren .']\", '[\"Ich habe heute eine Socke verloren , geschweige denn den ganzen Tag\", \"Das Auto, das ich gekauft habe, war zu teuer , geschweige denn zu ungerechtfertigt\", \"Ich habe gestern viel gegessen , geschweige denn zu viel\"]')\n",
            "99 98 97 \n",
            "(\"['Sicherheitsgefühl und objektive Sicherheit seien für die Lebensqualität gleich wichtig .', 'Wir haben schweizweit eine Patt - Situation , weil der linke und der rechte Block gleich stark sind .', 'Bis auf wenige Millimeter sind die Geräte praktisch gleich groß .']\", '[\"Die äquative Pluralkonstruktion zeigt die Gleichheit zweier Einheiten, die hinsichtlich eines bestimmten Wertes eines spezifischen Attributs auf einer Skala miteinander verglichen werden.\", \"Die äquative Pluralkonstruktion zeigt die Gleichheit zweier Einheiten, die hinsichtlich eines bestimmten Wertes eines spezifischen Attributs auf einer Skala miteinander verglichen werden.\", \"Die äquative Pluralkonstruktion zeigt die Gleichheit zweier Einheiten, die hinsichtlich eines bestimmten Wertes eines spezifischen Attributs auf einer Skala miteinander verglichen werden.\"]')\n",
            "99 98 \n",
            "(\"['Groß , größer , Istanbul', 'Hoch , höher , Holzdeppe :', '23. Juni 1999 Dumm , dümmer , Duden Der Bürger und die Arroganz der Macht :']\", '[\"Lang , länger , die Woche\", \"Schwer , schwerer , die Woche\", \"Kalt , kälter , der Winter\", \"Zart , zarter , die Rose\", \"Stark , stärker , das Auto\", \"Schön , schöner , das Mädchen\"]')\n",
            "99 \n",
            "(\"['Im besten Fall reicht eine mit weißer Farbe markierte Mittelinsel .', 'Dass eine Abstimmung nun erneut in größter Eile erfolgen müsste , macht die Sache nicht besser .', 'Maximilian Philipp hatte vor der Saison keiner auf der Rechnung , am Samstag traf der Ex-Freiburger zweimal nach bester Stürmerart .']\", '[\"In diesem Bereich schafft es keiner seiner Schüler, auf dem höchsten Niveau zu bestehen.\", \"In Bezug auf die Qualität der Arbeit steht sie an der Spitze der Klasse.\", \"Das ist die beste Leistung, die wir bisher erbracht haben.\"]')\n",
            "99 "
          ]
        }
      ],
      "source": [
        "import re\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def generate_examples(definition: str, sentence: str, temperature=0.75, top_p=0.95, top_k=1, max_new_tokens=1024):\n",
        "    prompt = lambda definition, sentence: f'''### User: Du bist kreativ und gewissenhaft. Hier ist eine Definition: {definition} Bilde neue Sätze gemäß dieser Definition. Gib die Sätze in einer Python-Liste aus. Gib sonst nichts aus.\n",
        "    ### Example: {sentence}\n",
        "    ### Assistant:[\"'''\n",
        "\n",
        "    prompt_length = len(prompt(definition, sentence))\n",
        "    output = []\n",
        "    first_output = \"\"\n",
        "    i = 100  # only try 100 times\n",
        "    while (\n",
        "        (not any([c.isalpha() for c in first_output]))\n",
        "        or any([x in first_output for x in {\"Konstruktion\", \"Satz\", \"Überschrift\", \"_\", \":\", \"XY\", \"XP\", \"X \", \"Y \", \"X.\", \"Y.\"}])\n",
        "        or re.search(r\".*\\].*\\[.*\", first_output)\n",
        "    ):\n",
        "        input_ids = tokenizer(prompt(definition, sentence), return_tensors='pt').input_ids.cuda()\n",
        "        output = model.generate(inputs=input_ids, temperature=temperature,\n",
        "                                do_sample=True, top_p=top_p, top_k=top_k,\n",
        "                                max_new_tokens=max_new_tokens)\n",
        "        output = tokenizer.decode(output[0])[prompt_length:].strip()\n",
        "        output = re.findall('\\[.*\\]', output)\n",
        "        if len(output) > 0:\n",
        "            first_output = output[0]\n",
        "        i -= 1\n",
        "        print(i, end=\" \")\n",
        "        if i == 0:\n",
        "            first_output = \"[]\"\n",
        "            break\n",
        "        #print(f\"\\t{output}\")\n",
        "    #print(f\"\\n{output}\")\n",
        "    print()\n",
        "    return first_output\n",
        "\n",
        "examples = []\n",
        "if os.path.exists(\"examples.pickle\"):\n",
        "    with open(\"examples.pickle\", \"rb\") as file:\n",
        "        examples = pickle.load(file)\n",
        "for k in tqdm(list(definitions.keys())[len(examples):]):\n",
        "    definition = definitions[str(k)]\n",
        "    sentence = str(list(sentences[int(k)])[0:3])  # get some sentences\n",
        "\n",
        "    example = generate_examples(definition, sentence, temperature=0.75, max_new_tokens=1000,\n",
        "                                top_k=100, top_p=0.99)\n",
        "    #example = re.findall('\\[(\"[^\"]*\"(?:, ?\"[^\"]*\")*)\\]', example)[0]\n",
        "    try:\n",
        "        print((sentence, example))\n",
        "        examples.append((sentence, example))  # one is enough\n",
        "    except:\n",
        "        print((sentence, \"[]\"))\n",
        "        examples.append((sentence, \"[]\"))\n",
        "\n",
        "    with open(\"examples.pickle\", \"wb\") as file:\n",
        "        pickle.dump(examples, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enXMGYUcTAlM"
      },
      "outputs": [],
      "source": [
        "while True:pass"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "66bfceea93a442b58252269f7c5ee5a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b7ad871964f4a6c9416bf94ec33c82e",
              "IPY_MODEL_3c9ed48e98314d9380bcb4004c4f54fa",
              "IPY_MODEL_51141b6efb55487b81cb2f18879eaeab"
            ],
            "layout": "IPY_MODEL_7bd3186bf23b4ec7a7d9aede81872e4e"
          }
        },
        "6b7ad871964f4a6c9416bf94ec33c82e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ece653dacb644c1ad5eb9f321574258",
            "placeholder": "​",
            "style": "IPY_MODEL_1c50e2aafcdf4d9ea7b32a4377c13359",
            "value": "  2%"
          }
        },
        "3c9ed48e98314d9380bcb4004c4f54fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f831815d6874c77b2bd2b8e248109d9",
            "max": 211,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ee0a2c83fa34912bcb28d9515e8f6e1",
            "value": 4
          }
        },
        "51141b6efb55487b81cb2f18879eaeab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6279e720f5af4c14976bcaad9ab95baa",
            "placeholder": "​",
            "style": "IPY_MODEL_e39ebe5b13a0466fb841e8bed6878361",
            "value": " 4/211 [01:38&lt;1:04:36, 18.73s/it]"
          }
        },
        "7bd3186bf23b4ec7a7d9aede81872e4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ece653dacb644c1ad5eb9f321574258": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c50e2aafcdf4d9ea7b32a4377c13359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f831815d6874c77b2bd2b8e248109d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ee0a2c83fa34912bcb28d9515e8f6e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6279e720f5af4c14976bcaad9ab95baa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e39ebe5b13a0466fb841e8bed6878361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}