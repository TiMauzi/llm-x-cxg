{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:34:49.077484200Z",
     "start_time": "2024-01-02T17:34:41.159510800Z"
    }
   },
   "id": "863338ddbf31a6c5"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 example  \\\n0      Und dann ist da noch das generelle Problem mit...   \n1      Und dann ist da noch das generelle Problem mit...   \n2      Und dann ist da noch das generelle Problem mit...   \n3      Und dann ist da noch das generelle Problem mit...   \n4      Und dann ist da noch das generelle Problem mit...   \n...                                                  ...   \n83378  Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n83379  Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n83380  Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n83381  Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n83382  Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n\n                                                   query    pseudoword  \n0      Und dann ist da noch das generelle Problem mit...  geschweige10  \n1      Und dann ist da noch das generelle Problem mit...        denn10  \n2      Und dann ist da noch das generelle Problem mit...  geschweige10  \n3      Und dann ist da noch das generelle Problem mit...        denn10  \n4      Und dann ist da noch das generelle Problem mit...  geschweige10  \n...                                                  ...           ...  \n83378  Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n83379  Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n83380  Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n83381  Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n83382  Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n\n[83383 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>example</th>\n      <th>query</th>\n      <th>pseudoword</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>geschweige10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>denn10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>geschweige10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>denn10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>geschweige10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>83378</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>83379</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>83380</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>83381</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>83382</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n  </tbody>\n</table>\n<p>83383 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../../data/pseudowords/CoMaPP_all_bert.json\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "data = [{\"example\": d[\"target1\"], \"query\": (\" \".join(d[\"query\"].split()[:d[\"query_idx\"]]) + \" \" + d[\"label\"] + \" \" + \" \".join(d[\"query\"].split()[d[\"query_idx\"]+1:])).strip(), \"pseudoword\": d[\"label\"]} for d in data]\n",
    "df = pd.DataFrame.from_dict(data).drop_duplicates(ignore_index=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:34:50.263991200Z",
     "start_time": "2024-01-02T17:34:49.083035400Z"
    }
   },
   "id": "18bb06d46d72aab4"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 example  \\\nindex                                                      \n10     Und dann ist da noch das generelle Problem mit...   \n10     Und dann ist da noch das generelle Problem mit...   \n10     Und dann ist da noch das generelle Problem mit...   \n10     Und dann ist da noch das generelle Problem mit...   \n10     Und dann ist da noch das generelle Problem mit...   \n...                                                  ...   \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n\n                                                   query    pseudoword  \nindex                                                                   \n10     Und dann ist da noch das generelle Problem mit...  geschweige10  \n10     Und dann ist da noch das generelle Problem mit...        denn10  \n10     Und dann ist da noch das generelle Problem mit...  geschweige10  \n10     Und dann ist da noch das generelle Problem mit...        denn10  \n10     Und dann ist da noch das generelle Problem mit...  geschweige10  \n...                                                  ...           ...  \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n\n[83383 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>example</th>\n      <th>query</th>\n      <th>pseudoword</th>\n    </tr>\n    <tr>\n      <th>index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>geschweige10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>denn10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>geschweige10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>denn10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>geschweige10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n  </tbody>\n</table>\n<p>83383 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['index'] = df['pseudoword'].str.extract('(\\d+)').astype(int)\n",
    "df.set_index('index', inplace=True)\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:34:50.591286300Z",
     "start_time": "2024-01-02T17:34:50.266057200Z"
    }
   },
   "id": "b7e1f6e88f687297"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                   example  \\\nconstruction pseudoword                                                      \n5            Und5        [Und schon gar nicht mit der Mehrwertsteuer .,...   \n             erst5       [Trainer Lucien Favre hatte schon seine beiden...   \n             gar5        [Es hat Afghanistan nicht stabilisiert und sch...   \n             nicht5      [Es hat Afghanistan nicht stabilisiert und sch...   \n             recht5      [Trainer Lucien Favre hatte schon seine beiden...   \n...                                                                    ...   \n1884         Gold1884    [Schweigen ist Silber , reden ist Gold ., Schw...   \n             Silber1884  [Schweigen ist Silber , reden ist Gold ., Schw...   \n             ist1884     [Schweigen ist Silber , reden ist Gold ., Schw...   \n1986         kaum1986    [Die Vorhut vor 20.000 Jahren war für das Ries...   \n1987         sehr1987    [Solche Menschen können sich sehr wohlfühlen o...   \n\n                                                                     query  \nconstruction pseudoword                                                     \n5            Und5        [Und5 schon gar nicht [MASK] der Mehrwertsteue...  \n             erst5       [Trainer Lucien Favre hatte schon seine beiden...  \n             gar5        [[MASK] hat Afghanistan nicht stabilisiert und...  \n             nicht5      [[MASK] hat Afghanistan nicht5 stabilisiert un...  \n             recht5      [Trainer Lucien Favre hatte schon seine beiden...  \n...                                                                    ...  \n1884         Gold1884    [[MASK] ist Silber , reden ist Gold1884 ., Sch...  \n             Silber1884  [[MASK] ist Silber1884 , reden ist Gold ., Sch...  \n             ist1884     [[MASK] ist1884 Silber , reden ist Gold ., Sch...  \n1986         kaum1986    [[MASK] Vorhut vor 20.000 Jahren war für das R...  \n1987         sehr1987    [[MASK] Menschen können sich sehr1987 wohlfühl...  \n\n[581 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>example</th>\n      <th>query</th>\n    </tr>\n    <tr>\n      <th>construction</th>\n      <th>pseudoword</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">5</th>\n      <th>Und5</th>\n      <td>[Und schon gar nicht mit der Mehrwertsteuer .,...</td>\n      <td>[Und5 schon gar nicht [MASK] der Mehrwertsteue...</td>\n    </tr>\n    <tr>\n      <th>erst5</th>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n    </tr>\n    <tr>\n      <th>gar5</th>\n      <td>[Es hat Afghanistan nicht stabilisiert und sch...</td>\n      <td>[[MASK] hat Afghanistan nicht stabilisiert und...</td>\n    </tr>\n    <tr>\n      <th>nicht5</th>\n      <td>[Es hat Afghanistan nicht stabilisiert und sch...</td>\n      <td>[[MASK] hat Afghanistan nicht5 stabilisiert un...</td>\n    </tr>\n    <tr>\n      <th>recht5</th>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">1884</th>\n      <th>Gold1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[[MASK] ist Silber , reden ist Gold1884 ., Sch...</td>\n    </tr>\n    <tr>\n      <th>Silber1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[[MASK] ist Silber1884 , reden ist Gold ., Sch...</td>\n    </tr>\n    <tr>\n      <th>ist1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[[MASK] ist1884 Silber , reden ist Gold ., Sch...</td>\n    </tr>\n    <tr>\n      <th>1986</th>\n      <th>kaum1986</th>\n      <td>[Die Vorhut vor 20.000 Jahren war für das Ries...</td>\n      <td>[[MASK] Vorhut vor 20.000 Jahren war für das R...</td>\n    </tr>\n    <tr>\n      <th>1987</th>\n      <th>sehr1987</th>\n      <td>[Solche Menschen können sich sehr wohlfühlen o...</td>\n      <td>[[MASK] Menschen können sich sehr1987 wohlfühl...</td>\n    </tr>\n  </tbody>\n</table>\n<p>581 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'construction'}, inplace=True)\n",
    "\n",
    "result_df = df.groupby(['construction', 'pseudoword']).agg({'example': list, 'query': list})\n",
    "\n",
    "result_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:34:50.752078400Z",
     "start_time": "2024-01-02T17:34:50.580606600Z"
    }
   },
   "id": "4a4e3d92707b4c4"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             definition\n10    Die \"Negation:NEG_XgeschweigedennY-Konstruktio...\n100   Die \"Äquativ_Plural-Konstruktion\" gehört zu de...\n1004  Die \"Superlativ_Klimax:ADJ1_ADJ1-er_NP-Konstru...\n1006  Die \"Superlativ:PRÄP_ADJ-ster_NP-Konstruktion\"...\n101   Die \"Äquativ:ADJwieNP-Konstruktion\" gehört zu ...\n...                                                 ...\n97    Die \"Komparativ:ADJ1-eralsADJ1-Konstruktion\" g...\n973   Bei \"Disjunktion_Doppeltitel:XoderY\" handelt e...\n976   Bei \"Korrelation_Affirmation:WoXist, istY\" han...\n98    Die \"Äquativ:soADJwieXP-Konstruktion\" gehört z...\n99    Die \"Komparativ:ADJ-eralsX-Konstruktion\" gehör...\n\n[211 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>definition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>Die \"Negation:NEG_XgeschweigedennY-Konstruktio...</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>Die \"Äquativ_Plural-Konstruktion\" gehört zu de...</td>\n    </tr>\n    <tr>\n      <th>1004</th>\n      <td>Die \"Superlativ_Klimax:ADJ1_ADJ1-er_NP-Konstru...</td>\n    </tr>\n    <tr>\n      <th>1006</th>\n      <td>Die \"Superlativ:PRÄP_ADJ-ster_NP-Konstruktion\"...</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>Die \"Äquativ:ADJwieNP-Konstruktion\" gehört zu ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>Die \"Komparativ:ADJ1-eralsADJ1-Konstruktion\" g...</td>\n    </tr>\n    <tr>\n      <th>973</th>\n      <td>Bei \"Disjunktion_Doppeltitel:XoderY\" handelt e...</td>\n    </tr>\n    <tr>\n      <th>976</th>\n      <td>Bei \"Korrelation_Affirmation:WoXist, istY\" han...</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>Die \"Äquativ:soADJwieXP-Konstruktion\" gehört z...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Die \"Komparativ:ADJ-eralsX-Konstruktion\" gehör...</td>\n    </tr>\n  </tbody>\n</table>\n<p>211 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../../out/definitions.pickle\", \"rb\") as definitions_file:\n",
    "    definitions = pd.DataFrame.from_dict(pickle.load(definitions_file), orient=\"index\", columns=[\"definition\"])\n",
    "    \n",
    "definitions"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:34:50.770384400Z",
     "start_time": "2024-01-02T17:34:50.723262Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                   example  \\\nconstruction pseudoword                                                      \n5            Und5        [Und schon gar nicht mit der Mehrwertsteuer .,...   \n             erst5       [Trainer Lucien Favre hatte schon seine beiden...   \n             gar5        [Es hat Afghanistan nicht stabilisiert und sch...   \n             nicht5      [Es hat Afghanistan nicht stabilisiert und sch...   \n             recht5      [Trainer Lucien Favre hatte schon seine beiden...   \n...                                                                    ...   \n1884         Gold1884    [Schweigen ist Silber , reden ist Gold ., Schw...   \n             Silber1884  [Schweigen ist Silber , reden ist Gold ., Schw...   \n             ist1884     [Schweigen ist Silber , reden ist Gold ., Schw...   \n1986         kaum1986    [Die Vorhut vor 20.000 Jahren war für das Ries...   \n1987         sehr1987    [Solche Menschen können sich sehr wohlfühlen o...   \n\n                                                                     query  \\\nconstruction pseudoword                                                      \n5            Und5        [Und5 schon gar nicht [MASK] der Mehrwertsteue...   \n             erst5       [Trainer Lucien Favre hatte schon seine beiden...   \n             gar5        [[MASK] hat Afghanistan nicht stabilisiert und...   \n             nicht5      [[MASK] hat Afghanistan nicht5 stabilisiert un...   \n             recht5      [Trainer Lucien Favre hatte schon seine beiden...   \n...                                                                    ...   \n1884         Gold1884    [[MASK] ist Silber , reden ist Gold1884 ., Sch...   \n             Silber1884  [[MASK] ist Silber1884 , reden ist Gold ., Sch...   \n             ist1884     [[MASK] ist1884 Silber , reden ist Gold ., Sch...   \n1986         kaum1986    [[MASK] Vorhut vor 20.000 Jahren war für das R...   \n1987         sehr1987    [[MASK] Menschen können sich sehr1987 wohlfühl...   \n\n                                                                definition  \nconstruction pseudoword                                                     \n5            Und5        Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...  \n             erst5       Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...  \n             gar5        Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...  \n             nicht5      Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...  \n             recht5      Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...  \n...                                                                    ...  \n1884         Gold1884    Die \"Intensivierung_Komparativ:Xist_SilberYist...  \n             Silber1884  Die \"Intensivierung_Komparativ:Xist_SilberYist...  \n             ist1884     Die \"Intensivierung_Komparativ:Xist_SilberYist...  \n1986         kaum1986    Die Konstruktion \"Relativierung:kaumADJ\" gehör...  \n1987         sehr1987    Die Konstruktion \"Intensivierung:sehrV\" gehört...  \n\n[581 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>example</th>\n      <th>query</th>\n      <th>definition</th>\n    </tr>\n    <tr>\n      <th>construction</th>\n      <th>pseudoword</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">5</th>\n      <th>Und5</th>\n      <td>[Und schon gar nicht mit der Mehrwertsteuer .,...</td>\n      <td>[Und5 schon gar nicht [MASK] der Mehrwertsteue...</td>\n      <td>Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...</td>\n    </tr>\n    <tr>\n      <th>erst5</th>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...</td>\n    </tr>\n    <tr>\n      <th>gar5</th>\n      <td>[Es hat Afghanistan nicht stabilisiert und sch...</td>\n      <td>[[MASK] hat Afghanistan nicht stabilisiert und...</td>\n      <td>Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...</td>\n    </tr>\n    <tr>\n      <th>nicht5</th>\n      <td>[Es hat Afghanistan nicht stabilisiert und sch...</td>\n      <td>[[MASK] hat Afghanistan nicht5 stabilisiert un...</td>\n      <td>Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...</td>\n    </tr>\n    <tr>\n      <th>recht5</th>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">1884</th>\n      <th>Gold1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[[MASK] ist Silber , reden ist Gold1884 ., Sch...</td>\n      <td>Die \"Intensivierung_Komparativ:Xist_SilberYist...</td>\n    </tr>\n    <tr>\n      <th>Silber1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[[MASK] ist Silber1884 , reden ist Gold ., Sch...</td>\n      <td>Die \"Intensivierung_Komparativ:Xist_SilberYist...</td>\n    </tr>\n    <tr>\n      <th>ist1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[[MASK] ist1884 Silber , reden ist Gold ., Sch...</td>\n      <td>Die \"Intensivierung_Komparativ:Xist_SilberYist...</td>\n    </tr>\n    <tr>\n      <th>1986</th>\n      <th>kaum1986</th>\n      <td>[Die Vorhut vor 20.000 Jahren war für das Ries...</td>\n      <td>[[MASK] Vorhut vor 20.000 Jahren war für das R...</td>\n      <td>Die Konstruktion \"Relativierung:kaumADJ\" gehör...</td>\n    </tr>\n    <tr>\n      <th>1987</th>\n      <th>sehr1987</th>\n      <td>[Solche Menschen können sich sehr wohlfühlen o...</td>\n      <td>[[MASK] Menschen können sich sehr1987 wohlfühl...</td>\n      <td>Die Konstruktion \"Intensivierung:sehrV\" gehört...</td>\n    </tr>\n  </tbody>\n</table>\n<p>581 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = pd.merge(result_df, definitions, how=\"inner\", left_on=\"construction\", right_index=True)  # TODO: Aussortierte Definitions betrachten!\n",
    "examples"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:34:50.894409700Z",
     "start_time": "2024-01-02T17:34:50.742076600Z"
    }
   },
   "id": "238d2238bbdd91d8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Generieren neuer Sätze:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bc899cb800665fa"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-2.0389168 , -1.6559315 ,  2.3402972 , ...,  1.9295877 ,\n        -0.2874232 ,  0.1127736 ],\n       [ 2.2873163 ,  1.1256251 , -0.72309786, ..., -0.9724281 ,\n        -0.6235189 ,  0.5858617 ],\n       [-0.72157246,  1.1234709 , -0.19191697, ..., -0.44904602,\n        -0.63462436, -0.51367843],\n       ...,\n       [ 1.5758858 ,  3.0587277 ,  1.1784296 , ..., -3.5326967 ,\n         2.022733  ,  0.7190625 ],\n       [-0.02080958,  2.2421186 ,  0.12035339, ..., -0.83508754,\n        -0.4160101 ,  0.07736167],\n       [ 1.2608864 ,  3.31698   , -3.9412627 , ..., -0.71156853,\n        -2.0257826 ,  2.4922867 ]], dtype=float32)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudowords = []\n",
    "for i in range(15):\n",
    "    pseudowords.append(np.load(f\"../../data/pseudowords/bert/pseudowords_comapp_bert_{i*37}_{i*37+37}.npy\"))\n",
    "pseudowords = np.concatenate(pseudowords)\n",
    "pseudowords"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:34:50.945514600Z",
     "start_time": "2024-01-02T17:34:50.788190200Z"
    }
   },
   "id": "c9e6d940aa4aaace"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  label\norder                                                  \n0                                               \"\"Was13\n1                                                  \"647\n2      \"Wir-äh-spielen-äh-in-der-äh-Champions-League647\n3                                                 (1597\n4                                                 (1600\n...                                                 ...\n550                                            wohl1134\n551                                          wollen1029\n552                                             wäre130\n553                                            wäre1660\n554                                            wäre1756\n\n[555 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n    </tr>\n    <tr>\n      <th>order</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"\"Was13</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"647</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"Wir-äh-spielen-äh-in-der-äh-Champions-League647</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(1597</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(1600</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>550</th>\n      <td>wohl1134</td>\n    </tr>\n    <tr>\n      <th>551</th>\n      <td>wollen1029</td>\n    </tr>\n    <tr>\n      <th>552</th>\n      <td>wäre130</td>\n    </tr>\n    <tr>\n      <th>553</th>\n      <td>wäre1660</td>\n    </tr>\n    <tr>\n      <th>554</th>\n      <td>wäre1756</td>\n    </tr>\n  </tbody>\n</table>\n<p>555 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_data = []\n",
    "for i in range(1, 16):\n",
    "    csv_data.append(pd.read_csv(f\"../../data/pseudowords/bert/order_bert_{i}.csv\", sep=\";\", index_col=0, header=None, quotechar=\"|\", names=[\"order\", \"label\"]))\n",
    "csv_data = pd.concat(csv_data)\n",
    "csv_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:34:50.984334300Z",
     "start_time": "2024-01-02T17:34:50.808881100Z"
    }
   },
   "id": "621718c51c9db794"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(['\"\"Was13',\n  '\"647',\n  '\"Wir-äh-spielen-äh-in-der-äh-Champions-League647',\n  '(1597',\n  '(1600',\n  '(1602',\n  '(1624',\n  '(1637',\n  '(1639',\n  '(1641',\n  '(1643',\n  '(1645',\n  '(379',\n  '(579',\n  '(581',\n  '(584',\n  '(590',\n  '(592',\n  '(600',\n  '(886',\n  '(889',\n  '(892',\n  '(900',\n  '(905',\n  '(907',\n  '(909',\n  '(911',\n  '(917',\n  '(919',\n  '(921',\n  '(923',\n  ')1597',\n  ')1600',\n  ')1602',\n  ')1624',\n  ')1637',\n  ')1639',\n  ')1641',\n  ')1643',\n  ')1645',\n  ')1792',\n  ')379',\n  ')579',\n  ')581',\n  ')584',\n  ')590',\n  ')592',\n  ')600',\n  ')886',\n  ')889',\n  ')892',\n  ')900',\n  ')905',\n  ')907',\n  ')909',\n  ')911',\n  ')917',\n  ')919',\n  ')921',\n  ')923',\n  ')«579',\n  ',1459',\n  ',973',\n  '-128',\n  '-651',\n  '-654',\n  '-875',\n  '-973',\n  ':595',\n  ':875',\n  ':973',\n  'Abstand683',\n  'Allein20',\n  'Aller1630',\n  'Als1315',\n  'Als133',\n  'Als1770',\n  'Am488',\n  'Am492',\n  'Am500',\n  'Amerika605',\n  'Anstatt320',\n  'Art129',\n  'Arzt1509',\n  'Augenblick1301',\n  'Ausmaß1777',\n  'BRUTAL1503',\n  'Besser1762',\n  'Bis559',\n  'Brutal1503',\n  'Buche1346',\n  'Das1313',\n  'Das1461',\n  'Dass21',\n  'Dasselbe104',\n  'Der1301',\n  'Desto111',\n  'Die1681',\n  'Diese19',\n  'Dieser1301',\n  'Dieser19',\n  'Dieses19',\n  'Entweder1779',\n  'Es1313',\n  'Es605',\n  'Gefühl1301',\n  'Generation1126',\n  'Geschweige10',\n  'Gleiche104',\n  'Gold1554',\n  'Gold1884',\n  'Hauptsache1033',\n  'Im557',\n  'In557',\n  'In858',\n  'Inbegriff1671',\n  'Ist1660',\n  'Je111',\n  'Jedermanns1329',\n  'Jener1301',\n  'Jetzt1631',\n  'Kein1525',\n  'Kein1715',\n  'Kein1835',\n  'Kein949',\n  'Keine(r1792',\n  'Keine1525',\n  'Keine1715',\n  'Keine1792',\n  'Keine1835',\n  'Keine902',\n  'Keine949',\n  'Keiner1792',\n  'Leben1461',\n  'Leben605',\n  'Lecker1649',\n  'Maß1777',\n  'Maße1777',\n  'Mit1029',\n  'Mit683',\n  'Moment1301',\n  'Mords651',\n  'Mutter1681',\n  'Neue875',\n  'Nicht1162',\n  'Nicht902',\n  'Niemand1792',\n  'Ponyhof1462',\n  'Raus1316',\n  'Reden1554',\n  'Riesen654',\n  'Silber1554',\n  'Silber1884',\n  'So1300',\n  'So1760',\n  'So1831',\n  'So22',\n  'So74',\n  'So98',\n  'Solch78',\n  'Solche78',\n  'Sowohl1134',\n  'Statt320',\n  'Tode1347',\n  'Trotz1630',\n  'Umfang1777',\n  'Umso111',\n  'Und11',\n  'Und5',\n  'Von1034',\n  'Von1629',\n  'Von1772',\n  'Warum1029',\n  'Was1029',\n  'Was13',\n  'Was16',\n  'Was1846',\n  'Weder12',\n  'Weil674',\n  'Weil681',\n  'Welch15',\n  'Wem1029',\n  'Wenn1291',\n  'Wer1029',\n  'Wie1029',\n  'Wie14',\n  'Wie1738',\n  'Wo1029',\n  'Wo976',\n  'Während320',\n  'Zeit605',\n  'Zeiten605',\n  '[1643',\n  ']1643',\n  'ab1574',\n  'aber902',\n  'allen1630',\n  'aller1630',\n  'aller1681',\n  'aller758',\n  'als1134',\n  'als133',\n  'als1762',\n  'als1770',\n  'als97',\n  'am488',\n  'am492',\n  'am500',\n  'an349',\n  'anstatt320',\n  'anstatt882',\n  'artig128',\n  'auch1134',\n  'auch1715',\n  'auch1835',\n  'auf1574',\n  'auf350',\n  'aufhübschen1029',\n  'aus1316',\n  'ausbreiten1029',\n  'auslöste1029',\n  'badete1029',\n  'bedeutet1029',\n  'besser1762',\n  'betreffen1029',\n  'bis1509',\n  'bis559',\n  'bisschen762',\n  'bleibt1660',\n  'braucht1029',\n  'bringt1029',\n  'brutal1503',\n  'darstellen1029',\n  'das104',\n  'das1301',\n  'das1459',\n  'das1461',\n  'das875',\n  'dass135',\n  'dasselbe104',\n  'dem1777',\n  'den557',\n  'den671',\n  'denn10',\n  'der1509',\n  'der1681',\n  'der557',\n  'der875',\n  'desto111',\n  'die1681',\n  'die875',\n  'diese605',\n  'dieses19',\n  'durch1574',\n  'ebenso122',\n  'ebenso98',\n  'ein127',\n  'ein1715',\n  'ein1835',\n  'ein762',\n  'einander1574',\n  'eine129',\n  'eine1715',\n  'eine1835',\n  'eine605',\n  'einem127',\n  'einer127',\n  'entweder1779',\n  'er1004',\n  'er1346',\n  'er99',\n  'erst5',\n  'erzeugt1029',\n  'es125',\n  'es1313',\n  'es1346',\n  'es1631',\n  'es605',\n  'euch1574',\n  'excellence1342',\n  'fahre1029',\n  'früher1459',\n  'für13',\n  'für1525',\n  'für350',\n  'gab605',\n  'ganz697',\n  'ganz777',\n  'gar5',\n  'gar697',\n  'gar777',\n  'geben605',\n  'gegeben605',\n  'gegen83',\n  'gehen1029',\n  'geht1300',\n  'genauso122',\n  'genauso98',\n  'geschweige10',\n  'gewesen1459',\n  'gibt605',\n  'gleich100',\n  'gleich675',\n  'gleich676',\n  'gleich98',\n  'gleiche104',\n  'gleichen1777',\n  'gleichkam676',\n  'gleichkommen676',\n  'gleichkommt676',\n  'gleichkäme676',\n  'gleicht132',\n  'gold1554',\n  'habe605',\n  'haben1029',\n  'haben605',\n  'hat605',\n  'hatte605',\n  'heisst1631',\n  'her1351',\n  'her1511',\n  'herunter1574',\n  'heute1459',\n  'hin1351',\n  'hin1511',\n  'hinaus1574',\n  'hindurch1574',\n  'hinunter1574',\n  'hätte1756',\n  'hätten1756',\n  'hättest1756',\n  'im1346',\n  'im1777',\n  'im557',\n  'in1316',\n  'in1777',\n  'in557',\n  'in605',\n  'in858',\n  'irrte1029',\n  'isst1029',\n  'ist1029',\n  'ist125',\n  'ist130',\n  'ist1313',\n  'ist1459',\n  'ist1461',\n  'ist1462',\n  'ist1554',\n  'ist1660',\n  'ist1715',\n  'ist1792',\n  'ist1835',\n  'ist1846',\n  'ist1881',\n  'ist1884',\n  'ist875',\n  'ist976',\n  'je111',\n  'jedermanns1329',\n  'jetzt1631',\n  'kam676',\n  'kann1593',\n  'kaum11',\n  'kaum1986',\n  'kein1461',\n  'kein1462',\n  'kein1525',\n  'kein1690',\n  'kein1715',\n  'kein1881',\n  'kein902',\n  'kein949',\n  'keine1461',\n  'keine1525',\n  'keine1715',\n  'keine1835',\n  'keine1881',\n  'keine605',\n  'keine902',\n  'keine949',\n  'keiner1792',\n  'kleiden1029',\n  'kommen1509',\n  'kommen676',\n  'kommt1509',\n  'kommt676',\n  'kostet1029',\n  'käme676',\n  'lachen1029',\n  'lassen1029',\n  'lassen1289',\n  'lebte1029',\n  'lecker1649',\n  'ließ1289',\n  'lässt1289',\n  'läuft1029',\n  'macht1029',\n  'machte1029',\n  'mag605',\n  'meinem605',\n  'meisten488',\n  'meisten492',\n  'mich1573',\n  'mich1574',\n  'mir1582',\n  'mit1846',\n  'mit683',\n  'mords651',\n  'muss1300',\n  'musste1509',\n  'müssen1029',\n  'neue875',\n  'neuen875',\n  'nicht.“1779',\n  'nicht1162',\n  'nicht1690',\n  'nicht1779',\n  'nicht5',\n  'nicht902',\n  'nicht904',\n  'niemand1525',\n  'niemand1792',\n  'noch12',\n  'noch1770',\n  'nämliche104',\n  'nützt1029',\n  'ob1315',\n  'ob133',\n  'oder1162',\n  'oder1779',\n  'oder973',\n  'ohne1690',\n  'ohne949',\n  'ohnegleichen618',\n  'par1342',\n  'pur.»1323',\n  'pur1323',\n  'pur«1323',\n  'raus1316',\n  'recht5',\n  'redet1029',\n  'rein1316',\n  'ruiniert1029',\n  'satt1324',\n  'schlechthin1556',\n  'schlechthin»1556',\n  'schon5',\n  'schufen1029',\n  'schützt1029',\n  'sehr1987',\n  'sei125',\n  'seien1660',\n  'sein1289',\n  'selben1777',\n  'sich1573',\n  'sich1574',\n  'sich1582',\n  'sie1346',\n  'silber1554',\n  'sind1029',\n  'sind130',\n  'sind1459',\n  'sind1554',\n  'sind1660',\n  'sind1881',\n  'sind875',\n  'sind976',\n  'so1134',\n  'so135',\n  'so1760',\n  'so1831',\n  'so74',\n  'so98',\n  'solch78',\n  'soll605',\n  'sollten1029',\n  'sondergleichen618',\n  'sondergleichen»618',\n  'sondern902',\n  'sowohl1134',\n  'stand1346',\n  'statt320',\n  'statt882',\n  'steht1346',\n  'um350',\n  'umso111',\n  'und1029',\n  'und11',\n  'und1140',\n  'und1849',\n  'und5',\n  'und697',\n  'und777',\n  'und904',\n  'uns1574',\n  'uns1582',\n  'unter671',\n  'verdient1029',\n  'verändern1029',\n  'von1034',\n  'von1035',\n  'von127',\n  'von1629',\n  'von1772',\n  'vor559',\n  'war1313',\n  'war1459',\n  'war1461',\n  'war1462',\n  'war1660',\n  'war1770',\n  'war1846',\n  'war1881',\n  'waren1459',\n  'waren1770',\n  'waren1881',\n  'was1029',\n  'was13',\n  'was1459',\n  'was1846',\n  'weder12',\n  'wegen1629',\n  'wegen1772',\n  'weil674',\n  'weil681',\n  'welch15',\n  'wem1029',\n  'wenig762',\n  'wenigsten488',\n  'wenigsten492',\n  'wenn1291',\n  'wenn136',\n  'werden1029',\n  'wie101',\n  'wie103',\n  'wie125',\n  'wie130',\n  'wie1346',\n  'wie136',\n  'wie1738',\n  'will1029',\n  'wird1029',\n  'wird1660',\n  'wird605',\n  'wissen1029',\n  'wo1029',\n  'wogegen320',\n  'wohingegen320',\n  'wohl11',\n  'wohl1134',\n  'wollen1029',\n  'wäre130',\n  'wäre1660',\n  'wäre1756'],\n 555)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokens = [d[0] for d in csv_data.values]\n",
    "\n",
    "bert_tokens, len(bert_tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:34:51.012241700Z",
     "start_time": "2024-01-02T17:34:50.869289100Z"
    }
   },
   "id": "d55848226af1aa95"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the vanilla bert-german model:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1fd4b9029d49e1e"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "Embedding(30000, 768, padding_idx=0)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained('bert-base-german-cased', return_dict=True)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-german-cased')\n",
    "model.bert.embeddings.word_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:34:54.224050900Z",
     "start_time": "2024-01-02T17:34:50.878233100Z"
    }
   },
   "id": "e82730a36da5ce9c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add to existing embeddings:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31cb60117910e817"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Embedding(30555, 768)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_embeddings = torch.cat((model.bert.embeddings.word_embeddings.weight, torch.tensor(pseudowords)), dim=0)\n",
    "model.bert.embeddings.word_embeddings = torch.nn.Embedding.from_pretrained(combined_embeddings)\n",
    "model.bert.embeddings.word_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:34:54.243905200Z",
     "start_time": "2024-01-02T17:34:54.209487300Z"
    }
   },
   "id": "de2759094c5daff5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add to existing tokens:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36118990fc6027ce"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 30555. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": "Embedding(30555, 768)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(bert_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:34:54.268006800Z",
     "start_time": "2024-01-02T17:34:54.235706900Z"
    }
   },
   "id": "5e0c6c41fda55604"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Complete the masks:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b006ebc8aa40484"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/581 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09203b5abcbf46d68916a7f704c55230"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Und5 1 [CLS] Und5 schon gar nicht wegen der Mehrwertsteuer . [SEP] 17.02823829650879\n",
      "Und5 1 [CLS] Und5 schon gar nicht mit der Mehrwertsteuer . [SEP] 18.764745712280273\n",
      "Und5 1 [CLS] Und5 schon gar nicht mit der Zeit . [SEP] 10.610733032226562\n",
      "Und5 1 [CLS] Und5 schon gar nicht dadurch , dass man die Patienten dafür dann nicht anderweitig zur Kasse bittet . [SEP] 14.959037780761719\n",
      "Und5 1 [CLS] Und5 schon gar nicht darauf als dass man die Patienten dafür dann nicht anderweitig zur Kasse bittet . [SEP] 10.12462329864502\n",
      "Und5 1 [CLS] Und5 schon gar nicht darauf , dass man die Patienten dafür dann nicht anderweitig zur Kasse bittet . [SEP] 18.30353546142578\n",
      "Und5 1 [CLS] Und5 schon gar nicht darauf , dass man die Patienten dafür dann nicht anderweitig zur Kasse bittet . [SEP] 16.84368133544922\n",
      "Und5 1 [CLS] Und5 schon gar nicht darauf , dass man die Patienten dafür dann nicht anderweitig zur Kasse bittet . [SEP] 18.3360595703125\n",
      "Und5 1 [CLS] Und5 schon gar nicht darauf , dass man die Kunden dafür dann nicht anderweitig zur Kasse bittet . [SEP] 13.055015563964844\n",
      "Und5 1 [CLS] Und5 schon gar nicht darauf , dass man die Patienten auch dann nicht anderweitig zur Kasse bittet . [SEP] 14.775947570800781\n",
      "Und5 1 [CLS] Und5 schon gar nicht darauf , dass man die Patienten dafür auch nicht anderweitig zur Kasse bittet . [SEP] 15.569363594055176\n",
      "Und5 1 [CLS] Und5 schon gar nicht darauf , dass man die Patienten dafür dann auch anderweitig zur Kasse bittet . [SEP] 15.004228591918945\n",
      "Und5 1 [CLS] Und5 schon gar nicht darauf , dass man die Patienten dafür dann nicht mehr zur Kasse bittet . [SEP] 16.532258987426758\n",
      "Und5 1 [CLS] Und5 schon gar nicht darauf , dass man die Patienten dafür dann nicht anderweitig zur Kasse bittet . [SEP] 23.97811508178711\n",
      "Und5 1 [CLS] Und5 schon gar nicht darauf , dass man die Patienten dafür dann nicht anderweitig zur Kasse bittet . [SEP] 21.654260635375977\n",
      "Und5 1 [CLS] Und5 schon gar nicht darauf , dass man die Patienten dafür dann nicht anderweitig zur Kasse schickt . [SEP] 16.552270889282227\n",
      "Und5 1 [CLS] Und5 schon gar nicht , weil das neue System die Schüler schl ##auer macht . [SEP] 18.342987060546875\n",
      "Und5 1 [CLS] Und5 schon gar nicht , dass das neue System die Schüler schl ##auer macht . [SEP] 22.683921813964844\n",
      "Und5 1 [CLS] Und5 schon gar nicht , dass das neue System die Schüler schl ##auer macht . [SEP] 17.66054344177246\n",
      "Und5 1 [CLS] Und5 schon gar nicht , dass das neue Gesetz die Schüler schl ##auer macht . [SEP] 14.553362846374512\n",
      "Und5 1 [CLS] Und5 schon gar nicht , dass das neue System die Schüler schl ##auer macht . [SEP] 17.4034481048584\n",
      "Und5 1 [CLS] Und5 schon gar nicht , dass das neue System die Menschen schl ##auer macht . [SEP] 13.374856948852539\n",
      "Und5 1 [CLS] Und5 schon gar nicht , dass das neue System die Schüler jünger macht . [SEP] 16.534225463867188\n",
      "Und5 1 [CLS] Und5 schon gar nicht , dass das neue System die Schüler schl ##auer macht . [SEP] 19.17458724975586\n",
      "Und5 1 [CLS] Und5 schon gar nicht die Mauer , die 28 Jahre feste stand . [SEP] 17.19729995727539\n",
      "Und5 1 [CLS] Und5 schon gar nicht eine Frau , die 28 Jahre feste stand . [SEP] 13.875640869140625\n",
      "Und5 1 [CLS] Und5 schon gar nicht eine Mauer um die 28 Jahre feste stand . [SEP] 13.502094268798828\n",
      "Und5 1 [CLS] Und5 schon gar nicht eine Mauer , die 28 Jahre feste stand . [SEP] 16.999103546142578\n",
      "Und5 1 [CLS] Und5 schon gar nicht eine Mauer , die zehn Jahre feste stand . [SEP] 13.134496688842773\n",
      "Und5 1 [CLS] Und5 schon gar nicht eine Mauer , die 28 Jahre feste stand . [SEP] 14.36351203918457\n",
      "Und5 1 [CLS] Und5 schon gar nicht eine Mauer , die 28 Jahre lang stand . [SEP] 15.030503273010254\n",
      "Und5 1 [CLS] Und5 schon gar nicht eine Mauer , die 28 Jahre feste hat . [SEP] 10.97325325012207\n",
      "Und5 1 [CLS] Und5 schon gar nicht viel mehr davon . [SEP] 13.634705543518066\n",
      "Und5 1 [CLS] Und5 schon gar nicht nach einer davon . [SEP] 11.144754409790039\n",
      "Und5 1 [CLS] Und5 schon gar nicht nach mehr als . [SEP] 8.618220329284668\n",
      "Und5 1 [CLS] Und5 schon gar nicht , um klar und deutlich zu widersprechen . [SEP] 12.877934455871582\n",
      "Und5 1 [CLS] Und5 schon gar nicht , ohne klar und deutlich zu widersprechen . [SEP] 16.799959182739258\n",
      "Und5 1 [CLS] Und5 schon gar nicht , ohne klar und deutlich zu widersprechen . [SEP] 19.157917022705078\n",
      "Und5 1 [CLS] Und5 schon gar nicht , ohne klar und deutlich zu widersprechen . [SEP] 19.519588470458984\n",
      "Und5 1 [CLS] Und5 schon gar nicht , ohne klar und deutlich zu widersprechen . [SEP] 22.48532485961914\n",
      "Und5 1 [CLS] Und5 schon gar nicht , ohne klar und deutlich zu sein . [SEP] 16.558122634887695\n",
      "Und5 1 [CLS] Und5 schon gar nicht die Wende . [SEP] 15.306975364685059\n",
      "Und5 1 [CLS] Und5 schon gar nicht die Politik . [SEP] 8.866706848144531\n",
      "Und5 1 [CLS] Und5 schon gar nicht wenn sie jetzt Fragen beantworten . [SEP] 15.494383811950684\n",
      "Und5 1 [CLS] Und5 schon gar nicht will er jetzt Fragen beantworten . [SEP] 14.944018363952637\n",
      "Und5 1 [CLS] Und5 schon gar nicht will sie ihre Fragen beantworten . [SEP] 14.14932632446289\n",
      "Und5 1 [CLS] Und5 schon gar nicht will sie jetzt Fragen beantworten . [SEP] 14.770792007446289\n",
      "Und5 1 [CLS] Und5 schon gar nicht will sie jetzt Fragen stellen . [SEP] 17.876649856567383\n",
      "Und5 1 [CLS] Und5 schon gar nicht auf die [UNK] andere Seite [UNK] von damals , also die Springer - Presse , recht , die Kur ##ras verteidigte , gerade weil er so ein for ##scher Schütz ##e war . [SEP] 15.170249938964844\n",
      "Und5 1 [CLS] Und5 schon gar nicht beh ##ält die [UNK] andere Seite [UNK] von damals , also die Springer - Presse , recht , die Kur ##ras verteidigte , gerade weil er so ein for ##scher Schütz ##e war . [SEP] 11.131811141967773\n",
      "Und5 1 [CLS] Und5 schon gar nicht beh ##ält die rechte Seite [UNK] von damals , also die Springer - Presse , recht , die Kur ##ras verteidigte , gerade weil er so ein for ##scher Schütz ##e war . [SEP] 11.81186580657959\n",
      "Und5 1 [CLS] Und5 schon gar nicht beh ##ält die [UNK] andere Zeitung von damals , also die Springer - Presse , recht , die Kur ##ras verteidigte , gerade weil er so ein for ##scher Schütz ##e war . [SEP] 13.628654479980469\n",
      "Und5 1 [CLS] Und5 schon gar nicht beh ##ält die [UNK] andere Seite [UNK] Schon damals , also die Springer - Presse , recht , die Kur ##ras verteidigte , gerade weil er so ein for ##scher Schütz ##e war . [SEP] 13.179722785949707\n",
      "Und5 1 [CLS] Und5 schon gar nicht beh ##ält die [UNK] andere Seite [UNK] von links , also die Springer - Presse , recht , die Kur ##ras verteidigte , gerade weil er so ein for ##scher Schütz ##e war . [SEP] 10.292062759399414\n",
      "Und5 1 [CLS] Und5 schon gar nicht beh ##ält die [UNK] andere Seite [UNK] von damals hatte also die Springer - Presse , recht , die Kur ##ras verteidigte , gerade weil er so ein for ##scher Schütz ##e war . [SEP] 13.797685623168945\n",
      "Und5 1 [CLS] Und5 schon gar nicht beh ##ält die [UNK] andere Seite [UNK] von damals , hatte die Springer - Presse , recht , die Kur ##ras verteidigte , gerade weil er so ein for ##scher Schütz ##e war . [SEP] 10.669809341430664\n",
      "Und5 1 [CLS] Und5 schon gar nicht beh ##ält die [UNK] andere Seite [UNK] von damals , also der Springer - Presse , recht , die Kur ##ras verteidigte , gerade weil er so ein for ##scher Schütz ##e war . [SEP] 12.343771934509277\n",
      "Und5 1 [CLS] Und5 schon gar nicht beh ##ält die [UNK] andere Seite [UNK] von damals , also die andere , recht , die Kur ##ras verteidigte , gerade weil er so ein for ##scher Schütz ##e war . [SEP] 9.103561401367188\n",
      "Und5 1 [CLS] Und5 schon gar nicht beh ##ält die [UNK] andere Seite [UNK] von damals , also die Springer - Presse erst recht , die Kur ##ras verteidigte , gerade weil er so ein for ##scher Schütz ##e war . [SEP] 13.907745361328125\n",
      "Und5 1 [CLS] Und5 schon gar nicht beh ##ält die [UNK] andere Seite [UNK] von damals , also die Springer - Presse , ##e , die Kur ##ras verteidigte , gerade weil er so ein for ##scher Schütz ##e war . [SEP] 9.48501205444336\n",
      "Und5 1 [CLS] Und5 schon gar nicht beh ##ält die [UNK] andere Seite [UNK] von damals , also die Springer - Presse , recht und die Kur ##ras verteidigte , gerade weil er so ein for ##scher Schütz ##e war . [SEP] 10.5796537399292\n",
      "Und5 1 [CLS] Und5 schon gar nicht beh ##ält die [UNK] andere Seite [UNK] von damals , also die Springer - Presse , recht , die Kur ##ras verteidigte , gerade weil er so ein for ##scher Schütz ##e war . [SEP] 11.48449993133545\n",
      "Und5 1 [CLS] Und5 schon gar nicht beh ##ält die [UNK] andere Seite [UNK] von damals , also die Springer - Presse , recht , die er verteidigte , gerade weil er so ein for ##scher Schütz ##e war . [SEP] 14.991189002990723\n",
      "Und5 1 [CLS] Und5 schon gar nicht beh ##ält die [UNK] andere Seite [UNK] von damals , also die Springer - Presse , recht , die Kur ##ras nicht , gerade weil er so ein for ##scher Schütz ##e war . [SEP] 9.717388153076172\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 42\u001B[0m\n\u001B[0;32m     39\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m pd\u001B[38;5;241m.\u001B[39mSeries({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconstruction\u001B[39m\u001B[38;5;124m'\u001B[39m: row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconstruction\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpseudoword\u001B[39m\u001B[38;5;124m'\u001B[39m: row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpseudoword\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexample\u001B[39m\u001B[38;5;124m'\u001B[39m: row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexample\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgenerated\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;28mstr\u001B[39m(e)], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1.0\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdefinition\u001B[39m\u001B[38;5;124m'\u001B[39m: row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdefinition\u001B[39m\u001B[38;5;124m'\u001B[39m]})\n\u001B[0;32m     41\u001B[0m examples_reset \u001B[38;5;241m=\u001B[39m examples\u001B[38;5;241m.\u001B[39mreset_index()\n\u001B[1;32m---> 42\u001B[0m pseudoword_output_scores \u001B[38;5;241m=\u001B[39m examples_reset\u001B[38;5;241m.\u001B[39mprogress_apply(complete_masks, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# TODO use \"pseudoword\" as index\u001B[39;00m\n\u001B[0;32m     43\u001B[0m pseudoword_output_scores\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\tqdm\\std.py:805\u001B[0m, in \u001B[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001B[1;34m(df, func, *args, **kwargs)\u001B[0m\n\u001B[0;32m    802\u001B[0m \u001B[38;5;66;03m# Apply the provided function (in **kwargs)\u001B[39;00m\n\u001B[0;32m    803\u001B[0m \u001B[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001B[39;00m\n\u001B[0;32m    804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(df, df_function)(wrapper, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    806\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    807\u001B[0m     t\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\pandas\\core\\frame.py:9423\u001B[0m, in \u001B[0;36mDataFrame.apply\u001B[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001B[0m\n\u001B[0;32m   9412\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapply\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m frame_apply\n\u001B[0;32m   9414\u001B[0m op \u001B[38;5;241m=\u001B[39m frame_apply(\n\u001B[0;32m   9415\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   9416\u001B[0m     func\u001B[38;5;241m=\u001B[39mfunc,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   9421\u001B[0m     kwargs\u001B[38;5;241m=\u001B[39mkwargs,\n\u001B[0;32m   9422\u001B[0m )\n\u001B[1;32m-> 9423\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m op\u001B[38;5;241m.\u001B[39mapply()\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapply\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\pandas\\core\\apply.py:678\u001B[0m, in \u001B[0;36mFrameApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    675\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw:\n\u001B[0;32m    676\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_raw()\n\u001B[1;32m--> 678\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_standard()\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\pandas\\core\\apply.py:798\u001B[0m, in \u001B[0;36mFrameApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    797\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_standard\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 798\u001B[0m     results, res_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_series_generator()\n\u001B[0;32m    800\u001B[0m     \u001B[38;5;66;03m# wrap results\u001B[39;00m\n\u001B[0;32m    801\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwrap_results(results, res_index)\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\pandas\\core\\apply.py:814\u001B[0m, in \u001B[0;36mFrameApply.apply_series_generator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    811\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m option_context(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode.chained_assignment\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    812\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(series_gen):\n\u001B[0;32m    813\u001B[0m         \u001B[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001B[39;00m\n\u001B[1;32m--> 814\u001B[0m         results[i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf(v)\n\u001B[0;32m    815\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(results[i], ABCSeries):\n\u001B[0;32m    816\u001B[0m             \u001B[38;5;66;03m# If we have a view on v, we need to make a copy because\u001B[39;00m\n\u001B[0;32m    817\u001B[0m             \u001B[38;5;66;03m#  series_generator will swap out the underlying data\u001B[39;00m\n\u001B[0;32m    818\u001B[0m             results[i] \u001B[38;5;241m=\u001B[39m results[i]\u001B[38;5;241m.\u001B[39mcopy(deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\tqdm\\std.py:800\u001B[0m, in \u001B[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    794\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    795\u001B[0m     \u001B[38;5;66;03m# update tbar correctly\u001B[39;00m\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001B[39;00m\n\u001B[0;32m    797\u001B[0m     \u001B[38;5;66;03m# on the first column/row to decide whether it can\u001B[39;00m\n\u001B[0;32m    798\u001B[0m     \u001B[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001B[39;00m\n\u001B[0;32m    799\u001B[0m     t\u001B[38;5;241m.\u001B[39mupdate(n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m t\u001B[38;5;241m.\u001B[39mtotal \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mn \u001B[38;5;241m<\u001B[39m t\u001B[38;5;241m.\u001B[39mtotal \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m--> 800\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "Cell \u001B[1;32mIn[13], line 13\u001B[0m, in \u001B[0;36mcomplete_masks\u001B[1;34m(row)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Predict the most probable word that is not part of the new embeddings:\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m---> 13\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m model(input_ids)\n\u001B[0;32m     14\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mlogits\n\u001B[0;32m     15\u001B[0m predicted_token_probs \u001B[38;5;241m=\u001B[39m predictions[\u001B[38;5;241m0\u001B[39m, masked_index]\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1373\u001B[0m, in \u001B[0;36mBertForMaskedLM.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1358\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbert(\n\u001B[0;32m   1359\u001B[0m     input_ids,\n\u001B[0;32m   1360\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1369\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[0;32m   1370\u001B[0m )\n\u001B[0;32m   1372\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m-> 1373\u001B[0m prediction_scores \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcls(sequence_output)\n\u001B[0;32m   1375\u001B[0m masked_lm_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1376\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:712\u001B[0m, in \u001B[0;36mBertOnlyMLMHead.forward\u001B[1;34m(self, sequence_output)\u001B[0m\n\u001B[0;32m    711\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, sequence_output: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[1;32m--> 712\u001B[0m     prediction_scores \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictions(sequence_output)\n\u001B[0;32m    713\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m prediction_scores\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:702\u001B[0m, in \u001B[0;36mBertLMPredictionHead.forward\u001B[1;34m(self, hidden_states)\u001B[0m\n\u001B[0;32m    700\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, hidden_states):\n\u001B[0;32m    701\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(hidden_states)\n\u001B[1;32m--> 702\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder(hidden_states)\n\u001B[0;32m    703\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m hidden_states\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\llm-cxg\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mlinear(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def complete_masks(row):\n",
    "    try:\n",
    "        output_texts = []\n",
    "        scores = []\n",
    "        for query, example in list(zip(row[\"query\"], row[\"example\"])):\n",
    "            tokenized_query = [\"[CLS]\"] + tokenizer.tokenize(query) + [\"[SEP]\"]\n",
    "            masked_index = tokenized_query.index(\"[MASK]\")\n",
    "            input_ids = tokenizer.convert_tokens_to_ids(tokenized_query)\n",
    "            input_ids = torch.tensor([input_ids])\n",
    "            \n",
    "            # Predict the most probable word that is not part of the new embeddings:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids)\n",
    "                predictions = outputs.logits\n",
    "            predicted_token_probs = predictions[0, masked_index]\n",
    "            vocab_size = len(tokenizer)\n",
    "            wanted_vocab_size = vocab_size - len(tokenizer.get_added_vocab())  # 27000 - 30000: unused tokens; 30000+: new tokens\n",
    "            \n",
    "            # Find the top 5 predicted tokens with IDs lower than 28997\n",
    "            found = 0\n",
    "            for i in range(vocab_size):\n",
    "                if found:#  >= 5:\n",
    "                    break\n",
    "                token_id = torch.argsort(predicted_token_probs, descending=True)[i].item()\n",
    "                if token_id < wanted_vocab_size:\n",
    "                    predicted_token = tokenizer.convert_ids_to_tokens([token_id])[0]\n",
    "                    if \"unused_\" in predicted_token:  # unused_token, unused_punctuation\n",
    "                        continue\n",
    "                    found += 1\n",
    "                    output_text = tokenized_query[:masked_index] + [predicted_token] + tokenized_query[masked_index+1:]\n",
    "                    score = predicted_token_probs[token_id].item()\n",
    "                    print(row[\"pseudoword\"], found, \" \".join(output_text), score)\n",
    "                    output_texts.append(output_text)\n",
    "                    scores.append(score)\n",
    "        \n",
    "        return pd.Series({'construction': row['construction'], 'pseudoword': row['pseudoword'], 'example': row['example'], 'generated': output_texts, 'score': [float(score) for score in scores], 'definition': row['definition']})\n",
    "    except Exception as e:  # TODO Entfernen, sobald alle Pseudowords da sind\n",
    "        print(\".\", end=\"\")\n",
    "        return pd.Series({'construction': row['construction'], 'pseudoword': row['pseudoword'], 'example': row['example'], 'generated': [str(e)], 'score': [-1.0], 'definition': row['definition']})\n",
    "\n",
    "examples_reset = examples.reset_index()\n",
    "pseudoword_output_scores = examples_reset.progress_apply(complete_masks, axis=1)  # TODO use \"pseudoword\" as index\n",
    "pseudoword_output_scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:36:34.855216900Z",
     "start_time": "2024-01-02T17:34:54.268006800Z"
    }
   },
   "id": "b7fc546c4aeb79b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "examples = pseudoword_output_scores[[\"pseudoword\", \"generated\", \"score\"]]\n",
    "\n",
    "examples"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:36:34.858215700Z",
     "start_time": "2024-01-02T17:36:34.856215100Z"
    }
   },
   "id": "14e01733b5a4aeba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Anzahl neuer Sätze"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a64a06083f0ccd35"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "examples.to_csv(f\"../../out/comapp/data_bert.tsv\", sep=\"\\t\", decimal=\",\")\n",
    "examples.to_excel(f\"../../out/comapp/data_bert.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:36:34.859215400Z",
     "start_time": "2024-01-02T17:36:34.859215400Z"
    }
   },
   "id": "93ee2263ebe468ba"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pseudoword_output_scores.to_csv(\"../../out/comapp/data_bert_complete.tsv\", sep=\"\\t\", decimal=\",\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:36:34.861822800Z",
     "start_time": "2024-01-02T17:36:34.860339100Z"
    }
   },
   "id": "fa67b7735df5f46c",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
