{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:32:09.014610500Z",
     "start_time": "2024-01-04T17:32:08.961922900Z"
    }
   },
   "id": "863338ddbf31a6c5"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 example  \\\n0      Und dann ist da noch das generelle Problem mit...   \n1      Und dann ist da noch das generelle Problem mit...   \n2      Und dann ist da noch das generelle Problem mit...   \n3      Und dann ist da noch das generelle Problem mit...   \n4      Und dann ist da noch das generelle Problem mit...   \n...                                                  ...   \n83378  Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n83379  Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n83380  Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n83381  Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n83382  Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n\n                                                   query    pseudoword  \n0      Und dann ist da noch das generelle Problem mit...  geschweige10  \n1      Und dann ist da noch das generelle Problem mit...        denn10  \n2      Und dann ist da noch das generelle Problem mit...  geschweige10  \n3      Und dann ist da noch das generelle Problem mit...        denn10  \n4      Und dann ist da noch das generelle Problem mit...  geschweige10  \n...                                                  ...           ...  \n83378  Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n83379  Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n83380  Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n83381  Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n83382  Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n\n[83383 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>example</th>\n      <th>query</th>\n      <th>pseudoword</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>geschweige10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>denn10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>geschweige10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>denn10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>geschweige10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>83378</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>83379</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>83380</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>83381</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>83382</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n  </tbody>\n</table>\n<p>83383 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../../data/pseudowords/CoMaPP_all_bert.json\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "data = [{\"example\": d[\"target1\"], \"query\": (\" \".join(d[\"query\"].split()[:d[\"query_idx\"]]) + \" \" + d[\"label\"] + \" \" + \" \".join(d[\"query\"].split()[d[\"query_idx\"]+1:])).strip(), \"pseudoword\": d[\"label\"]} for d in data]\n",
    "df = pd.DataFrame.from_dict(data).drop_duplicates(ignore_index=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:32:09.876516800Z",
     "start_time": "2024-01-04T17:32:09.018655100Z"
    }
   },
   "id": "18bb06d46d72aab4"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 example  \\\nindex                                                      \n10     Und dann ist da noch das generelle Problem mit...   \n10     Und dann ist da noch das generelle Problem mit...   \n10     Und dann ist da noch das generelle Problem mit...   \n10     Und dann ist da noch das generelle Problem mit...   \n10     Und dann ist da noch das generelle Problem mit...   \n...                                                  ...   \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...   \n\n                                                   query    pseudoword  \nindex                                                                   \n10     Und dann ist da noch das generelle Problem mit...  geschweige10  \n10     Und dann ist da noch das generelle Problem mit...        denn10  \n10     Und dann ist da noch das generelle Problem mit...  geschweige10  \n10     Und dann ist da noch das generelle Problem mit...        denn10  \n10     Und dann ist da noch das generelle Problem mit...  geschweige10  \n...                                                  ...           ...  \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n99     Rund 45 . 000 Dollar soll der Byton - SUV kost...          er99  \n\n[83383 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>example</th>\n      <th>query</th>\n      <th>pseudoword</th>\n    </tr>\n    <tr>\n      <th>index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>geschweige10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>denn10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>geschweige10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>denn10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>Und dann ist da noch das generelle Problem mit...</td>\n      <td>geschweige10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>Rund 45 . 000 Dollar soll der Byton - SUV kost...</td>\n      <td>er99</td>\n    </tr>\n  </tbody>\n</table>\n<p>83383 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['index'] = df['pseudoword'].str.extract('(\\d+)').astype(int)\n",
    "df.set_index('index', inplace=True)\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:32:10.157954900Z",
     "start_time": "2024-01-04T17:32:09.877502700Z"
    }
   },
   "id": "b7e1f6e88f687297"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                   example  \\\nconstruction pseudoword                                                      \n5            Und5        [Und schon gar nicht mit der Mehrwertsteuer .,...   \n             erst5       [Trainer Lucien Favre hatte schon seine beiden...   \n             gar5        [Es hat Afghanistan nicht stabilisiert und sch...   \n             nicht5      [Es hat Afghanistan nicht stabilisiert und sch...   \n             recht5      [Trainer Lucien Favre hatte schon seine beiden...   \n...                                                                    ...   \n1884         Gold1884    [Schweigen ist Silber , reden ist Gold ., Schw...   \n             Silber1884  [Schweigen ist Silber , reden ist Gold ., Schw...   \n             ist1884     [Schweigen ist Silber , reden ist Gold ., Schw...   \n1986         kaum1986    [Die Vorhut vor 20.000 Jahren war fÃ¼r das Ries...   \n1987         sehr1987    [Solche Menschen kÃ¶nnen sich sehr wohlfÃ¼hlen o...   \n\n                                                                     query  \nconstruction pseudoword                                                     \n5            Und5        [Und5 schon gar nicht [MASK] der Mehrwertsteue...  \n             erst5       [Trainer Lucien Favre hatte schon seine beiden...  \n             gar5        [[MASK] hat Afghanistan nicht stabilisiert und...  \n             nicht5      [[MASK] hat Afghanistan nicht5 stabilisiert un...  \n             recht5      [Trainer Lucien Favre hatte schon seine beiden...  \n...                                                                    ...  \n1884         Gold1884    [[MASK] ist Silber , reden ist Gold1884 ., Sch...  \n             Silber1884  [[MASK] ist Silber1884 , reden ist Gold ., Sch...  \n             ist1884     [[MASK] ist1884 Silber , reden ist Gold ., Sch...  \n1986         kaum1986    [[MASK] Vorhut vor 20.000 Jahren war fÃ¼r das R...  \n1987         sehr1987    [[MASK] Menschen kÃ¶nnen sich sehr1987 wohlfÃ¼hl...  \n\n[581 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>example</th>\n      <th>query</th>\n    </tr>\n    <tr>\n      <th>construction</th>\n      <th>pseudoword</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">5</th>\n      <th>Und5</th>\n      <td>[Und schon gar nicht mit der Mehrwertsteuer .,...</td>\n      <td>[Und5 schon gar nicht [MASK] der Mehrwertsteue...</td>\n    </tr>\n    <tr>\n      <th>erst5</th>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n    </tr>\n    <tr>\n      <th>gar5</th>\n      <td>[Es hat Afghanistan nicht stabilisiert und sch...</td>\n      <td>[[MASK] hat Afghanistan nicht stabilisiert und...</td>\n    </tr>\n    <tr>\n      <th>nicht5</th>\n      <td>[Es hat Afghanistan nicht stabilisiert und sch...</td>\n      <td>[[MASK] hat Afghanistan nicht5 stabilisiert un...</td>\n    </tr>\n    <tr>\n      <th>recht5</th>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">1884</th>\n      <th>Gold1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[[MASK] ist Silber , reden ist Gold1884 ., Sch...</td>\n    </tr>\n    <tr>\n      <th>Silber1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[[MASK] ist Silber1884 , reden ist Gold ., Sch...</td>\n    </tr>\n    <tr>\n      <th>ist1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[[MASK] ist1884 Silber , reden ist Gold ., Sch...</td>\n    </tr>\n    <tr>\n      <th>1986</th>\n      <th>kaum1986</th>\n      <td>[Die Vorhut vor 20.000 Jahren war fÃ¼r das Ries...</td>\n      <td>[[MASK] Vorhut vor 20.000 Jahren war fÃ¼r das R...</td>\n    </tr>\n    <tr>\n      <th>1987</th>\n      <th>sehr1987</th>\n      <td>[Solche Menschen kÃ¶nnen sich sehr wohlfÃ¼hlen o...</td>\n      <td>[[MASK] Menschen kÃ¶nnen sich sehr1987 wohlfÃ¼hl...</td>\n    </tr>\n  </tbody>\n</table>\n<p>581 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'construction'}, inplace=True)\n",
    "\n",
    "result_df = df.groupby(['construction', 'pseudoword']).agg({'example': list, 'query': list})\n",
    "\n",
    "result_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:32:10.235892600Z",
     "start_time": "2024-01-04T17:32:10.157954900Z"
    }
   },
   "id": "4a4e3d92707b4c4"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             definition\n10    Die \"Negation:NEG_XgeschweigedennY-Konstruktio...\n100   Die \"Ã„quativ_Plural-Konstruktion\" gehÃ¶rt zu de...\n1004  Die \"Superlativ_Klimax:ADJ1_ADJ1-er_NP-Konstru...\n1006  Die \"Superlativ:PRÃ„P_ADJ-ster_NP-Konstruktion\"...\n101   Die \"Ã„quativ:ADJwieNP-Konstruktion\" gehÃ¶rt zu ...\n...                                                 ...\n97    Die \"Komparativ:ADJ1-eralsADJ1-Konstruktion\" g...\n973   Bei \"Disjunktion_Doppeltitel:XoderY\" handelt e...\n976   Bei \"Korrelation_Affirmation:WoXist, istY\" han...\n98    Die \"Ã„quativ:soADJwieXP-Konstruktion\" gehÃ¶rt z...\n99    Die \"Komparativ:ADJ-eralsX-Konstruktion\" gehÃ¶r...\n\n[211 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>definition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>Die \"Negation:NEG_XgeschweigedennY-Konstruktio...</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>Die \"Ã„quativ_Plural-Konstruktion\" gehÃ¶rt zu de...</td>\n    </tr>\n    <tr>\n      <th>1004</th>\n      <td>Die \"Superlativ_Klimax:ADJ1_ADJ1-er_NP-Konstru...</td>\n    </tr>\n    <tr>\n      <th>1006</th>\n      <td>Die \"Superlativ:PRÃ„P_ADJ-ster_NP-Konstruktion\"...</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>Die \"Ã„quativ:ADJwieNP-Konstruktion\" gehÃ¶rt zu ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>Die \"Komparativ:ADJ1-eralsADJ1-Konstruktion\" g...</td>\n    </tr>\n    <tr>\n      <th>973</th>\n      <td>Bei \"Disjunktion_Doppeltitel:XoderY\" handelt e...</td>\n    </tr>\n    <tr>\n      <th>976</th>\n      <td>Bei \"Korrelation_Affirmation:WoXist, istY\" han...</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>Die \"Ã„quativ:soADJwieXP-Konstruktion\" gehÃ¶rt z...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Die \"Komparativ:ADJ-eralsX-Konstruktion\" gehÃ¶r...</td>\n    </tr>\n  </tbody>\n</table>\n<p>211 rows Ã— 1 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../../out/definitions.pickle\", \"rb\") as definitions_file:\n",
    "    definitions = pd.DataFrame.from_dict(pickle.load(definitions_file), orient=\"index\", columns=[\"definition\"])\n",
    "    \n",
    "definitions"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:32:10.261479200Z",
     "start_time": "2024-01-04T17:32:10.239335200Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                   example  \\\nconstruction pseudoword                                                      \n5            Und5        [Und schon gar nicht mit der Mehrwertsteuer .,...   \n             erst5       [Trainer Lucien Favre hatte schon seine beiden...   \n             gar5        [Es hat Afghanistan nicht stabilisiert und sch...   \n             nicht5      [Es hat Afghanistan nicht stabilisiert und sch...   \n             recht5      [Trainer Lucien Favre hatte schon seine beiden...   \n...                                                                    ...   \n1884         Gold1884    [Schweigen ist Silber , reden ist Gold ., Schw...   \n             Silber1884  [Schweigen ist Silber , reden ist Gold ., Schw...   \n             ist1884     [Schweigen ist Silber , reden ist Gold ., Schw...   \n1986         kaum1986    [Die Vorhut vor 20.000 Jahren war fÃ¼r das Ries...   \n1987         sehr1987    [Solche Menschen kÃ¶nnen sich sehr wohlfÃ¼hlen o...   \n\n                                                                     query  \\\nconstruction pseudoword                                                      \n5            Und5        [Und5 schon gar nicht [MASK] der Mehrwertsteue...   \n             erst5       [Trainer Lucien Favre hatte schon seine beiden...   \n             gar5        [[MASK] hat Afghanistan nicht stabilisiert und...   \n             nicht5      [[MASK] hat Afghanistan nicht5 stabilisiert un...   \n             recht5      [Trainer Lucien Favre hatte schon seine beiden...   \n...                                                                    ...   \n1884         Gold1884    [[MASK] ist Silber , reden ist Gold1884 ., Sch...   \n             Silber1884  [[MASK] ist Silber1884 , reden ist Gold ., Sch...   \n             ist1884     [[MASK] ist1884 Silber , reden ist Gold ., Sch...   \n1986         kaum1986    [[MASK] Vorhut vor 20.000 Jahren war fÃ¼r das R...   \n1987         sehr1987    [[MASK] Menschen kÃ¶nnen sich sehr1987 wohlfÃ¼hl...   \n\n                                                                definition  \nconstruction pseudoword                                                     \n5            Und5        Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...  \n             erst5       Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...  \n             gar5        Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...  \n             nicht5      Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...  \n             recht5      Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...  \n...                                                                    ...  \n1884         Gold1884    Die \"Intensivierung_Komparativ:Xist_SilberYist...  \n             Silber1884  Die \"Intensivierung_Komparativ:Xist_SilberYist...  \n             ist1884     Die \"Intensivierung_Komparativ:Xist_SilberYist...  \n1986         kaum1986    Die Konstruktion \"Relativierung:kaumADJ\" gehÃ¶r...  \n1987         sehr1987    Die Konstruktion \"Intensivierung:sehrV\" gehÃ¶rt...  \n\n[581 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>example</th>\n      <th>query</th>\n      <th>definition</th>\n    </tr>\n    <tr>\n      <th>construction</th>\n      <th>pseudoword</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">5</th>\n      <th>Und5</th>\n      <td>[Und schon gar nicht mit der Mehrwertsteuer .,...</td>\n      <td>[Und5 schon gar nicht [MASK] der Mehrwertsteue...</td>\n      <td>Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...</td>\n    </tr>\n    <tr>\n      <th>erst5</th>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...</td>\n    </tr>\n    <tr>\n      <th>gar5</th>\n      <td>[Es hat Afghanistan nicht stabilisiert und sch...</td>\n      <td>[[MASK] hat Afghanistan nicht stabilisiert und...</td>\n      <td>Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...</td>\n    </tr>\n    <tr>\n      <th>nicht5</th>\n      <td>[Es hat Afghanistan nicht stabilisiert und sch...</td>\n      <td>[[MASK] hat Afghanistan nicht5 stabilisiert un...</td>\n      <td>Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...</td>\n    </tr>\n    <tr>\n      <th>recht5</th>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>[Trainer Lucien Favre hatte schon seine beiden...</td>\n      <td>Die \"Negation:NEG_Xund_schon_gar_nichtY-Konstr...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">1884</th>\n      <th>Gold1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[[MASK] ist Silber , reden ist Gold1884 ., Sch...</td>\n      <td>Die \"Intensivierung_Komparativ:Xist_SilberYist...</td>\n    </tr>\n    <tr>\n      <th>Silber1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[[MASK] ist Silber1884 , reden ist Gold ., Sch...</td>\n      <td>Die \"Intensivierung_Komparativ:Xist_SilberYist...</td>\n    </tr>\n    <tr>\n      <th>ist1884</th>\n      <td>[Schweigen ist Silber , reden ist Gold ., Schw...</td>\n      <td>[[MASK] ist1884 Silber , reden ist Gold ., Sch...</td>\n      <td>Die \"Intensivierung_Komparativ:Xist_SilberYist...</td>\n    </tr>\n    <tr>\n      <th>1986</th>\n      <th>kaum1986</th>\n      <td>[Die Vorhut vor 20.000 Jahren war fÃ¼r das Ries...</td>\n      <td>[[MASK] Vorhut vor 20.000 Jahren war fÃ¼r das R...</td>\n      <td>Die Konstruktion \"Relativierung:kaumADJ\" gehÃ¶r...</td>\n    </tr>\n    <tr>\n      <th>1987</th>\n      <th>sehr1987</th>\n      <td>[Solche Menschen kÃ¶nnen sich sehr wohlfÃ¼hlen o...</td>\n      <td>[[MASK] Menschen kÃ¶nnen sich sehr1987 wohlfÃ¼hl...</td>\n      <td>Die Konstruktion \"Intensivierung:sehrV\" gehÃ¶rt...</td>\n    </tr>\n  </tbody>\n</table>\n<p>581 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = pd.merge(result_df, definitions, how=\"inner\", left_on=\"construction\", right_index=True)  # TODO: Aussortierte Definitions betrachten!\n",
    "examples"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:32:10.301850900Z",
     "start_time": "2024-01-04T17:32:10.251968300Z"
    }
   },
   "id": "238d2238bbdd91d8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Generieren neuer SÃ¤tze:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bc899cb800665fa"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-2.0389168 , -1.6559315 ,  2.3402972 , ...,  1.9295877 ,\n        -0.2874232 ,  0.1127736 ],\n       [ 2.2873163 ,  1.1256251 , -0.72309786, ..., -0.9724281 ,\n        -0.6235189 ,  0.5858617 ],\n       [-0.72157246,  1.1234709 , -0.19191697, ..., -0.44904602,\n        -0.63462436, -0.51367843],\n       ...,\n       [ 1.5758858 ,  3.0587277 ,  1.1784296 , ..., -3.5326967 ,\n         2.022733  ,  0.7190625 ],\n       [-0.02080958,  2.2421186 ,  0.12035339, ..., -0.83508754,\n        -0.4160101 ,  0.07736167],\n       [ 1.2608864 ,  3.31698   , -3.9412627 , ..., -0.71156853,\n        -2.0257826 ,  2.4922867 ]], dtype=float32)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudowords = []\n",
    "for i in range(15):\n",
    "    pseudowords.append(np.load(f\"../../data/pseudowords/bert/pseudowords_comapp_bert_{i*37}_{i*37+37}.npy\"))\n",
    "pseudowords = np.concatenate(pseudowords)\n",
    "pseudowords"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:32:10.333311600Z",
     "start_time": "2024-01-04T17:32:10.274809400Z"
    }
   },
   "id": "c9e6d940aa4aaace"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  label\norder                                                  \n0                                               \"\"Was13\n1                                                  \"647\n2      \"Wir-Ã¤h-spielen-Ã¤h-in-der-Ã¤h-Champions-League647\n3                                                 (1597\n4                                                 (1600\n...                                                 ...\n550                                            wohl1134\n551                                          wollen1029\n552                                             wÃ¤re130\n553                                            wÃ¤re1660\n554                                            wÃ¤re1756\n\n[555 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n    </tr>\n    <tr>\n      <th>order</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"\"Was13</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"647</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"Wir-Ã¤h-spielen-Ã¤h-in-der-Ã¤h-Champions-League647</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(1597</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(1600</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>550</th>\n      <td>wohl1134</td>\n    </tr>\n    <tr>\n      <th>551</th>\n      <td>wollen1029</td>\n    </tr>\n    <tr>\n      <th>552</th>\n      <td>wÃ¤re130</td>\n    </tr>\n    <tr>\n      <th>553</th>\n      <td>wÃ¤re1660</td>\n    </tr>\n    <tr>\n      <th>554</th>\n      <td>wÃ¤re1756</td>\n    </tr>\n  </tbody>\n</table>\n<p>555 rows Ã— 1 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_data = []\n",
    "for i in range(1, 16):\n",
    "    csv_data.append(pd.read_csv(f\"../../data/pseudowords/bert/order_bert_{i}.csv\", sep=\";\", index_col=0, header=None, quotechar=\"|\", names=[\"order\", \"label\"]))\n",
    "csv_data = pd.concat(csv_data)\n",
    "csv_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:32:10.394858300Z",
     "start_time": "2024-01-04T17:32:10.287051800Z"
    }
   },
   "id": "621718c51c9db794"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(['\"\"Was13',\n  '\"647',\n  '\"Wir-Ã¤h-spielen-Ã¤h-in-der-Ã¤h-Champions-League647',\n  '(1597',\n  '(1600',\n  '(1602',\n  '(1624',\n  '(1637',\n  '(1639',\n  '(1641',\n  '(1643',\n  '(1645',\n  '(379',\n  '(579',\n  '(581',\n  '(584',\n  '(590',\n  '(592',\n  '(600',\n  '(886',\n  '(889',\n  '(892',\n  '(900',\n  '(905',\n  '(907',\n  '(909',\n  '(911',\n  '(917',\n  '(919',\n  '(921',\n  '(923',\n  ')1597',\n  ')1600',\n  ')1602',\n  ')1624',\n  ')1637',\n  ')1639',\n  ')1641',\n  ')1643',\n  ')1645',\n  ')1792',\n  ')379',\n  ')579',\n  ')581',\n  ')584',\n  ')590',\n  ')592',\n  ')600',\n  ')886',\n  ')889',\n  ')892',\n  ')900',\n  ')905',\n  ')907',\n  ')909',\n  ')911',\n  ')917',\n  ')919',\n  ')921',\n  ')923',\n  ')Â«579',\n  ',1459',\n  ',973',\n  '-128',\n  '-651',\n  '-654',\n  '-875',\n  '-973',\n  ':595',\n  ':875',\n  ':973',\n  'Abstand683',\n  'Allein20',\n  'Aller1630',\n  'Als1315',\n  'Als133',\n  'Als1770',\n  'Am488',\n  'Am492',\n  'Am500',\n  'Amerika605',\n  'Anstatt320',\n  'Art129',\n  'Arzt1509',\n  'Augenblick1301',\n  'AusmaÃŸ1777',\n  'BRUTAL1503',\n  'Besser1762',\n  'Bis559',\n  'Brutal1503',\n  'Buche1346',\n  'Das1313',\n  'Das1461',\n  'Dass21',\n  'Dasselbe104',\n  'Der1301',\n  'Desto111',\n  'Die1681',\n  'Diese19',\n  'Dieser1301',\n  'Dieser19',\n  'Dieses19',\n  'Entweder1779',\n  'Es1313',\n  'Es605',\n  'GefÃ¼hl1301',\n  'Generation1126',\n  'Geschweige10',\n  'Gleiche104',\n  'Gold1554',\n  'Gold1884',\n  'Hauptsache1033',\n  'Im557',\n  'In557',\n  'In858',\n  'Inbegriff1671',\n  'Ist1660',\n  'Je111',\n  'Jedermanns1329',\n  'Jener1301',\n  'Jetzt1631',\n  'Kein1525',\n  'Kein1715',\n  'Kein1835',\n  'Kein949',\n  'Keine(r1792',\n  'Keine1525',\n  'Keine1715',\n  'Keine1792',\n  'Keine1835',\n  'Keine902',\n  'Keine949',\n  'Keiner1792',\n  'Leben1461',\n  'Leben605',\n  'Lecker1649',\n  'MaÃŸ1777',\n  'MaÃŸe1777',\n  'Mit1029',\n  'Mit683',\n  'Moment1301',\n  'Mords651',\n  'Mutter1681',\n  'Neue875',\n  'Nicht1162',\n  'Nicht902',\n  'Niemand1792',\n  'Ponyhof1462',\n  'Raus1316',\n  'Reden1554',\n  'Riesen654',\n  'Silber1554',\n  'Silber1884',\n  'So1300',\n  'So1760',\n  'So1831',\n  'So22',\n  'So74',\n  'So98',\n  'Solch78',\n  'Solche78',\n  'Sowohl1134',\n  'Statt320',\n  'Tode1347',\n  'Trotz1630',\n  'Umfang1777',\n  'Umso111',\n  'Und11',\n  'Und5',\n  'Von1034',\n  'Von1629',\n  'Von1772',\n  'Warum1029',\n  'Was1029',\n  'Was13',\n  'Was16',\n  'Was1846',\n  'Weder12',\n  'Weil674',\n  'Weil681',\n  'Welch15',\n  'Wem1029',\n  'Wenn1291',\n  'Wer1029',\n  'Wie1029',\n  'Wie14',\n  'Wie1738',\n  'Wo1029',\n  'Wo976',\n  'WÃ¤hrend320',\n  'Zeit605',\n  'Zeiten605',\n  '[1643',\n  ']1643',\n  'ab1574',\n  'aber902',\n  'allen1630',\n  'aller1630',\n  'aller1681',\n  'aller758',\n  'als1134',\n  'als133',\n  'als1762',\n  'als1770',\n  'als97',\n  'am488',\n  'am492',\n  'am500',\n  'an349',\n  'anstatt320',\n  'anstatt882',\n  'artig128',\n  'auch1134',\n  'auch1715',\n  'auch1835',\n  'auf1574',\n  'auf350',\n  'aufhÃ¼bschen1029',\n  'aus1316',\n  'ausbreiten1029',\n  'auslÃ¶ste1029',\n  'badete1029',\n  'bedeutet1029',\n  'besser1762',\n  'betreffen1029',\n  'bis1509',\n  'bis559',\n  'bisschen762',\n  'bleibt1660',\n  'braucht1029',\n  'bringt1029',\n  'brutal1503',\n  'darstellen1029',\n  'das104',\n  'das1301',\n  'das1459',\n  'das1461',\n  'das875',\n  'dass135',\n  'dasselbe104',\n  'dem1777',\n  'den557',\n  'den671',\n  'denn10',\n  'der1509',\n  'der1681',\n  'der557',\n  'der875',\n  'desto111',\n  'die1681',\n  'die875',\n  'diese605',\n  'dieses19',\n  'durch1574',\n  'ebenso122',\n  'ebenso98',\n  'ein127',\n  'ein1715',\n  'ein1835',\n  'ein762',\n  'einander1574',\n  'eine129',\n  'eine1715',\n  'eine1835',\n  'eine605',\n  'einem127',\n  'einer127',\n  'entweder1779',\n  'er1004',\n  'er1346',\n  'er99',\n  'erst5',\n  'erzeugt1029',\n  'es125',\n  'es1313',\n  'es1346',\n  'es1631',\n  'es605',\n  'euch1574',\n  'excellence1342',\n  'fahre1029',\n  'frÃ¼her1459',\n  'fÃ¼r13',\n  'fÃ¼r1525',\n  'fÃ¼r350',\n  'gab605',\n  'ganz697',\n  'ganz777',\n  'gar5',\n  'gar697',\n  'gar777',\n  'geben605',\n  'gegeben605',\n  'gegen83',\n  'gehen1029',\n  'geht1300',\n  'genauso122',\n  'genauso98',\n  'geschweige10',\n  'gewesen1459',\n  'gibt605',\n  'gleich100',\n  'gleich675',\n  'gleich676',\n  'gleich98',\n  'gleiche104',\n  'gleichen1777',\n  'gleichkam676',\n  'gleichkommen676',\n  'gleichkommt676',\n  'gleichkÃ¤me676',\n  'gleicht132',\n  'gold1554',\n  'habe605',\n  'haben1029',\n  'haben605',\n  'hat605',\n  'hatte605',\n  'heisst1631',\n  'her1351',\n  'her1511',\n  'herunter1574',\n  'heute1459',\n  'hin1351',\n  'hin1511',\n  'hinaus1574',\n  'hindurch1574',\n  'hinunter1574',\n  'hÃ¤tte1756',\n  'hÃ¤tten1756',\n  'hÃ¤ttest1756',\n  'im1346',\n  'im1777',\n  'im557',\n  'in1316',\n  'in1777',\n  'in557',\n  'in605',\n  'in858',\n  'irrte1029',\n  'isst1029',\n  'ist1029',\n  'ist125',\n  'ist130',\n  'ist1313',\n  'ist1459',\n  'ist1461',\n  'ist1462',\n  'ist1554',\n  'ist1660',\n  'ist1715',\n  'ist1792',\n  'ist1835',\n  'ist1846',\n  'ist1881',\n  'ist1884',\n  'ist875',\n  'ist976',\n  'je111',\n  'jedermanns1329',\n  'jetzt1631',\n  'kam676',\n  'kann1593',\n  'kaum11',\n  'kaum1986',\n  'kein1461',\n  'kein1462',\n  'kein1525',\n  'kein1690',\n  'kein1715',\n  'kein1881',\n  'kein902',\n  'kein949',\n  'keine1461',\n  'keine1525',\n  'keine1715',\n  'keine1835',\n  'keine1881',\n  'keine605',\n  'keine902',\n  'keine949',\n  'keiner1792',\n  'kleiden1029',\n  'kommen1509',\n  'kommen676',\n  'kommt1509',\n  'kommt676',\n  'kostet1029',\n  'kÃ¤me676',\n  'lachen1029',\n  'lassen1029',\n  'lassen1289',\n  'lebte1029',\n  'lecker1649',\n  'lieÃŸ1289',\n  'lÃ¤sst1289',\n  'lÃ¤uft1029',\n  'macht1029',\n  'machte1029',\n  'mag605',\n  'meinem605',\n  'meisten488',\n  'meisten492',\n  'mich1573',\n  'mich1574',\n  'mir1582',\n  'mit1846',\n  'mit683',\n  'mords651',\n  'muss1300',\n  'musste1509',\n  'mÃ¼ssen1029',\n  'neue875',\n  'neuen875',\n  'nicht.â€œ1779',\n  'nicht1162',\n  'nicht1690',\n  'nicht1779',\n  'nicht5',\n  'nicht902',\n  'nicht904',\n  'niemand1525',\n  'niemand1792',\n  'noch12',\n  'noch1770',\n  'nÃ¤mliche104',\n  'nÃ¼tzt1029',\n  'ob1315',\n  'ob133',\n  'oder1162',\n  'oder1779',\n  'oder973',\n  'ohne1690',\n  'ohne949',\n  'ohnegleichen618',\n  'par1342',\n  'pur.Â»1323',\n  'pur1323',\n  'purÂ«1323',\n  'raus1316',\n  'recht5',\n  'redet1029',\n  'rein1316',\n  'ruiniert1029',\n  'satt1324',\n  'schlechthin1556',\n  'schlechthinÂ»1556',\n  'schon5',\n  'schufen1029',\n  'schÃ¼tzt1029',\n  'sehr1987',\n  'sei125',\n  'seien1660',\n  'sein1289',\n  'selben1777',\n  'sich1573',\n  'sich1574',\n  'sich1582',\n  'sie1346',\n  'silber1554',\n  'sind1029',\n  'sind130',\n  'sind1459',\n  'sind1554',\n  'sind1660',\n  'sind1881',\n  'sind875',\n  'sind976',\n  'so1134',\n  'so135',\n  'so1760',\n  'so1831',\n  'so74',\n  'so98',\n  'solch78',\n  'soll605',\n  'sollten1029',\n  'sondergleichen618',\n  'sondergleichenÂ»618',\n  'sondern902',\n  'sowohl1134',\n  'stand1346',\n  'statt320',\n  'statt882',\n  'steht1346',\n  'um350',\n  'umso111',\n  'und1029',\n  'und11',\n  'und1140',\n  'und1849',\n  'und5',\n  'und697',\n  'und777',\n  'und904',\n  'uns1574',\n  'uns1582',\n  'unter671',\n  'verdient1029',\n  'verÃ¤ndern1029',\n  'von1034',\n  'von1035',\n  'von127',\n  'von1629',\n  'von1772',\n  'vor559',\n  'war1313',\n  'war1459',\n  'war1461',\n  'war1462',\n  'war1660',\n  'war1770',\n  'war1846',\n  'war1881',\n  'waren1459',\n  'waren1770',\n  'waren1881',\n  'was1029',\n  'was13',\n  'was1459',\n  'was1846',\n  'weder12',\n  'wegen1629',\n  'wegen1772',\n  'weil674',\n  'weil681',\n  'welch15',\n  'wem1029',\n  'wenig762',\n  'wenigsten488',\n  'wenigsten492',\n  'wenn1291',\n  'wenn136',\n  'werden1029',\n  'wie101',\n  'wie103',\n  'wie125',\n  'wie130',\n  'wie1346',\n  'wie136',\n  'wie1738',\n  'will1029',\n  'wird1029',\n  'wird1660',\n  'wird605',\n  'wissen1029',\n  'wo1029',\n  'wogegen320',\n  'wohingegen320',\n  'wohl11',\n  'wohl1134',\n  'wollen1029',\n  'wÃ¤re130',\n  'wÃ¤re1660',\n  'wÃ¤re1756'],\n 555)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokens = [d[0] for d in csv_data.values]\n",
    "\n",
    "bert_tokens, len(bert_tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:32:10.395866600Z",
     "start_time": "2024-01-04T17:32:10.314936100Z"
    }
   },
   "id": "d55848226af1aa95"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the vanilla bert-german model:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1fd4b9029d49e1e"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "Embedding(30000, 768, padding_idx=0)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained('bert-base-german-cased', return_dict=True)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-german-cased')\n",
    "model.bert.embeddings.word_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:32:12.376059200Z",
     "start_time": "2024-01-04T17:32:10.324822600Z"
    }
   },
   "id": "e82730a36da5ce9c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add to existing embeddings:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31cb60117910e817"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "Embedding(30555, 768)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_embeddings = torch.cat((model.bert.embeddings.word_embeddings.weight, torch.tensor(pseudowords)), dim=0)\n",
    "model.bert.embeddings.word_embeddings = torch.nn.Embedding.from_pretrained(combined_embeddings)\n",
    "model.bert.embeddings.word_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:32:12.426500200Z",
     "start_time": "2024-01-04T17:32:12.379573700Z"
    }
   },
   "id": "de2759094c5daff5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add to existing tokens:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36118990fc6027ce"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 30555. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": "Embedding(30555, 768)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(bert_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:32:12.430499500Z",
     "start_time": "2024-01-04T17:32:12.405026600Z"
    }
   },
   "id": "5e0c6c41fda55604"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Complete the masks:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b006ebc8aa40484"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/581 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "624be67f4ee64f83a97723cb6fff65bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................................................................."
     ]
    }
   ],
   "source": [
    "def complete_masks(row):\n",
    "    try:\n",
    "        output_texts = []\n",
    "        scores = []\n",
    "        for query, example in list(zip(row[\"query\"], row[\"example\"])):\n",
    "            tokenized_query = [\"[CLS]\"] + tokenizer.tokenize(query) + [\"[SEP]\"]  # adding start and end of sequence\n",
    "            masked_index = tokenized_query.index(\"[MASK]\")\n",
    "            input_ids = tokenizer.convert_tokens_to_ids(tokenized_query)\n",
    "            input_ids = torch.tensor([input_ids])\n",
    "            \n",
    "            # Predict the most probable word that is not part of the new embeddings:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids)\n",
    "                predictions = outputs.logits\n",
    "            predicted_token_probs = predictions[0, masked_index]\n",
    "            vocab_size = len(tokenizer)\n",
    "            wanted_vocab_size = vocab_size - len(tokenizer.get_added_vocab())  # 27000 - 30000: unused tokens; 30000+: new tokens\n",
    "            \n",
    "            # Find the top 5 predicted tokens with IDs lower than 28997\n",
    "            found = 0\n",
    "            for i in range(vocab_size):\n",
    "                if found:#  >= 5:\n",
    "                    break\n",
    "                token_id = torch.argsort(predicted_token_probs, descending=True)[i].item()\n",
    "                if token_id < wanted_vocab_size:\n",
    "                    predicted_token = tokenizer.convert_ids_to_tokens([token_id])[0]\n",
    "                    if \"unused_\" in predicted_token:  # unused_token, unused_punctuation\n",
    "                        continue\n",
    "                    found += 1\n",
    "                    output_text = tokenized_query[:masked_index] + [predicted_token] + tokenized_query[masked_index+1:]\n",
    "                    score = predicted_token_probs[token_id].item()\n",
    "                    #print(row[\"pseudoword\"], found, \" \".join(output_text), score)\n",
    "                    output_texts.append(output_text)\n",
    "                    scores.append(score)\n",
    "        \n",
    "        return pd.Series({'construction': row['construction'], 'pseudoword': row['pseudoword'], 'example': row['example'], 'generated': output_texts, 'score': [float(score) for score in scores], 'definition': row['definition']})\n",
    "    except Exception as e:  # TODO Entfernen, sobald alle Pseudowords da sind\n",
    "        print(\".\", end=\"\")\n",
    "        return pd.Series({'construction': row['construction'], 'pseudoword': row['pseudoword'], 'example': row['example'], 'generated': [str(e)], 'score': [-1.0], 'definition': row['definition']})\n",
    "\n",
    "examples_reset = examples.reset_index()\n",
    "pseudoword_output_scores = examples_reset.progress_apply(complete_masks, axis=1)  # TODO use \"pseudoword\" as index\n",
    "pseudoword_output_scores"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-04T17:32:12.434500200Z"
    }
   },
   "id": "b7fc546c4aeb79b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "examples = pseudoword_output_scores[[\"pseudoword\", \"generated\", \"score\"]]\n",
    "\n",
    "examples"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "14e01733b5a4aeba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Anzahl neuer SÃ¤tze"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a64a06083f0ccd35"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "examples.to_csv(f\"../../out/comapp/data_bert.tsv\", sep=\"\\t\", decimal=\",\")\n",
    "examples.to_excel(f\"../../out/comapp/data_bert.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "93ee2263ebe468ba"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pseudoword_output_scores.to_csv(\"../../out/comapp/data_bert_complete.tsv\", sep=\"\\t\", decimal=\",\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "fa67b7735df5f46c",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
