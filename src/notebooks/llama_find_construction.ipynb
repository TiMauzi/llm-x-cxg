{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!pip3 install transformers==4.33.2\n",
    "!pip3 install optimum==1.13.2\n",
    "!pip3 install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/\n",
    "\n",
    "!nvidia-smi"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "574dcd99336b5f64"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_name_or_path = 'TheBloke/Llama-2-13B-German-Assistant-v4-GPTQ'\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    device_map=\"cuda:0\",\n",
    "    trust_remote_code=False,\n",
    "    revision=\"gptq-4bit-32g-actorder_True\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "737979872a7f76f1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(\"../../out/definitions.pickle\", \"rb\") as file:\n",
    "    definitions = pickle.load(file)\n",
    "with open(\"../../out/sentences.pickle\", \"rb\") as file:\n",
    "    sentences = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb7917f993cd42d8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def find_examples(definition, examples, temperature=0.1, top_p=0.95, top_k=1, true_examples=0):\n",
    "    max_new_tokens = 5 * true_examples\n",
    "    options = \"\"\n",
    "    for num, example in enumerate(examples):\n",
    "        options += f\"{num}: \\\"{example}\\\", \"\n",
    "    options = \"{\" + options[:-2] + \"}\"\n",
    "\n",
    "    tries = 5  # only try 5 times\n",
    "    output = set()\n",
    "\n",
    "    if true_examples > 0:\n",
    "        while len(output) != true_examples:\n",
    "            if true_examples == 1:\n",
    "                prompt = lambda d, e: f'''### User: Du bist genau und gewissenhaft und gibst stets die korrekte Antwort. Hier sind mögliche Sätze: {e} Hier ist eine Definition: {d} Nenne den Index des Satzes, der zur Definition passt.\n",
    "                ### Assistant: '''\n",
    "            else:\n",
    "                prompt = lambda d, e: f'''### User: Du bist genau und gewissenhaft und gibst stets die korrekte Antwort. Hier sind mögliche Sätze: {e} Hier ist eine Definition: {d} Nenne die Indizes der Sätze, die zur Definition passen, in einer Liste. Es sind genau {true_examples} Beispiele richtig.\n",
    "                ### Assistant: ['''\n",
    "            prompt_length = len(prompt(definition, options))\n",
    "\n",
    "            input_ids = tokenizer([prompt(definition, options)]*tries, return_tensors='pt').input_ids.to(\"cuda:0\")\n",
    "            pred = model.generate(\n",
    "                inputs=input_ids, temperature=temperature, do_sample=True, top_p=top_p, top_k=top_k,\n",
    "                max_new_tokens=len(input_ids[0]) + max_new_tokens\n",
    "            )\n",
    "            # print(tokenizer.batch_decode(pred))\n",
    "            pred = [re.findall('\\d', p[prompt_length:].strip()) for p in tokenizer.batch_decode(pred)]\n",
    "            output = {int(item) for row in pred for item in row}\n",
    "\n",
    "    else:\n",
    "        prompt = lambda d, e: f'''### User: Du bist genau und gewissenhaft und gibst stets die korrekte Antwort. Hier sind mögliche Sätze: {e} Hier ist eine Definition: {d} Nenne die Indizes der Sätze, die zur Definition passen, in einer Liste. Falls kein Satz richtig ist, gib [] aus.\n",
    "        ### Assistant: ['''\n",
    "        prompt_length = len(prompt(definition, options))\n",
    "\n",
    "        input_ids = tokenizer([prompt(definition, options)]*tries, return_tensors='pt').input_ids.to(\"cuda:0\")\n",
    "        pred = model.generate(inputs=input_ids, temperature=temperature,\n",
    "                                do_sample=True, top_p=top_p, top_k=top_k,\n",
    "                                max_new_tokens=len(input_ids[0]) + max_new_tokens)\n",
    "        # print(tokenizer.batch_decode(pred))\n",
    "        pred = [re.findall('\\d', p[prompt_length:].strip()) for p in tokenizer.batch_decode(pred)]\n",
    "        output |= {int(item) for row in pred for item in row}\n",
    "    print(output, end=\" \")\n",
    "    res = [examples[i] for i in output if 0 <= i < len(examples)]\n",
    "    input_ids = input_ids.to(\"cpu\")\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "693ad2b73bd9bcb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_metrics(positive_predicted, negative_predicted, true_sentences, false_sentences, key, definition, examples):\n",
    "    true_positives = [pr for pr in positive_predicted if pr in true_sentences]\n",
    "    false_positives = [pr for pr in positive_predicted if pr in false_sentences]\n",
    "    false_negatives = [pr for pr in negative_predicted if pr in true_sentences]\n",
    "    true_negatives = [pr for pr in negative_predicted if pr in false_sentences]\n",
    "    \n",
    "    if len(true_positives) + len(false_positives) > 0:\n",
    "        precision = len(true_positives) / (len(true_positives) + len(false_positives))\n",
    "    else:\n",
    "        precision = 1.0  # nothing found, so all things found are correct\n",
    "    \n",
    "    if len(true_positives) > 0:\n",
    "        recall = len(true_positives) / (len(true_positives) + len(false_negatives))\n",
    "    else:\n",
    "        recall = 1.0  # all found\n",
    "        \n",
    "    return pd.Series({\n",
    "        \"constr\": key, \n",
    "        \"definition\": definition, \n",
    "        \"examples\": examples, \n",
    "        \"positive_predicted\": positive_predicted,\n",
    "        \"negative_predicted\": negative_predicted,\n",
    "        \"true_positives\": true_positives,\n",
    "        \"false_positives\": false_positives,\n",
    "        \"false_negatives\": false_negatives,\n",
    "        \"true_negatives\": true_negatives,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": (2 * precision * recall) / (precision + recall),\n",
    "        \"accuracy\": (len(true_positives) + len(true_negatives)) / (len(true_sentences) + len(false_sentences))\n",
    "    })"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b56b8577f886471",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "random.seed(15)\n",
    "attempts = 3  # will be done in batches of 5 => 15 attempts!\n",
    "for num_true in range(0, 6):\n",
    "    for num_false in range(0, 6):\n",
    "        print()\n",
    "        if not num_true and not num_false:\n",
    "            continue  # skip (0, 0)\n",
    "        result = []\n",
    "        for key, definition in tqdm(definitions.items()):\n",
    "            others = list(itertools.chain.from_iterable([sentence_list for constr, sentence_list in sentences.items() if int(constr) != int(key)]))  # flatten all other sentences which are not part of the current construction\n",
    "            \n",
    "            for attempt in range(attempts):\n",
    "                try:\n",
    "                    # pick the true elements of the current construction\n",
    "                    true_sentences = {random.choice(list(sentences[int(key)])) for t in range(num_true)}\n",
    "                except KeyError:\n",
    "                    result.append(pd.Series({\"constr\": key, \"definition\": definition}))\n",
    "                    continue\n",
    "    \n",
    "                # pick random false positives from the other sentences\n",
    "                false_sentences = set(random.choices(others, k=num_false))\n",
    "                examples = list(false_sentences | true_sentences)\n",
    "                \n",
    "                positive_predicted = find_examples(definition[:definition.index(\".\")+1], examples)\n",
    "                negative_predicted = [ex for ex in examples if ex not in positive_predicted]\n",
    "                \n",
    "                result.append(get_metrics(positive_predicted, negative_predicted, true_sentences, false_sentences, key, definition, examples))\n",
    "                \n",
    "        result = pd.DataFrame(result)\n",
    "        result.to_csv(f\"../../out/llama/result_{num_true}t_vs_{num_false}f_{attempts}attempts_llama.tsv\", sep=\"\\t\", decimal=\",\", header=True, index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ecad5aeec67bfd80",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "random.seed(15)\n",
    "attempts = 15\n",
    "for num_true in range(1, 6):\n",
    "    for num_false in range(1, 6):\n",
    "        print()\n",
    "        result = []\n",
    "        for key, definition in tqdm(definitions.items()):\n",
    "            others = list(itertools.chain.from_iterable([sentence_list for constr, sentence_list in sentences.items() if int(constr) != int(key)]))  # flatten all other sentences which are not part of the current construction\n",
    "            \n",
    "            for attempt in range(attempts):\n",
    "                try:\n",
    "                    # pick the true elements of the current construction\n",
    "                    true_sentences = {random.choice(list(sentences[int(key)])) for t in range(num_true)}\n",
    "                except KeyError:\n",
    "                    result.append(pd.Series({\"constr\": key, \"definition\": definition}))\n",
    "                    continue\n",
    "    \n",
    "                # pick random false positives from the other sentences\n",
    "                false_sentences = set(random.choices(others, k=num_false))\n",
    "                examples = list(false_sentences | true_sentences)\n",
    "                \n",
    "                positive_predicted = find_examples(definition[:definition.index(\".\")+1], examples, num_true)\n",
    "                negative_predicted = [ex for ex in examples if ex not in positive_predicted]\n",
    "                \n",
    "                result.append(get_metrics(positive_predicted, negative_predicted, true_sentences, false_sentences, key, definition, examples))\n",
    "                \n",
    "        result = pd.DataFrame(result)\n",
    "        result.to_csv(f\"../../out/llama/result_{num_true}t_vs_{num_false}f_{attempts}attempts_llama_2.tsv\", sep=\"\\t\", decimal=\",\", header=True, index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddbbc3fe4ff4e01a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
