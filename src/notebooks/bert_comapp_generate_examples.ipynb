{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "863338ddbf31a6c5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"../../data/pseudowords/CoMaPP_all_bert.json\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "data = [{\"example\": d[\"target1\"], \"query\": (\" \".join(d[\"query\"].split()[:d[\"query_idx\"]]) + \" \" + d[\"label\"] + \" \" + \" \".join(d[\"query\"].split()[d[\"query_idx\"]+1:])).strip(), \"pseudoword\": d[\"label\"]} for d in data]\n",
    "df = pd.DataFrame.from_dict(data).drop_duplicates(ignore_index=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18bb06d46d72aab4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['index'] = df['pseudoword'].str.extract('(\\d+)').astype(int)\n",
    "df.set_index('index', inplace=True)\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7e1f6e88f687297"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'construction'}, inplace=True)\n",
    "\n",
    "result_df = df.groupby(['construction', 'pseudoword']).agg({'example': list, 'query': list})\n",
    "\n",
    "result_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a4e3d92707b4c4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"../../out/definitions.pickle\", \"rb\") as definitions_file:\n",
    "    definitions = pd.DataFrame.from_dict(pickle.load(definitions_file), orient=\"index\", columns=[\"definition\"])\n",
    "    \n",
    "definitions"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "examples = pd.merge(result_df, definitions, how=\"inner\", left_on=\"construction\", right_index=True)\n",
    "examples"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "238d2238bbdd91d8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generation of new sentences:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bc899cb800665fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pseudowords = []\n",
    "for i in range(15):\n",
    "    pseudowords.append(np.load(f\"../../data/pseudowords/bsbbert/pseudowords_comapp_bsbbert_{i*37}_{i*37+37}.npy\"))\n",
    "pseudowords = np.concatenate(pseudowords)\n",
    "pseudowords"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9e6d940aa4aaace"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "csv_data = []\n",
    "for i in range(1, 16):\n",
    "    csv_data.append(pd.read_csv(f\"../../data/pseudowords/bsbbert/order_bsbbert_{i}.csv\", sep=\";\", index_col=0, header=None, quotechar=\"|\", names=[\"order\", \"label\"]))\n",
    "csv_data = pd.concat(csv_data)\n",
    "csv_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "621718c51c9db794"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bert_tokens = [d[0] for d in csv_data.values]\n",
    "\n",
    "bert_tokens, len(bert_tokens)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d55848226af1aa95"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the vanilla bert-german model:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1fd4b9029d49e1e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = BertForMaskedLM.from_pretrained('dbmdz/bert-base-german-cased', return_dict=True)\n",
    "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-german-cased')\n",
    "model.bert.embeddings.word_embeddings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e82730a36da5ce9c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add to existing embeddings:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31cb60117910e817"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combined_embeddings = torch.cat((model.bert.embeddings.word_embeddings.weight, torch.tensor(pseudowords)), dim=0)\n",
    "model.bert.embeddings.word_embeddings = torch.nn.Embedding.from_pretrained(combined_embeddings)\n",
    "model.bert.embeddings.word_embeddings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de2759094c5daff5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add to existing tokens:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36118990fc6027ce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer.add_tokens(bert_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e0c6c41fda55604"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.to(\"cuda:0\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e5359f3050ec221",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Complete the masks:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b006ebc8aa40484"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def complete_masks(row):\n",
    "    try:\n",
    "        output_texts = []\n",
    "        scores = []\n",
    "        for query, example in list(zip(row[\"query\"], row[\"example\"])):\n",
    "            tokenized_query = [\"[CLS]\"] + tokenizer.tokenize(query) + [\"[SEP]\"]  # adding start and end of sequence\n",
    "            masked_index = tokenized_query.index(\"[MASK]\")\n",
    "            input_ids = tokenizer.convert_tokens_to_ids(tokenized_query)\n",
    "            input_ids = torch.tensor([input_ids], device=\"cuda:0\")\n",
    "            \n",
    "            # Predict the most probable word that is not part of the new embeddings:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids)\n",
    "                predictions = outputs.logits\n",
    "            predicted_token_probs = predictions[0, masked_index]\n",
    "            vocab_size = len(tokenizer)\n",
    "            wanted_vocab_size = vocab_size - len(tokenizer.get_added_vocab())  # 27000 - 30000: unused tokens; 30000+: new tokens\n",
    "            \n",
    "            # Find the top 5 predicted tokens with IDs lower than 28997\n",
    "            found = 0\n",
    "            for i in range(vocab_size):\n",
    "                if found:#  >= 5:\n",
    "                    break\n",
    "                token_id = torch.argsort(predicted_token_probs, descending=True)[i].item()\n",
    "                if token_id < wanted_vocab_size:\n",
    "                    predicted_token = tokenizer.convert_ids_to_tokens([token_id])[0]\n",
    "                    if \"unused_\" in predicted_token:  # unused_token, unused_punctuation\n",
    "                        continue\n",
    "                    found += 1\n",
    "                    output_text = tokenized_query[:masked_index] + [predicted_token] + tokenized_query[masked_index+1:]\n",
    "                    score = predicted_token_probs[token_id].item()\n",
    "                    #print(row[\"pseudoword\"], found, \" \".join(output_text), score)\n",
    "                    output_texts.append(output_text)\n",
    "                    scores.append(score)\n",
    "        \n",
    "        return pd.Series({'construction': row['construction'], 'pseudoword': row['pseudoword'], 'example': row['example'], 'generated': output_texts, 'score': [float(score) for score in scores], 'definition': row['definition']})\n",
    "    except Exception as e:\n",
    "        print(\".\", end=\"\")\n",
    "        return pd.Series({'construction': row['construction'], 'pseudoword': row['pseudoword'], 'example': row['example'], 'generated': [str(e)], 'score': [-1.0], 'definition': row['definition']})\n",
    "\n",
    "examples_reset = examples.reset_index()\n",
    "pseudoword_output_scores = examples_reset.progress_apply(complete_masks, axis=1)\n",
    "pseudoword_output_scores"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b7fc546c4aeb79b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "examples = pseudoword_output_scores[[\"pseudoword\", \"generated\", \"score\"]]\n",
    "\n",
    "examples"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "14e01733b5a4aeba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "examples.to_csv(f\"../../out/comapp/data_bsbbert.tsv\", sep=\"\\t\", decimal=\",\")\n",
    "examples.to_excel(f\"../../out/comapp/data_bsbbert.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "93ee2263ebe468ba"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pseudoword_output_scores.to_csv(\"../../out/comapp/data_bsbbert_complete.tsv\", sep=\"\\t\", decimal=\",\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "fa67b7735df5f46c",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
